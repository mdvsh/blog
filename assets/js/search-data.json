{
  
    
        "post0": {
            "title": "The Chain Rule: Revisited",
            "content": "In this blog post, I&#39;ll be revisiting Chain Rule as an essential concept behind Machine Learning and will explain how it works for both single and multivariable functions. Let&#39;s get started... . Fundamentals: functions, differentiability and compostion of functions. . Function : Think of a function $f$ as a mapping between the domain of a set, say $X$, to the codomain $Y$ of another set. Such a function is represented as $f : X rightarrow Y$. . If with this $f$, it&#39;s given that $g : Y rightarrow Z$, then $g circ f : X rightarrow Y$ isn&#39;t just gof, rather it&#39;s known as the composition of $g$ and $f$. This composition is defined $ forall x in X$ as : . $$ (g circ f)(x)=g(f(x)) $$ . In the case of Single variable calculus, $f$ and $g$ are real valued functions with their Domains and Co-domains both belonging to $ mathbb{R}$. . Example : . Let, $g(x) = x^{3}$ and $f(x) = x - 3$, then the composition gof is : $$(g circ f)(x)=g(f(x))=g(x-3)=(x-3)^{3}$$ | Note: Compositions work the other way around too, like you can also find $f circ g$ but we shouldn&#39;t assume compositions to be commutative. Compositions are in fact associative. . Differntiability : I&#39;ll not go into much detail about this here. If you feel like refreshing this concept, head out to Khan Academy here to brush up your basics. . A function $f$ is differentiable at a point, say $a$ if the following limit exists . $$ lim _{h rightarrow 0} frac{f left(a+h right)-f left(a right)}{h}$$ . This particular limit is also an expression for the derivative of function $f$ at point $a$. Mostly, instead of writing this lenghty limit, we express this derivative as $f^{&#39;}(a)$ or $ frac{d}{d x} f left(a right)$. This particular point can be any point on the real line and the value of the derivative is also a real number. . Chain Rule for Single Variable Functions . It states that if $g$ is differentiable at $a$ and $f$ is differentiable at $g(a)$, then the composition $f circ g$ is differentiable at $a$ and the value of its derivative is $$(f circ g)^{ prime} left(a right)=f^{ prime} left(g left(a right) right) g^{ prime} left(a right)$$ . It&#39;s proof is best left to the people at Khan Academy. However, there is one small error I noticed in a majority of the proofs online. All of them contain division by a quantity which might be zero. This is often overlooked and doesn&#39;t really make a difference, but for the sake of mathematical rigor if you wish to see the complicated version of the proof, please refer to Thomas Calculus&#39;. . Examples : . Take $f(x) = (x-2)^{2}$. Now try to think (and split) this function as a composition of two or more functions. Here, we can take $g(x) = x-2$ and $h(x) = x^{2}$. This way, $f(x)$ can be represented as $h circ g$ and the derivative of this composition is $h^{ prime}(g(x)) g^{ prime}(x), text { or } 2(x-2) text { since } g^{ prime}(x)=1$. The derivative of $w$ exists at all points. . | Take $f(x)= cos left[(x-2)^{3} right]$. After analysing, we observe that $f$ is a composition of 3 other functions: $$ begin{aligned} g(x) &amp;=x-2 h(x) &amp;=x^{3} i(x) &amp;= cos (x) end{aligned}$$ As discussed, compositon of functions is associative. $f$ can be expressed in one of two associative ways: $i circ (h circ g)$ or $(i circ h) circ g$. Going with the first one, we have $h circ g$ from the previous example, so : . | $$ begin{aligned} frac{d f(x)}{d x}= frac{d i(h(g(x)))}{d x} &amp;=i^{ prime}(h(g(x))) h(g(x))^{ prime}(x) &amp;=- sin (w(g(x))) 3(x-2) &amp;=-3 sin left[(x-2)^{3} right](x-2)^{2} end{aligned} $$ The Chain Rule in Programming . As we saw earlier, the chain rule can be used several times in a single calculation and it&#39;s this perk which makes chain rule such a powerful methjod for computing derivative of even every complex functions through a computational method. A function can simply be broken into simpler compositions and the chain rule be applied ever until we reach the base case of 1. . To understand, let&#39;s take the softmax function as an example. Softmax is a crucial function in Machine Learning and finding it&#39;s derivative is a step in backpropagation in Neural Networks where it is mostly used as the activation function of the final layer to get the output of the model as a probability distribution. If you have appropriate background, I suggest looking at Softmax Regression (C2W3L08) by Andrew Ng. . $$z(x)= frac{1}{1+e^{-x}}$$ . Here, we&#39;ll start drawing an equivalence between the mathematical part and the computational part to get a better intution. . import numpy as np def sigmoid(z): &quot;&quot;&quot;the sigmoid activation function&quot;&quot;&quot; return 1/(1+np.exp(-1*x)) . This might seem extremely similar to the mathematical function defined but this is all due to pseudocode-like syntax of Python. When interpreted, this computation is done step-by-step. Assuming we can only do one computation operation at every step, the code becomes : . import numpy as np def sigmoid(z): a = -x b = np.exp(a) c = 1 + b d = 1 / c return v . This can be equivalently written in this notation $S^{ prime}=d^{ prime}(c) c^{ prime}(b) b^{ prime}(a) a^{ prime}(x)$. Calculating this derivative is same as calculating derivative of the composition $d circ(c circ(b circ a))$ and is really simple since the constituent functions&#39; derivative is trivial. . $$ begin{aligned} S^{ prime} &amp;=d^{ prime}(c) c^{ prime}(b) b^{ prime}(a)(-1) &amp;=d^{ prime}(c) c^{ prime}(b) e^{-x}(-1) &amp;=d^{ prime}(c)(1) e^{-x}(-1) &amp;= frac{-1}{ left(1+e^{-x} right)^{2}} e^{-x}(-1) &amp;= frac{e^{-x}}{ left(1+e^{-x} right)^{2}} end{aligned} $$Now, the exciting part and the intution strikes! If every function (even a complex one) can be broken down into trivial functions, then, using the chain rule we can find the derivative of any function computable by a program!!! Isn&#39;t this awesome. . And this, my friends, is the basic of a technique known as Automatic Differentiation on which all of scientific computing and deep learning is based. As most of you would&#39;ve heard about Backpropagation: The miraculous algorithm which makes the computer learn, understand and predict stuff; is the most notable use case of Automatic Differentiation and form the foundation of modern machine learning. . Fun Fact: The modern Deep Learning Derby b/w PyTorch and Tensorflow essentially comes down to the different ways in which both these pacakges do their automatic differentiation on a computational graph. . Tip: To learn more, read this from CSC321@UToronto. . The Multivariate Chain Rule . So far we&#39;ve dealt with functions that map from $n$ to $m$ dimensions: $f: mathbb{R}^{n} rightarrow mathbb{R}^{m}$. Since every output of $f$ can be considered a separate function dependent on $n$ variables, we can also think about using matrices and vectors. . Multivariate Notation . Consider outputs of a function $f$ to be numbered from 1 to m as $f_{1}, f_{2} ldots f_{m}$. For all these outputs, we can calculate the partial derivative by any of n inputs as : $$D_{j} f_{i}(a)= frac{ partial f_{i}}{ partial a_{j}}(a)$$ where $j$ goes from 1 to $n$, $a$ is a vector with $n$ elems. When $f$ is differentiable at $a$, then the derivative is expressed as the Jacobian Matrix: a matrix of all first-order partial derivatives of the function. | . $$ D f(a)= left[ begin{array}{ccc} frac{ partial f_{1}}{ partial a_{1}}(a) &amp; cdots &amp; frac{ partial f_{1}}{ partial a_{n}}(a) vdots &amp; &amp; vdots frac{ partial f_{m}}{ partial a_{1}}(a) &amp; cdots &amp; frac{ partial f_{m}}{ partial a_{n}}(a) end{array} right] $$The Rule . The Multivariate Chain Rule states that: given a function $f: mathbb{R}^{m} rightarrow mathbb{R}^{p}$ and $g: mathbb{R}^{n} rightarrow mathbb{R}^{m}$ along with an arbitrary point $a$ in belonging to Real Numbers, if $g$ is differentiable at $a$ and $f$ is differentiable at $g(a)$; . Then $f circ g$ is differentiable at $a$ and the derivative is $$D(f circ g)(a)=D f(g(a)) cdot D g(a)$$ . This is also the product of matrix multiplication of $D f(g(a))$ and $D g(a)$ (try verifying the dimensions to cross-check the validity of the multiplication). . Intuitively, the multivariate chain rule is identical to the single variable one (the latter being nothing more than a special case of the former) with derivatives replaced by derivative matrices. We know From Linear Algebr how to represent Linear Transformations by Matrices, and how the composition of two linear transformations is the product of their matrices. . Thus, since derivative matrices - like derivatives in one dimension - are a linear approximation to the function, the chain rule makes complete sense. This is an amazing connection between Linear Algebra and Calculus. Again, the proof is best left to the experts at MIT (below) &amp; this document from LSU. . Applying Multivariate Chain Rule . Example . Let&#39;s take function $f$ as a scalar function $ mathbb{R}^{3} rightarrow mathbb{R}$ representing $f(x, y, z)$ giving the weather at some point in a 3D grid. Obviously, such a function would be a very complex function to write (or even think about) but just assume it as a simple function for the sake of this thought experiement. . Now, imagine moving through this 3D space on a curve defined by say, $g: mathbb{R} rightarrow mathbb{R}^{3}$, which takes time and gives your spatial coordinates $x(t), y(t), z(t)$ at a particular point in the 3D space. . Now we want to know what the weather is like at that particular point and how it changes as a funtion of $t$. Since, here weather isn&#39;t a direct dependence on $t$, but a function of location and in turn location is a function of time. And just like that, we get a composition $f circ g$ as the solution to our thought experiment. . Single Variate Approach: . $$g(t)= left( begin{array}{c} t t^{2} t^{3} end{array} right)$$and say $f$ is : $$f left( begin{array}{l} x y z end{array} right)=x^{2}+5y+10z+x y z$$ . Now, if we rewrite x, y, z as function of $t$, we get : $$f(x(t), y(t), z(t))=x(t)^{2}+x(t) y(t) z(t)+5 y(t) + 10 z(t)$$ . Composing $f$ with $g$ gives us, $$(f circ g)(t)=f(g(t))=f left(t, t^{2}, t^{3} right)=t^{2}+t^{6}+5 t^{2}+10 t^{3}=6 t^{2}+t^{6}+10 t^{3}$$ and the derivative is easily found out to be $(f circ g)^{ prime}(t)=12 t+6 t^{5}+30 t^{2}$ . . Multi-variate Approach: . Let&#39;s try the same thing now but using Multivariate Chain Rule. Thus to compute $D(f circ g)(t)$ we need $D f(g(t))$ and $D g(t)$. Starting with $D f(g(t))$, let&#39;s find $D f(x, y, z)$. Since it&#39;s a mapping from $ mathbb{R}^{3} rightarrow mathbb{R}$, the Jacobian Matrix is $1x3$ or simply, a row vector as : . $$D f(x, y, z)= left[ begin{array}{lll} 2 x+y z &amp; x z+5 &amp; x y + 10 end{array} right]$$But for applying the chain rule we need $D f(g(t))$ (see $g(t)$ from the single variate example) $$ D f(g(t))= left[ begin{array}{lll} 2 t+t^{5} &amp; t^{4}+5 &amp; t^{3} + 10 end{array} right] $$ . Now we need to find $D g(t) cdot g(t)$ maps $ mathbb{R} rightarrow mathbb{R}^{3},$ so its Jacobian is a 3x1 matrix, or column vector: $$ D g(t)= left[ begin{array}{c} 1 2 t 3 t^{2} end{array} right] $$ . Finally, multiplying $D f(g(t))$ by $D g(t),$ we get: $$ begin{aligned} D(f circ g)(t)=D f(g(t)) cdot D g(t) &amp;= left[2 t+t^{5} quad t^{4}+5 quad t^{3}+10 right] cdot left[ begin{array}{c} 1 2 t 3 t^{2} end{array} right] &amp;=2 t+t^{5}+2 t^{6}+10 t+3 t^{5} +30 t^{2} &amp;=12 t+6 t^{5}+30 t^{2} end{aligned} $$ . Now that we&#39;ve explored both the ways of finding the derivative,we can also interpret this result for the case where $f: mathbb{R}^{3} rightarrow mathbb{R}$ and $g: mathbb{R} rightarrow mathbb{R}^{3}$ is to recall that the directional derivative of $f$ in the direction of some vector $ vec{v}$ is: $$ D_{ vec{v}} f=( nabla f) cdot vec{v} $$ . If you don&#39;t understand what I&#39;m talking about, give this video a watch... . Coming back to our case, $( nabla f)$ is the Jacobian of $f$ (because of its dimensionality). So if we take $ vec{v}$ to be the vector $D g(t),$ and evaluate the gradient at $g(t)$ we get: $$ D_{D vec{g}(t)} f(t)=( nabla f(g(t))) cdot D g(t) $$ This gives us some additional intuition for the weather experiment. The change in weather as a function of time is the directional derivative of $f$ in the direction of the change in location $(D g(t))$ . The &#39;Link&#39; . So how does it all come together ? . Given function $f(x): mathbb{R} rightarrow mathbb{R},$ the Jacobian matrix contains a single entry. $$ D f(a)= left[D_{x} f(a) right]= left[ frac{d f}{d x}(a) right] $$ Therefore, given two functions mapping $ mathbb{R} rightarrow mathbb{R}$, the derivative of their composition using the multivariate chain rule is: $$ D(f circ g)(a)=D f(g(a)) cdot D g(a)=f^{ prime}(g(a)) g^{ prime}(a) $$ Which is just the single-variable chain rule. . This results from matrix multiplication between two $1 times 1$ matrices, which ends up being just the product of their single entries and Voila! We&#39;re Done. . $Q. E. D$ . So, why this Madhav ? . I don&#39;t know truly what prompted me to write this. Inspiration appeared from various sources with my occasional flipping through calc notes and a strong urge to write something math-y with LaTeX being among the major ones. .",
            "url": "https://csblog.madhavshekhar.com/ml/math/2020/06/15/Deepdive-into-the-chain-rule.html",
            "relUrl": "/ml/math/2020/06/15/Deepdive-into-the-chain-rule.html",
            "date": " • Jun 15, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Convolutional Model Building Blocks",
            "content": ". Note: Gist hosted here. . import numpy as np import matplotlib.pyplot as plt %matplotlib inline . TODO: . Convolution Functions Zero padding | Convolve window | Forward convolution | Backward Convolution | . | Pooling Function Forward pool | Mask creation | Value distribution | Backward Pool | . | . . Basic structure of CNN . Zero Padding . To add zeros around the image matrix to prevent loss of features due to scaling down after one step of a convolution. Same Convolution: padding such that h-w of original image preserved after one layer. . def zero_pad(X, p): &quot;&quot;&quot; params X: (n, nH, nW, nC) dims array representing a batch of images p: int, amount of padding around each image &quot;&quot;&quot; pad_width = ((0, 0), (p, p), (p, p), (0, 0)) X_p = np.pad(X, pad_width, mode=&#39;constant&#39;, constant_values=(0, 0)) return X_p . An example of padding some sample data and demonstrating. . np.random.seed(0) x = np.random.randn(1, 3, 3, 2) x_p = zero_pad(x, 2) print (&quot;X.shape = n&quot;, x.shape) print (&quot;x_p.shape = n&quot;, x_p.shape) fig, axarr = plt.subplots(1, 2) axarr[0].set_title(&#39;X: Original Image Matrix&#39;) axarr[0].imshow(x[0,:,:,0]) axarr[1].set_title(&#39;X_p: Padded Image Matrix&#39;) axarr[1].imshow(x_p[0,:,:,0]) . X.shape = (1, 3, 3, 2) x_p.shape = (1, 7, 7, 2) . &lt;matplotlib.image.AxesImage at 0x7f33b5942bd0&gt; . Convolution . conv_one_part() TODO: Take input volume (matrix by no. of channels) and convolve filter against it to output new volume with features (hopefully) identified. | . | conv_one_part() will apply convolution to a part of the given image matrix (X) of dimensions filter_h x filter_w, taking steps of value stride after each iteration of the function. To be implemented in the next function. . def conv_one_part(a_slice, W, b): &quot;&quot;&quot; params m_slice: slice of input matrix; dims --&gt; (f_h, f_w, nC_prev) W: Weight params contained in a window; dims --&gt; (f_h, f_w, nC_prev) b: Bias params contained in a window; dims --&gt; (1, 1, 1) : scalar &quot;&quot;&quot; Z = float(np.add(np.sum(np.multiply(a_slice, W)), b)) return Z . forward_conv() TODO: Take multiple filters and convolve all of them on the input. Stack 2D Matrix outputs to produce output volume giving result of a single forward pass of convolution. | . | def forward_conv(A_prev, W, b, hparams): &quot;&quot;&quot; params A_prev: previous layer activation; dims --&gt; (n, nH, nW, nC_prev) W: Weight params contained in a window; dims --&gt; (f_h, f_w, nC_prev, nC) b: Bias params contained in a window; dims --&gt; (1, 1, 1, nC) : scalar hparams: dict containing values for stride and padding return Z: conv step output; dims --&gt; (n, nH, nW, nC) cache: for calculating derivatives in backward_conv() &quot;&quot;&quot; # Init: Dimensions, hparams (n, nH_prev, nW_prev, nC_prev) = np.shape(A_prev) (f, f, nC_prev, nC) = np.shape(W) s = hparams[&#39;stride&#39;] pad = hparams[&#39;padding&#39;] nH = int((nH_prev-f+2*pad)/s)+1 nW = int((nW_prev-f+2*pad)/s)+1 Z = np.zeros((n, nH, nW, nC)) # Applying padding to prev layer activation A_prev_p = zero_pad(A_prev, pad) # Loop (Vectorization &gt;&gt;&gt;&gt;&gt;&gt;&gt; Loops) to apply convolution operation. for i in range(n): a_prev_p = A_prev_p[i, :, :, :] for h in range(nH): for w in range(nW): vert1_f, vert2_f = h*s, h*s+f hori1_f, hori2_f = w*s, w*s+f for c in range (nC): # slice a_slice = a_prev_p[vert1_f:vert2_f, hori1_f:hori2_f, :] Z[i, h, w, c] = conv_one_part(a_slice, W[:, :, :, c], b[:, :, :, c]) # for backward_conv() cache = (A_prev, W, b, hparams) # assert(Z.shape == (n, nH, nW, nC)) return (Z, cache) . Testing one iteration of forward_conv() on sample data. . np.random.seed(1) A_prev = np.random.randn(10,8,8,4) W = np.random.randn(3,3,4,8) # channels of A_prev and W has to be the same (here, 4) b = np.random.randn(1,1,1,8) hparams = {&quot;padding&quot; : 2, &quot;stride&quot;: 2} Z, cache_conv = forward_conv(A_prev, W, b, hparams) print(&quot;Z&#39;s mean = n&quot;, np.mean(Z)) print(&quot;Z[3,2,1] = n&quot;, Z[3,2,1]) print(&quot;cache_conv[0][1][2][3] =&quot;, cache_conv[0][1][2][3]) . Z&#39;s mean = -0.1282614539128993 Z[3,2,1] = [ 4.98925312 -0.12934609 6.77487928 -6.44934224 1.80531313 8.75470928 -2.85387942 -2.65858316] cache_conv[0][1][2][3] = [-0.9970198 -0.10679399 1.45142926 -0.61803685] . Pooling . Pooling operation after convolution to keep strong features by taking the maximum / average value contained in a sub-matrix of dims of the filter. Pooling helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. forward_pool() implments a forward pass of the pooling layer. By default, maxpool. . def forward_pool(A_prev, hparams, mode=&quot;maxpool&quot;): &quot;&quot;&quot; params A_prev: previous layer activation; dims --&gt; (n, nH, nW, nC_prev) hparams: dict containing values for filter_size and padding mode: pooling to perform; default --&gt; maxpool return A: pool step output; dims --&gt; (n, nH, nW, nC) cache: for calculating derivatives in backward_pool() &quot;&quot;&quot; # Init: Dimensions, hparams (n, nH_prev, nW_prev, nC_prev) = np.shape(A_prev) s = hparams[&#39;stride&#39;] fs = hparams[&#39;filt_size&#39;] nH = int((nH_prev-fs)/s)+1 nW = int((nW_prev-fs)/s)+1 nC = nC_prev A = np.zeros((n, nH, nW, nC)) # Loop (Vectorization &gt;&gt;&gt;&gt;&gt;&gt;&gt; Loops) to apply pooling operation. for i in range(n): for h in range(nH): for w in range(nW): for c in range(nC): vert1_f, vert2_f = h*s, h*s+fs hori1_f, hori2_f = w*s, w*s+fs a_slice = A_prev[i, vert1_f:vert2_f, hori1_f:hori2_f, c] if mode == &#39;maxpool&#39;: A[i, h, w, c] = np.max(a_slice) elif mode == &#39;avrgpool&#39;: A[i, h, w, c] = np.mean(a_slice) # for backward_conv() cache = (A_prev, hparams) # assert(A.shape == (n, nH, nW, nC)) return (A, cache) . Testing one iteration of forward_pool(mode=&#39;maxpool&#39;) on sample data. . np.random.seed(1) A_prev = np.random.randn(1, 5, 5, 3) hparams = {&quot;stride&quot; : 2, &quot;filt_size&quot;: 3} print(&#39;A_prev.shape = &#39; + str(A_prev.shape)) print(&quot;A = n&quot;, A_prev) print() A, cache = forward_pool(A_prev, hparams) print(&quot;Pooling type : Max Pooling&quot;) print(&quot;A.shape = &quot; + str(A.shape)) print(&quot;A = n&quot;, A) print() A, cache = forward_pool(A_prev, hparams, mode = &quot;avrgpool&quot;) print(&quot;Pooling type : Average Pooling&quot;) print(&quot;A.shape = &quot; + str(A.shape)) print(&quot;A = n&quot;, A) . A_prev.shape = (1, 5, 5, 3) A = [[[[ 1.62434536 -0.61175641 -0.52817175] [-1.07296862 0.86540763 -2.3015387 ] [ 1.74481176 -0.7612069 0.3190391 ] [-0.24937038 1.46210794 -2.06014071] [-0.3224172 -0.38405435 1.13376944]] [[-1.09989127 -0.17242821 -0.87785842] [ 0.04221375 0.58281521 -1.10061918] [ 1.14472371 0.90159072 0.50249434] [ 0.90085595 -0.68372786 -0.12289023] [-0.93576943 -0.26788808 0.53035547]] [[-0.69166075 -0.39675353 -0.6871727 ] [-0.84520564 -0.67124613 -0.0126646 ] [-1.11731035 0.2344157 1.65980218] [ 0.74204416 -0.19183555 -0.88762896] [-0.74715829 1.6924546 0.05080775]] [[-0.63699565 0.19091548 2.10025514] [ 0.12015895 0.61720311 0.30017032] [-0.35224985 -1.1425182 -0.34934272] [-0.20889423 0.58662319 0.83898341] [ 0.93110208 0.28558733 0.88514116]] [[-0.75439794 1.25286816 0.51292982] [-0.29809284 0.48851815 -0.07557171] [ 1.13162939 1.51981682 2.18557541] [-1.39649634 -1.44411381 -0.50446586] [ 0.16003707 0.87616892 0.31563495]]]] Pooling type : Max Pooling A.shape = (1, 2, 2, 3) A = [[[[1.74481176 0.90159072 1.65980218] [1.74481176 1.6924546 1.65980218]] [[1.13162939 1.51981682 2.18557541] [1.13162939 1.6924546 2.18557541]]]] Pooling type : Average Pooling A.shape = (1, 2, 2, 3) A = [[[[-0.03010467 -0.00324021 -0.33629886] [ 0.12893444 0.22242847 0.1250676 ]] [[-0.38268052 0.23257995 0.6259979 ] [-0.09525515 0.268511 0.46605637]]]] . Convolution Layer - Backward Pass . Note: $dZ_{hw}$ is a scalar corresponding to the gradient of the cost with respect to the output of the conv layer Z at the hth row and wth column (corresponding to the dot product taken at the ith stride left and jth stride down). . Further, We need to compute : . $dA$ (w.r.t cost for a certain filter $W_{c}$) $$ dA += sum _{h=0} ^{n_H} sum_{w=0} ^{n_W} W_c times dZ_{hw} tag{1}$$ . Notice, how everytime the same filter is multiplied by a different derivative of cost w.r.t output of conv layer Z ($dZ$) | . | $dW$ (derivative of one filter w.r.t to the loss) $$ dW_c += sum _{h=0} ^{n_H} sum_{w=0} ^ {n_W} a_{slice} times dZ_{hw} tag{2}$$ Where, $a_{slice}$ is the slice of original matrix used to generate activation $Z_{ij}$. This follows from the fact that the filter matrix can also learn (from backprop) optimal values. | . | $db$ ( w.r.t to the cost of a certain filter $dW_{c}$) $$ db = sum_h sum_w dZ_{hw} tag{3}$$ . summing over all the gradients of the conv output (Z) with respect to the cost. | . | backward_conv() : To implement the backward propagation for a convolution function . def backward_conv(dZ, cache): &quot;&quot;&quot; params dZ: gradient of cost w.r.t conv layer output (Z); dims --&gt; (n, nH, nW, nC) cache: cache of values needed for backward_conv(); i.e. output of forward_conv() returns see above (markdown) &quot;&quot;&quot; # Init: Dimensions, hparams (A_prev, W, b, hparams) = cache (n, nH_prev, nW_prev, nC_prev) = np.shape(A_prev) (f, f, nC_prev, nC) = np.shape(W) s = hparams[&#39;stride&#39;] pad = hparams[&#39;padding&#39;] (n, nH, nW, nC) = np.shape(dZ) dA_prev = np.zeros_like(A_prev) dW = np.zeros_like(W) db = np.zeros_like(b) A_prev_p = zero_pad(A_prev, pad) dA_prev_p = zero_pad(dA_prev, pad) # Loop (Vectorization &gt;&gt;&gt;&gt;&gt;&gt;&gt; Loops) for backward convolution step. for i in range(n): a_prev_p = A_prev_p[i, :, :, :] da_prev_p = dA_prev_p[i, :, :, :] for h in range(nH): for w in range(nW): for c in range(nC): vert1_f, vert2_f = h*s, h*s+f hori1_f, hori2_f = w*s, w*s+f # slice a_slice = a_prev_p[vert1_f:vert2_f, hori1_f:hori2_f, :] # updating gradients da_prev_p[vert1_f:vert2_f, hori1_f:hori2_f, :] += W[:, :, :, c] * dZ[i, h, w, c] dW[:, :, :, c] += a_slice * dZ[i, h, w, c] db[:, :, :, c] += dZ[i, h, w, c] dA_prev[i, :, :, :] = da_prev_p[pad:-pad, pad:-pad, :] # assert(dA_prev.shape == (m, nH_prev, nW_prev, nC_prev)) return dA_prev, dW, db . Testing backward_conv() on sample data. . # We&#39;ll run conv_forward to initialize the &#39;Z&#39; and &#39;cache_conv&quot;, # which we&#39;ll use to test the conv_backward function np.random.seed(1) A_prev = np.random.randn(10,4,4,3) W = np.random.randn(2,2,3,6) # six filters b = np.random.randn(1,1,1,6) hparameters = {&quot;padding&quot; : 2, &quot;stride&quot;: 2} Z, cache_conv = forward_conv(A_prev, W, b, hparameters) # Testing backward_conv() dA, dW, db = backward_conv(Z, cache_conv) print(&quot;dA_mean =&quot;, np.mean(dA)) print(&quot;dW_mean =&quot;, np.mean(dW)) print(&quot;db_mean =&quot;, np.mean(db)) . dA_mean = -0.9683520023516613 dW_mean = -3.028451139022465 db_mean = 41.04575496729348 . Pooling Layer - Backward Pass . Although, pooling layer has no learnable parameters for backpropagation, we still need to go through the pooling layer to complete gradient computation for layers that come before pooling layer. . To compute backward pooling, we would need a function mask_window() to create a matrix which keeps track of where the maximum of the matrix is. . $$ X = begin{bmatrix} 1 &amp;&amp; 2 3 &amp;&amp; 4 end{bmatrix} quad rightarrow quad M = begin{bmatrix} 0 &amp;&amp; 0 0 &amp;&amp; 1 end{bmatrix}$$But, why do we keep track of the position of the max? . It&#39;s because this is the input value that ultimately influenced the output, and therefore the cost. Backprop is computing gradients with respect to the cost, so anything that influences the ultimate cost should have a non-zero gradient. So, backprop will &quot;propagate&quot; the gradient back to this particular input value that had influenced the cost. . def max_mask(x): &quot;&quot;&quot; params x: input matrix to be masked returns m_x: masked matrix, same dims as x, 1 / True at max elem position &quot;&quot;&quot; m_x = (x == np.max(x)) return m_x . np.random.seed(1) x = np.random.randint(10, size=(3, 3)) print(&#39;x = &#39;, x) print(&#39;m_x = &#39;, max_mask(x)) . x = [[5 8 9] [5 0 0] [1 7 6]] m_z = [[False False True] [False False False] [False False False]] . We would also need a similar mask function for average pooling as well. . In case of average pooling, every elem of the sliced (window) matrix has equal influence on the output unlike max pooling where maximum influence is by the largest element. . def avrg_mask(x, dims): &quot;&quot;&quot; params x: input scalar to be masked dims: dims of array we want to distribute x to. returns m_x: masked matrix, same dims as x with x distributed among it &quot;&quot;&quot; (nH, nW) = dims avg = x/(nH*nW) m_x = avg * np.ones((nH, nW)) return m_x . print(&#39;Value to be Distributed: &#39;, 25,&#39; nDistributed / Average Mask: n&#39;, avrg_mask(25, (3, 3))) . Value to be Distributed: 25 Distributed / Average Mask: [[2.77777778 2.77777778 2.77777778] [2.77777778 2.77777778 2.77777778] [2.77777778 2.77777778 2.77777778]] . Now with our helper functions in place, we can proceed towards writing our final function of the day backward_pool(). . def backward_pool(dA, cache, mode=&#39;maxpool&#39;): &quot;&quot;&quot; params dA: gradient of cost w.r.t output of pooling layer; dims --&gt; like A cache: cache output from forward step of pooling layer; contains inputs and hparams moode: max/average pool returns dA_prev: gradient of cost w.r.t input of pooling layer; dims --&gt; like A_prev &quot;&quot;&quot; # Init; Dimensions and hparams (A_prev, hparams) = cache s = hparams[&#39;stride&#39;] fs = hparams[&#39;filt_size&#39;] (n, nH, nW, nC) = np.shape(dA) (n, nH_prev, nW_prev, nC_prev) = np.shape(A_prev) dA_prev = np.zeros_like(A_prev) # Loop (Vectorization &gt;&gt;&gt;&gt;&gt;&gt;&gt; Loops) for backward pooling step. for i in range(n): a_prev = A_prev[i, :, :, :] for h in range(nH): for w in range(nW): for c in range(nC): vert1_f, vert2_f = h*s, h*s+fs hori1_f, hori2_f = w*s, w*s+fs if mode==&#39;maxpool&#39;: a_prev_slice = a_prev[vert1_f:vert2_f, hori1_f:hori2_f, c] # create mask from a_prev_slice mask = max_mask(a_prev_slice) dA_prev[i, vert1_f:vert2_f, hori1_f:hori2_f, c] += mask * dA[i, h, w, c] elif mode==&#39;avrgpool&#39;: da = dA[i, h, w, c] dims = (fs, fs) dA_prev[i, vert1_f:vert2_f, hori1_f:hori2_f, c] += avrg_mask(da, dims) # assert(dA_prev.shape == A_prev.shape) return dA_prev . Testing backward_pool() on sample data. . np.random.seed(1) A_prev = np.random.randn(5, 5, 3, 2) hparameters = {&quot;stride&quot; : 1, &quot;filt_size&quot;: 2} A, cache = forward_pool(A_prev, hparameters) dA = np.random.randn(5, 4, 2, 2) dA_prev = backward_pool(dA, cache, mode = &quot;maxpool&quot;) print(&quot;Pooling type : Max Pooling&quot;) print(&#39;mean of dA = &#39;, np.mean(dA)) print(&#39;dA_prev[1,1] = &#39;, dA_prev[1,1]) print() dA_prev = backward_pool(dA, cache, mode = &quot;avrgpool&quot;) print(&quot;Pooling type : Average Pooling&quot;) print(&#39;mean of dA = &#39;, np.mean(dA)) print(&#39;dA_prev[1,1] = &#39;, dA_prev[1,1]) . Pooling type : Max Pooling mean of dA = 0.14571390272918056 dA_prev[1,1] = [[ 0. 0. ] [ 5.05844394 -1.68282702] [ 0. 0. ]] Pooling type : Average Pooling mean of dA = 0.14571390272918056 dA_prev[1,1] = [[ 0.08485462 0.2787552 ] [ 1.26461098 -0.25749373] [ 1.17975636 -0.53624893]] . . With this, we have completed all the basic building blocks functions required to build a Convolutional Model. . While coding this out, I was able to greatly increase my understanding about the mathematical working beneath both convolution and pooling operations. . With deeplearning libraries such as PyTorch and Tensorflow making such things a breeze, (only 10 lines of pytorch code to do all things I&#39;ve done in this notebook) it&#39;s not practical to define CNN models from scratch using numpy since tensors (numpy arrays + GPU support) are the go-to. Still, this endeavour turned out to be extremely knowledgable and EPIC. . kthnxbye .",
            "url": "https://csblog.madhavshekhar.com/dl/2020/05/20/cnn-numpy.html",
            "relUrl": "/dl/2020/05/20/cnn-numpy.html",
            "date": " • May 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Hand Signs Recognition with PyTorch",
            "content": ". Code at https://github.com/PseudoCodeNerd/pytorch-playground/tree/master/handsigns-pytorch Rewrote code from CS230 PyTorch Code Examples to acclimatize myself with PyTorch Workflow. . Read the Documentation at the source page to recreate. . As I venture into Deep Learning, I wanted to try PyTorch as a framework. This project is my first vision implementation using PyTorch. It was really helpful in getting myself used to the best practices to follow while using PyTorch for deep learning. . I’ve made the tough decision of choosing PyTorch as my go-to deep learning framework because of its more pythonic and numpy-like approach which made it easier to get used to the dynamic-graph paradigm. Also, debugging was a breeze. Tensorflow was really complex to understand with concepts like session, graph, variable scope, etc. being really hard to comprehend. . Task . Given an image of a hand doing a sign representing 0, 1, 2, 3, 4 or 5, predict the correct label. Model is trained on a 64x64 image dataset. For resizing, please see build_dataset . . Key Takeaways from this Vision Experiment . How to organize any Deep Learning Project in PyTorch. | How to work with Datasets and Dataloaders to get the data into the model. | How to implement stuff like dropout, regularization, batch-normalization, transforms, logging and reproducibility. | Utilizing nn.Module to better structure the actual model. | Effectively searching for optimal hyper-parameters through the use of various experiments/. | How to work with argparse. | Final Accuracy on the Test Set : 0.9453125 | Here. . The base model given in CS230 gave ~ 83% test-set accuracy. . . Resources . PyTorch documentation | PyTorch : What is torch.nn ? | PyTorch : Writing Custom Datasets, Dataloaders &amp; Transforms | CS230 Blog | SIGNS Dataset | .",
            "url": "https://csblog.madhavshekhar.com/pytorch/dl/2020/04/12/handsigns-recognition-pytorch.html",
            "relUrl": "/pytorch/dl/2020/04/12/handsigns-recognition-pytorch.html",
            "date": " • Apr 12, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Musings over Backpropagation",
            "content": "Notes and Implementation of Backpropagation Algorithm . A third attempt (finally a successful one) to understand the mechanics behind a neural network FT. Calculus . Explaination and Math . 1,3 2,4 . | | . | | . . . Important: If my notes aren&#8217;t visible, please go the the individual page link at imgur: . https://i.imgur.com/2y312KC.jpg . | https://i.imgur.com/F6Afhfy.jpg . | https://i.imgur.com/OamO0UN.jpg . | https://i.imgur.com/zlAyNq4.jpg . | . Notation used . Weights Biases (star) . | | . read notes to better understand . Formulas to be further used in code : . . Code . %matplotlib inline import numpy as np import random import matplotlib.pyplot as plt import json import sys . # helper functions (here, activation functions) def sigmoid(z): &quot;&quot;&quot;the sigmoid activation function&quot;&quot;&quot; return 1/(1+np.exp(-1*x)) def sigmoid_prime(x): &quot;&quot;&quot;the derivative of the sigmoid function&quot;&quot;&quot; return sigmoid(z)*(1-sigmoid(z)) def relu(z): &quot;&quot;&quot;the ReLU activation function&quot;&quot;&quot; return np.maximum(0,z) def one_hot_encoding(j): &quot;&quot;&quot;One hot encode to a 10-dimensional unit vector with prediction&quot;&quot;&quot; encoded_vec = np.zeroes((10, 1)) encoded_vec[j] = 1.0 return ohe . # loss functions : here I&#39;ll try using both CrossEntropyLoss (losLoss) and # QuadraticLoss functions to compare their performance. # https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html : Formulas # employed decent OOP practices class CrossEntropyCost(object): @staticmethod def func(a, y): &quot;&quot;&quot; return : cost associated with input a and desired output y sometime, when a = y, the formula for CrossEntropy returns NaN Formula : (1-y)*np.log(1-a) hence, np.nan_to_num is used to convert NaN&#39;s to (0.0) &quot;&quot;&quot; return np.sum(np.nan_to_numn(-y * np.log(a) - (1-y) * np.log(1-a))) @staticmethod def delta(a, y, z): return (a - y) class MSE_cost(object): @staticmethod def func(a, y): &quot;&quot;&quot;return : cost associated with input a and desired output y&quot;&quot;&quot; return np.linalg.norm(a - y) * 0.5 ** 2 @staticmethod def delta(a, y, z): &quot;&quot;&quot;params a, y follow suite z is the value of the neuron. from our derivation &quot;&quot;&quot; return (a - y) * sigmoid_prime(z) . class NN(object): def __init__(self, size, cost = CrossEntropyCost): &quot;&quot;&quot; list::size : number of neurons in respective layers of the network weights and biases are generated randomly through Gaussian Distribution with zero mean and variance of 1. &quot;&quot;&quot; self.n_layers = len(size) self.size = size # initializing weights only for 2nd to last layer since 1st layer is input layer (lacks weights) self.biases = [np.random.randn(y, 1) for y in self.size[1:]] self.weights = [np.random.randn(y, x)/np.sqrt(x) for x, y in zip(self.size[:-1], self.size[1:])] self.cost = cost def forward_propagation(self, a): &quot;&quot;&quot;The neuron calculation formula : Wa+b&quot;&quot;&quot; for w, b in zip(self.weights, self.biases): a = sigmoid(np.dot(w, a) + b) return a def back_propagation(self, x, y): &quot;&quot;&quot; return : (del_w, del_b) , the gradient for the cost function del_w and del_b are layer-by-layer lists of numpy arrays. Warning : negative indices would be heavily utilized &quot;&quot;&quot; del_w = [np.zeros(w.shape) for w in self.weights] del_b = [np.zeroes(b.shape) for b in self.biases] # forward prop curr_activation = x activations = [x] # store all activations by layer, remember chain-rule z_lis = [] # store all z values for layers, remember tree structure from notes for w, b in zip(self.weights, self.biases): z = np.dot(w, curr_activation) + b curr_activation = sigmoid(z) z_lis.append(z) activations.append(curr_activation) # backward pass : calculating cost by taking last elems of a, z lists delta = (self.cost).delta(activations[-1], y, z_lis[-1]) del_w[-1] = np.dot(delta, activations[-2].transpose()) del_b[-1] = delta # going back all layers for l in range(2, self.n_layers): z = z_lis[-l] del_sigmoid = sigmoid_prime(z) delta = np.dot(self.weights[-l+1].transpose(), delta) * del_sigmoid del_w[-l] = np.dot(delta, activations[-l-1].transpose()) del_b[-l] = delta return (del_w, del_b) def initialize_weight(self): &quot;&quot;&quot; initialize weights using Gaussian Distribution with mean 0 and SD 1 over sqrt of number of weights connecting same neuron initialize biases using Gaussian Distribution with mean 0 and SD 1 &quot;&quot;&quot; self.weights = [np.random.randn(y, x)/np.sqrt(x) for x, y in zip(self.size[:-1], self.size[:-1])] self.biases = [np.random.randn(y, 1) for y in self.size[1:]] def trainer(self, training_data, epochs, m_bs, eta, lmbda, eval_data=None, print_eval_cost=False, print_eval_acc=False, print_train_cost=False, print_train_acc=False): &quot;&quot;&quot; Train the neural network using mini-batch stochastic gradient descent. &quot;&quot;&quot; if eval_data: n_data = sum(1 for _ in eval_data) n = sum(1 for _ in training_data) eval_cost, eval_acc = [], [] train_cost, train_acc = [], [] for c in range(epochs): random.shuffle(training_data) mini_batches = [training_data[k:k+m_bs] for k in range(0, n, m_bs)] for mini_batch in mini_batches: self.update_mini_batch(mini_batch, eta, lmbda, len(training_data)) print(&#39;Training : Epoch % complete.&#39; % c) if print_train_cost: acc = self.accuracy(training_data, convert=True) train_acc.append(acc) print(&#39;Accuracy on training data : {} / {}&#39;.format(acc, n)) if print_train_cost: cost = self.total_cost(training_data, lmbda) train_cost.append(cost) print(&#39;Cost on training data : {}&#39;.format(cost)) if print_eval_acc: acc = self.accuracy(eval_data) eval_acc.append(acc) print(&#39;Accuracy on training data : {} / {}&#39;.format(acc, n)) if print_eval_cost: cost = self.total_cost(eval_data, lmbda, convert=True) train_cost.append(cost) print(&#39;Cost on training data : {}&#39;.format(cost)) print() return (eval_cost, eval_acc, train_cost, train_acc) def update_mini_batch(self, mini_batch, eta, lmbda, n): &quot;&quot;&quot;Update the network&#39;s weights and biases by applying gradient descent using backpropagation to a single mini batch.mini_batch is a list of tuples ``(x, y)``, ``eta`` is the learning rate, lmbda is the regularization parameter, and n is the total size of the training data set. &quot;&quot;&quot; nabla_b = [np.zeros(b.shape) for b in self.biases] nabla_w = [np.zeros(w.shape) for w in self.weights] for x, y in mini_batch: delta_nabla_b, delta_nabla_w = self.backprop(x, y) nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)] nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)] self.weights = [(1-eta*(lmbda/n))*w-(eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)] self.biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)] def accuracy(self, data, convert=False): &quot;&quot;&quot;Return the number of inputs in ``data`` for which the neural network outputs the correct result. The neural network&#39;s output is assumed to be the index of whichever neuron in the final layer has the highest activation. The flag ``convert`` should be set to False if the data set is validation or test data (the usual case), and to True if the data set is the training data. &quot;&quot;&quot; if convert: results = [(np.argmax(self.feedforward(x)), np.argmax(y)) for (x, y) in data] else: results = [(np.argmax(self.feedforward(x)), y) for (x, y) in data] return sum(int(x == y) for (x, y) in results) def total_cost(self, data, lmbda, convert=False): &quot;&quot;&quot;Return the total cost for the data set ``data``. &quot;&quot;&quot; cost = 0.0 for x, y in data: a = self.feedforward(x) if convert: y = vectorized_result(y) cost += self.cost.fn(a, y)/len(data) cost += 0.5*(lmbda/len(data))*sum( np.linalg.norm(w)**2 for w in self.weights) return cost def save(self, filename): &quot;&quot;&quot;Save the neural network to the file ``filename``.&quot;&quot;&quot; data = {&quot;size&quot;: self.size, &quot;weights&quot;: [w.tolist() for w in self.weights], &quot;biases&quot;: [b.tolist() for b in self.biases], &quot;cost&quot;: str(self.cost.__name__)} f = open(filename, &quot;w&quot;) json.dump(data, f) f.close() . Loading Data . # this python code to load MNIST Data is by Michael Nielsen. import _pickle as cPickle import gzip # Third-party libraries import numpy as np def load_data(): &quot;&quot;&quot;Return the MNIST data as a tuple containing the training data, the validation data, and the test data. The ``training_data`` is returned as a tuple with two entries. The first entry contains the actual training images. This is a numpy ndarray with 50,000 entries. Each entry is, in turn, a numpy ndarray with 784 values, representing the 28 * 28 = 784 pixels in a single MNIST image. The second entry in the ``training_data`` tuple is a numpy ndarray containing 50,000 entries. Those entries are just the digit values (0...9) for the corresponding images contained in the first entry of the tuple. The ``validation_data`` and ``test_data`` are similar, except each contains only 10,000 images. This is a nice data format, but for use in neural networks it&#39;s helpful to modify the format of the ``training_data`` a little. That&#39;s done in the wrapper function ``load_data_wrapper()``, see below. &quot;&quot;&quot; f = gzip.open(&#39;mnist.pkl.gz&#39;, &#39;rb&#39;) training_data, validation_data, test_data = cPickle.load(f, encoding=&#39;latin1&#39;) f.close() return (training_data, validation_data, test_data) def load_data_wrapper(): &quot;&quot;&quot;Return a tuple containing ``(training_data, validation_data, test_data)``. Based on ``load_data``, but the format is more convenient for use in our implementation of neural networks. In particular, ``training_data`` is a list containing 50,000 2-tuples ``(x, y)``. ``x`` is a 784-dimensional numpy.ndarray containing the input image. ``y`` is a 10-dimensional numpy.ndarray representing the unit vector corresponding to the correct digit for ``x``. ``validation_data`` and ``test_data`` are lists containing 10,000 2-tuples ``(x, y)``. In each case, ``x`` is a 784-dimensional numpy.ndarry containing the input image, and ``y`` is the corresponding classification, i.e., the digit values (integers) corresponding to ``x``. Obviously, this means we&#39;re using slightly different formats for the training data and the validation / test data. These formats turn out to be the most convenient for use in our neural network code.&quot;&quot;&quot; tr_d, va_d, te_d = load_data() training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]] training_results = [vectorized_result(y) for y in tr_d[1]] training_data = zip(training_inputs, training_results) validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]] validation_data = zip(validation_inputs, va_d[1]) test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]] test_data = zip(test_inputs, te_d[1]) return (training_data, validation_data, test_data) def vectorized_result(j): &quot;&quot;&quot;Return a 10-dimensional unit vector with a 1.0 in the jth position and zeroes elsewhere. This is used to convert a digit (0...9) into a corresponding desired output from the neural network.&quot;&quot;&quot; e = np.zeros((10, 1)) e[j] = 1.0 return e . training_data, validation_data, test_data = load_data_wrapper() . learner = NN([784, 30, 10]) . learner.trainer(training_data, 30, 10, 3.0, 0.1, eval_data=test_data) . TypeError Traceback (most recent call last) &lt;ipython-input-44-742e24694131&gt; in &lt;module&gt; -&gt; 1 learner.trainer(training_data, 30, 10, 3.0, 0.1, eval_data=test_data) &lt;ipython-input-40-6f3c6ca52295&gt; in trainer(self, training_data, epochs, m_bs, eta, lmbda, eval_data, print_eval_cost, print_eval_acc, print_train_cost, print_train_acc) 79 train_cost, train_acc = [], [] 80 for c in range(epochs): &gt; 81 random.shuffle(training_data) 82 mini_batches = [training_data[k:k+m_bs] for k in 83 range(0, n, m_bs)] ~/anaconda3/envs/fastai/lib/python3.7/random.py in shuffle(self, x, random) 273 if random is None: 274 randbelow = self._randbelow --&gt; 275 for i in reversed(range(1, len(x))): 276 # pick an element in x[:i+1] with which to exchange x[i] 277 j = randbelow(i+1) TypeError: object of type &#39;zip&#39; has no len() . . Other Resources to dive more into Backpropagation Calculus . Here&#39;s a good paper about matrix calculus for ML/DL. . | Here&#39;s a presentation from cornell that covers the derivation of the back propagation formulas. . | Here is a more intuitive explanation of back propagation with examples and some math from Stanford CS231n. . | Here&#39;s a deeper look at the underlying math also from Stanford CS231n. . | And if you ever did any graduate work in math or physics or related fields, you might find this treatment worth a look, but &quot;there be dragons!&quot; ;^) ... . | . . With this, I end this post. It was really intense, trying to comprehend the math behind Backpropagation in a single layer and then expanding the knowledge over to deep learning neural networks. 3B1B&#39;s video on Backpropagation was really intuitive to help me visualise the working in order to write this code. .",
            "url": "https://csblog.madhavshekhar.com/ml/2020/03/30/backpropagation-and-nn-from-scratch.html",
            "relUrl": "/ml/2020/03/30/backpropagation-and-nn-from-scratch.html",
            "date": " • Mar 30, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Rango - A Web Directory for anything.",
            "content": ". https://pseudocodenerd.pythonanywhere.com/ How it all started ? . I always wanted to learn backend web development to compliment the front-end only websites I built to make them more dynamic, interactive and complex (?). I initially experimented with ExpressJS but came to the conclusion that I lacked enough JS knowledge to make complex stuff in/with it. Later, a friend of mine suggested me to try Ruby on Rails (through The ODIN Project of course) but I never quite understod the Model-View-Controller design pattern / approach it advocated. Also, I remained hesitant to get the Ruby syntax into my framework. . Enter Django. . initially Flask for me though. . I was pretty good with python and the thought of using it in my websites to implement logic was sweet. At this time, I was only beginning to read through the official docs when another good friend of mine told me about this book (Tango with Django) to learn Django and how awesome and practical it was in teaching Django from the groundup. . I had never read a book for the sake of learning some new tech and was really curious as to how things would be. I had plenty of time to devote to learning Django as my Junior Year had just ended and we had a month long break until Senior Year started. So I started reading the book… . And Oh Boy! it was really EPIC. It provided just the right amount of theory in each meticulously divided chapter to cover all of Django and also had exercises to implement what we had learnt in each chapter and even a testing script to check our implementation. It made the learning curve way easier than what the official docs offered. Enough about the book, let’s dive into what I did over my ~3 week journey. . Stuff Learnt. . I kept track of my daily chapterwise progress through git and the commits were done after passing all tests. The commit history allows me to see how I increasingly made my django application from complex starting from the groundup. Here is a brief overview of the awesome new concepts I learnt: . Basics of Django: setup, architecture, views, urls, etc. // Code then | Template Engine, static / media files, DRY Approach // Code then | Database using ORM, data management w/ SQL and Models // Code then | Complex views and connections with models &amp; templates, forms and workflow // Code then | Custom user authentication views &amp; handling, User model, class-based views // Code then | Cookies, fundamentals of JQuery, AJAX for CRUD, search functionality // Code then | Bulma (themed entire site from skeleton –&gt; bulma) // Code then | deployment using PythonAnywhere and Progressive Web Apps. | . Putting it all together. . Not gonna lie, the most satisfying part was the deployment and asking my friends to test it out. I’m thankful to those who tested out my app by creating accounts on this Social Media Web App Barebones (That’s what I call it to make it sound cool). I have a few other ideas for things I want to make with Django but they are still a WIP. . Preview the website here . Looks great! Well done @sharmadhavs - we are super glad you grasped everything! Keep learning! ☺️ pic.twitter.com/oDy7Wrxm5u . &mdash; Tango With Django (@tangowithdjango) March 10, 2020 . . Fin. .",
            "url": "https://csblog.madhavshekhar.com/django/weekend-project/2020/03/10/rango-django-project.html",
            "relUrl": "/django/weekend-project/2020/03/10/rango-django-project.html",
            "date": " • Mar 10, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Judging books by their covers",
            "content": "(Don&#39;t) judge a book by its cover. . Task Description . Create a machine learning model to predict the category of a book from its cover image This task is inspired by this paper. Your task is to use the Flux machine learning library to predict the category of books in this dataset based on their cover images. You can find the Flux documentation here and sample models for image categorization in the model zoo. We recommend starting with a simple model like this one and then optionally using a more complex one if you are interested. . Aim : . In this notebook, I&#39;ll attempt to judge a book by it&#39;s cover (sorry Mom!). Pretty Simple right ? I think not... Shoutout to Akshat Mehortra and Mudit Somani for their helpful message in GCI Slack. . 1. Importing required libraries. . using Flux using CSV, Images, FileIO . 2. Getting the data . Data is sourced from The Book DatasSet. We&#39;ll use FileIO to get it into a variable. It&#39;d been better if the researcher could have made a script to download the full images in Julia also. I&#39;ll try doing that myself when I get some free time. . Data Courtesy : . B. K. Iwana, S. T. Raza Rizvi, S. Ahmed, A. Dengel, and S. Uchida, &quot;Judging a Book by its Cover,&quot; arXiv preprint arXiv:1610.09204 (2016). . data_train_csv = CSV.File(&quot;book30-listing-train.csv&quot;); . data_train_csv[42] . 7-element CSV.Row{false}: &#34;520271181&#34; &#34;0520271181.jpg&#34; &#34;http://ecx.images-amazon.com/images/I/51s8awrmTRL.jpg&#34; &#34;Becoming Dr. Q: My Journey from Migrant Farm Worker to Brain Surgeon&#34; &#34;Alfredo Quinones-Hinojosa&#34; 1 &#34;Biographies &amp; Memoirs&#34; . So we can see that every item (or row here) is of the form, . ID | FileName | Image URL | Title | Author | CategoryNum | Category . From the data README on GitHub, we come to know that there are 30 categories of books, each 1710 train and 190 test images. . Total Number of images : 51,300 (Train) | 5,700 (Test) . 3. Data pre-processing . Our model will accept an image as a Floating Vector. I&#39;ll also convert it to greyscale as directed by Image Classification workflows in ML community. . function grey_arr(img) return vec(Float64.(Gray.(img))) end . grey_arr (generic function with 1 method) . Creating batches of training images using Flux&#39;s Batch and using onehot for getting the categories of book images into another array. . function batcher(size) for x in data_train_csv[1:size] images = [grey_arr(load(&quot;./data/$(x[2])&quot;))]; labels = [Flux.onehot(x[6]+1,1:30)]; #plus 1 to account for 1 based indexing end return (Flux.batch(images), Flux.batch(labels)) end . create_batch (generic function with 1 method) . Making batches of 2000/1000 book images using our newly created function. . trainbatch = batcher(2000); . trainbatch_2 = batcher(1000) . ([0.7568627450980392 0.6 … 0.4117647058823529 0.12549019607843137; 0.6862745098039216 0.47058823529411764 … 0.4117647058823529 0.12549019607843137; … ; 0.8 0.22352941176470587 … 0.12941176470588234 0.2980392156862745; 0.9607843137254902 0.2784313725490196 … 0.12941176470588234 0.3529411764705882], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 1 0; 0 0 … 0 1]) . 4. Setting up our model, defining hyperparameters, adding loss, accuracy and optimiser functions. . The image is of dimensions 224x224x3 so we&#39;ll feed our Vanilla Neural Network with a 224x224 input. The expected output is one of the 30 labels of the book genre. . Therefore, . const alpha = 0.000075; const epoch = 20; . Using a NN with 3 layers as my fellow peers at GCI said that they were themselves unable to get a conv NN work. . relu as an activation function because it&#39;s my go to with image classification tasks and also of its non-saturation of gradient, which greatly accelerates the convergence of stochastic gradient descent compared to the sigmoid / tanh functions. . softmax to return a 30 element array with probabilities of the predicted labels. . model = Chain(Dense(224*224, 512, relu), Dense(512, 64), Dense(64, 30), softmax, ) . Chain(Dense(50176, 512, relu), Dense(512, 64), Dense(64, 30), softmax) . using Flux: onehotbatch, crossentropy, throttle using Statistics . optim = ADAM(alpha); loss(x,y) = Flux.crossentropy(model(x), y); acc(a,b) = mean(Flux.onecold(model(a)).== Flux.onecold(b)); function mod_cb() c_acc = acc(trainbatch_2...) c_loss = loss(trainbatch_2...) print(&quot;Current Accuracy: &quot;, string(c_acc), &quot; | Current Loss : &quot;, string(c_loss), &quot; ; n&quot;) end . mod_cb (generic function with 1 method) . 5. Training process . Flux.train!(loss, params(model), Iterators.repeated(trainbatch_2, 10), optim, cb = Flux.throttle(mod_cb, 10)) . Current Accuracy: 0.075 | Current Loss : 7.827263 ;Current Accuracy: 0.057 | Current Loss : 7.081502 ;Current Accuracy: 0.04 | Current Loss : 5.475811 ;Current Accuracy: 0.049 | Current Loss : 4.304302 ; . Flux.train!(loss, params(model), Iterators.repeated(trainbatch, 10), optim, cb = Flux.throttle(mod_cb, 10)) . Current Accuracy: 0.083 | Current Loss : 4.1588893 ;Current Accuracy: 0.082 | Current Loss : 3.8012412 ;Current Accuracy: 0.07 | Current Loss : 3.4713938 ;Current Accuracy: 0.102 | Current Loss : 3.3677185 ; . we can see that the accuracy nearly doubled, Lets train it further and also the iterations. . trainbatch_3 = create_batch(3000) Flux.train!(loss, params(model), Iterators.repeated(trainbatch, 50), optim, cb = Flux.throttle(mod_cb, 10)) . Current Accuracy: 0.101 | Current Loss : 3.3449063 ;Current Accuracy: 0.103 | Current Loss : 3.2926059 ;Current Accuracy: 0.123 | Current Loss : 3.228091 ;Current Accuracy: 0.141 | Current Loss : 3.1849866 ;Current Accuracy: 0.142 | Current Loss : 3.1404302 ;Current Accuracy: 0.137 | Current Loss : 3.1053653 ;Current Accuracy: 0.156 | Current Loss : 3.0754461 ;Current Accuracy: 0.154 | Current Loss : 3.0544689 ;Current Accuracy: 0.166 | Current Loss : 3.0326622 ;Current Accuracy: 0.181 | Current Loss : 3.0075598 ;Current Accuracy: 0.193 | Current Loss : 2.9763196 ;Current Accuracy: 0.192 | Current Loss : 2.9434323 ;Current Accuracy: 0.216 | Current Loss : 2.920823 ;Current Accuracy: 0.227 | Current Loss : 2.893316 ;Current Accuracy: 0.232 | Current Loss : 2.8663476 ;Current Accuracy: 0.253 | Current Loss : 2.8385205 ;Current Accuracy: 0.255 | Current Loss : 2.8103878 ; . We get a train accuracy of 25.5 % which is swell. . 6. Testing Time . loss(trainbatch_3...) . 3.0033288f0 . acc(trainbatch_3...) . 0.19166666666666668 . Loading and predicting label for a new image. . load(&quot;./data/$(data_test_csv[7][2])&quot;) . data_test_csv[7] . 7-element CSV.Row{false}: &#34;521456924&#34; &#34;0521456924.jpg&#34; &#34;http://ecx.images-amazon.com/images/I/41n7iZq-0jL.jpg&#34; &#34;Diagrammatica: The Path to Feynman Diagrams (Cambridge Lecture Notes in Physics)&#34; &#34;Martinus Veltman&#34; 23 &#34;Science &amp; Math&#34; . output_arr = model(grey_arr(load(&quot;./data/$(data_train_csv[69][2])&quot;))) . 30-element Array{Float32,1}: 0.027294824 0.008443545 0.032920413 0.008069489 0.016592907 0.010181716 0.13866615 0.03892814 0.02634485 0.03132174 0.0062278663 0.04601992 0.008348866 ⋮ 0.025657153 0.010952779 0.0171675 0.06719829 0.010065774 0.0694461 0.02233742 0.034847874 0.024896467 0.01961776 0.01895972 0.042962853 . maxval = maximum(output_arr) . 0.13866615f0 . findall(x -&gt; x==maxval, output_arr) . 1-element Array{Int64,1}: 7 . 7 acc to the Labels and Categories of the images is the Computers &amp; Technology however it should be Science &amp; Math. Pretty Close I must say . Thank You! .",
            "url": "https://csblog.madhavshekhar.com/julia/ml/gci19/2020/01/17/Judge-books-by-their-covers-FluxML.html",
            "relUrl": "/julia/ml/gci19/2020/01/17/Judge-books-by-their-covers-FluxML.html",
            "date": " • Jan 17, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Comparing Sentiment Analysis Models",
            "content": ". Note: Part 2 of this notebook is accomplished with TensorFlow and can be found here. . Task Description . Use the amazon review data from Kaggle to test the efficiency of our Sentiment Analysis models that live in TextAnalysis.jl. Compare it with models in ScikitLearn and Spacy python libraries. Upload your results as an issue in the TextAnalysis package. . Some basic machine learning knowledge is useful for this task. . Special thanks to Ayush Kaushal; an exemplary mentor without whom this task wouldn&#39;t be possible. . Find below, the julia part of the task. The python notebook would be attached too but would have sparse documentation. . The process of algorithmically identifying and categorizing opinions expressed in text to determine the user’s attitude toward the subject of the document (or post). . This is how I understand it. . Importing Required Packages . using TextAnalysis, FileIO . I would be working on the test data since the train one is humongous and my laptop was unable to render that in Jupyter every single time even when left for about an hour. . So, declaring the test reviews as review as evident by the code below. . reviews = Document(&quot;text/test.ft.txt&quot;) . FileDocument(&#34;text/test.ft.txt&#34;, TextAnalysis.DocumentMetadata(Languages.English(), &#34;text/test.ft.txt&#34;, &#34;Unknown Author&#34;, &#34;Unknown Time&#34;)) . Getting to know some of our data. . We can see that the .txt file contains reviews in the form of : . &quot;label1(/2) space ...the review...&quot; . Exploratory data analysis also reveals that reviews beginning with __label__2 are positive reviews. That means that their sentiment score would also be higher (I&#39;ll demonstrate that in a sec...) Similarly, reviews beginning with __label__1 are negative reviews and so their sentiment score should evidently be lower. . Getting our pre-trained Sentiment Analyser to check on these lines. . sent = SentimentAnalyzer() . ┌ Info: CUDAdrv.jl failed to initialize, GPU functionality unavailable (set JULIA_CUDA_SILENT or JULIA_CUDA_VERBOSE to silence or expand this message) └ @ CUDAdrv C: Users shekh .julia packages CUDAdrv 3EzC1 src CUDAdrv.jl:69 . Sentiment Analysis Model Trained on IMDB with a 88587 word corpus . #seeing how the data is arranged. readlines(&quot;text/test.ft.txt&quot;)[1:3] . 3-element Array{String,1}: &#34;__label__2 Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I&#39;m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life&#39;s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing &#34;Who was that singing ? &#34;&#34; &#34;__label__2 One of the best game music soundtracks - for a game I didn&#39;t really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there&#39;s not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren&#39;t included I would still consider the collection worth it.&#34; &#34;__label__1 Batteries died within a year ...: I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.&#34; . Now, I&#39;ll see that for the first 10 reviews in our dataset, what the actual label is and what sentiment score does our model return. From this we&#39;ll be able to know that the model isn&#39;t perfect and does indeed predict wrong sentiments for some reviews. Thus, developing a need to do text pre-processing to make the reviews comparable and remove unnecessary stuff like urls and other things generally not contributing to the read/feel of the review. ! . tab = &quot;SNo. | Label | Prediction Score | Should be | Predicted | Correct/Incorrect &quot; println(tab) println(&quot;-&quot;^(length(tab)+5)) for i in 1:15 label = readlines(&quot;text/test.ft.txt&quot;)[i][1:10]; review = readlines(&quot;text/test.ft.txt&quot;)[i][11:end]; review = StringDocument(review); pred = sent(review); if label == &quot;__label__2&quot; should_be = &quot;+ve&quot; else should_be = &quot;-ve&quot; end if pred &gt;= 0.5 pred_be = &quot;+ve&quot; elseif pred &lt; 0.5 pred_be = &quot;-ve&quot; end if pred_be == should_be correct = &quot;Correct&quot; else correct = &quot;Incorrect&quot; end println(&quot;$i | $label | $pred | $should_be | $pred_be | $correct &quot;) end . SNo. | Label | Prediction Score | Should be | Predicted | Correct/Incorrect -- 1 | __label__2 | 0.39506337 | +ve | -ve | Incorrect 2 | __label__2 | 0.5314957 | +ve | +ve | Correct 3 | __label__1 | 0.52432084 | -ve | +ve | Incorrect 4 | __label__2 | 0.5501878 | +ve | +ve | Correct 5 | __label__2 | 0.5919624 | +ve | +ve | Correct 6 | __label__1 | 0.61544746 | -ve | +ve | Incorrect 7 | __label__1 | 0.732198 | -ve | +ve | Incorrect 8 | __label__1 | 0.55473757 | -ve | +ve | Incorrect 9 | __label__2 | 0.4127747 | +ve | -ve | Incorrect 10 | __label__1 | 0.58470565 | -ve | +ve | Incorrect 11 | __label__2 | 0.5855292 | +ve | +ve | Correct 12 | __label__1 | 0.51694876 | -ve | +ve | Incorrect 13 | __label__1 | 0.5547061 | -ve | +ve | Incorrect 14 | __label__2 | 0.45876318 | +ve | -ve | Incorrect 15 | __label__1 | 0.52366424 | -ve | +ve | Incorrect . It&#39;s clear that our model isn&#39;t optimal since out of 15 samples, only 4 were correct predictions. However, I went a little too harsh on the model since in some cases, like in . 14 | __label__2 | 0.45876318 | +ve | -ve | Incorrect . the model was within some limit of correct predictions. So yeah, sorry Mr. Sentiment Analyzer. . Moving on towards trying to improve the accuracy of predcitions by performing some general pre-defined text-processing functions in TextAnalysis package. But first, I want to know the length of our test data set so I can make batches of processing accrodinly to my computational powers. . test_data = readlines(&quot;text/test.ft.txt&quot;) length(test_data) . 400000 . Ok, so now we know the size of the data we&#39;re dealing with let&#39;s get started with the pre-processing. . A true positive is an outcome where the model correctly predicts the positive class. Similarly, a true negative is an outcome where the model correctly predicts the negative class. . A false positive is an outcome where the model incorrectly predicts the positive class. And a false negative is an outcome where the model incorrectly predicts the negative class. . test_labels = [] test_string = [] fal_pos = 0 fal_neg = 0 tru_pos = 0 tru_neg = 0 for i in 1:length(test_data) label =test_data[i][1:10]; push!(test_labels, label); review = test_data[i][11:end]; push!(test_string, review) #after adding reviews and labels in their respective arrays. #I&#39;ll perform pre-processing on individual reviews. review_sd = StringDocument(review) remove_corrupt_utf8!(review_sd) stem!(review_sd) remove_case!(review_sd) #remove_indefinite_articles!(review_sd) #remove_definite_articles!(review_sd) if label == &quot;__label__2&quot; should_be = &quot;+ve&quot; else should_be = &quot;-ve&quot; end pred = sent(review_sd) if pred &gt;= 0.5 pred_be = &quot;+ve&quot; elseif pred &lt; 0.5 pred_be = &quot;-ve&quot; end if pred_be == &quot;+ve&quot; &amp;&amp; should_be == &quot;+ve&quot; tru_pos += 1 elseif pred_be == &quot;-ve&quot; &amp;&amp; should_be == &quot;-ve&quot; tru_neg += 1 elseif pred_be == &quot;-ve&quot; &amp;&amp; should_be == &quot;+ve&quot; fal_pos += 1 elseif pred_be == &quot;+ve&quot; &amp;&amp; should_be == &quot;-ve&quot; fal_neg += 1 end end . BoundsError: attempt to access 32×5000 Array{Float32,2} at index [Base.Slice(Base.OneTo(32)), 5001] Stacktrace: [1] throw_boundserror(::Array{Float32,2}, ::Tuple{Base.Slice{Base.OneTo{Int64}},Int64}) at . abstractarray.jl:538 [2] checkbounds at . abstractarray.jl:503 [inlined] [3] _getindex at . multidimensional.jl:669 [inlined] [4] getindex at . abstractarray.jl:981 [inlined] [5] embedding(::Array{Float32,2}, ::Array{Float64,1}) at C: Users shekh .julia packages TextAnalysis pcFQf src sentiment.jl:27 [6] (::TextAnalysis.var&#34;#24#25&#34;{Dict{Symbol,Any}})(::Array{Float64,1}) at C: Users shekh .julia packages TextAnalysis pcFQf src sentiment.jl:40 [7] get_sentiment(::TextAnalysis.var&#34;#26#27&#34;, ::Array{String,1}, ::Dict{Symbol,Any}, ::Dict{String,Any}) at C: Users shekh .julia packages TextAnalysis pcFQf src sentiment.jl:59 [8] (::TextAnalysis.SentimentModel)(::Function, ::Array{String,1}) at C: Users shekh .julia packages TextAnalysis pcFQf src sentiment.jl:87 [9] SentimentAnalyzer at C: Users shekh .julia packages TextAnalysis pcFQf src sentiment.jl:103 [inlined] (repeats 2 times) [10] top-level scope at . In[33]:28 . Ahh! Finally it&#39;s complete. . We get BoundsError: attempt to access 32×5000 Array{Float32,2} at index [Base.Slice(Base.OneTo(32)), 5001] error however on seeing this issue on TextAnalysis package. . Ref:BoundsError in sentiment analysis I&#39;ve decided to ignore it. Let&#39;s get on towards calculating our predictions metrices: Precision / F1Score / Recall. . $$P = frac{T_p}{T_p+F_p}$$ . $$R = frac{T_p}{T_p + F_n}$$ . $$ F1 = frac{2 cdot P cdot R}{P+ R} $$ . Precision . precision = tru_pos / (tru_pos + fal_pos) println(&quot;Precision is $precision&quot;) . Precision is 0.583117838593833 . recall = tru_pos / (tru_pos + fal_neg) println(&quot;Recall is $recall&quot;) . Recall is 0.5144996465068449 . f1score = (2 * precision * recall) / (precision + recall) #f1score is from 0 --&gt; 1 println(&quot;F1Score is $f1score.&quot;) . F1Score is 0.5466638895622987. . End of Report .",
            "url": "https://csblog.madhavshekhar.com/julia/ml/gci19/2020/01/14/Sentiment-Analysis-with-TextAnalysis(jl).html",
            "relUrl": "/julia/ml/gci19/2020/01/14/Sentiment-Analysis-with-TextAnalysis(jl).html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "[Kaggle] What's cooking ?",
            "content": "What&#8217;s cooking? - Kaggle Competition . . Note: Documentation and GitHub repository . In this project I aim to predict the category of a dish&#39;s cuisine given a list of its ingredients. . From the official desc. - . ‘’If you&#39;re in Northern California, you&#39;ll be walking past the inevitable bushels of leafy greens, spiked with dark purple kale and the bright pinks and yellows of chard. Across the world in South Korea, mounds of bright red kimchi greet you, while the smell of the sea draws your attention to squids squirming nearby. India’s market is perhaps the most colorful, awash in the rich hues and aromas of dozens of spices: turmeric, star anise, poppy seeds, and garam masala as far as the eye can see. Some of our strongest geographic and cultural associations are tied to a region&#39;s local foods.’’ . The public dataset is from the Kaggle competition, What’s for Dinner? The data is provided in JSON format. Each example in the dataset contains the recipe identification, type of cuisine and a list of ingredients. There are an average of 11 ingredients per recipe. The data consists of 39,774 unique recipes from 20 countries with 428,275 ingredients (6,714 unique). . Importing the required packages. . %matplotlib inline import pandas as pd import numpy as np import matplotlib as plt . Exploratory Data Analysis . data = pd.read_json(&#39;data/train.json&#39;, orient=&#39;records&#39;) . Number of recipes in the dataset. . print(&quot;Number of recipes:&quot;, len(data)) . Number of recipes: 39774 . Let&#39;s see the distribution of data in the file... For thi I&#39;ll see the first 10 rows. . data[:10] . cuisine id ingredients . 0 greek | 10259 | [romaine lettuce, black olives, grape tomatoes... | . 1 southern_us | 25693 | [plain flour, ground pepper, salt, tomatoes, g... | . 2 filipino | 20130 | [eggs, pepper, salt, mayonaise, cooking oil, g... | . 3 indian | 22213 | [water, vegetable oil, wheat, salt] | . 4 indian | 13162 | [black pepper, shallots, cornflour, cayenne pe... | . 5 jamaican | 6602 | [plain flour, sugar, butter, eggs, fresh ginge... | . 6 spanish | 42779 | [olive oil, salt, medium shrimp, pepper, garli... | . 7 italian | 3735 | [sugar, pistachio nuts, white almond bark, flo... | . 8 mexican | 16903 | [olive oil, purple onion, fresh pineapple, por... | . 9 italian | 12734 | [chopped tomatoes, fresh basil, garlic, extra-... | . Let&#39;s have a look at Matar Paneer (My favourite dish) . matar_paneer = (data[&#39;id&#39;] == 29172) data[matar_paneer][[&#39;ingredients&#39;]] . ingredients . 1517 [red chili powder, coriander powder, salt, oil... | . Cuisine Analysis . cuisine = data[&#39;cuisine&#39;].value_counts().index data[&#39;cuisine&#39;].value_counts() #Kagglers love Italian food i guess...lol . italian 7838 mexican 6438 southern_us 4320 indian 3003 chinese 2673 french 2646 cajun_creole 1546 thai 1539 japanese 1423 greek 1175 spanish 989 korean 830 vietnamese 825 moroccan 821 british 804 filipino 755 irish 667 jamaican 526 russian 489 brazilian 467 Name: cuisine, dtype: int64 . bargraph = data[&#39;cuisine&#39;].value_counts().plot(kind=&#39;bar&#39;,title=&quot;Cuisine Distribution by Countries&quot;) . Ingredient Analysis . Let&#39;s collect all the ingredients in a list and print few examples. . ingredientlist = [] for ingre in data[&#39;ingredients&#39;]: ingredientlist.extend(ingre) print(&quot;Total Inrgedients used : &quot;, len(ingredientlist)) print(&quot;Unique Ingredients : &quot;, len(set(ingredientlist)),&#39; n&#39;) for i in range(20): print(ingredientlist[i]) . Total Inrgedients used : 428275 Unique Ingredients : 6714 romaine lettuce black olives grape tomatoes garlic pepper purple onion seasoning garbanzo beans feta cheese crumbles plain flour ground pepper salt tomatoes ground black pepper thyme eggs green tomatoes yellow corn meal milk vegetable oil . Most used ingredients : . ingredients_series = pd.Series(ingredientlist) ax1 = ingredients_series.value_counts().head(15).plot(kind=&#39;bar&#39;, title=&#39;15 Most Used Ingredients&#39;) ax1.set_ylabel(&quot; Number of Recipes&quot;) . Text(0, 0.5, &#39; Number of Recipes&#39;) . Now, I&#39;m going to see how many cuisines use paneer and how many use tomatoes (random thought lol) . ingredients2 = data[&#39;ingredients&#39;].map(&quot;;&quot;.join) indices = ingredients2.str.contains(&#39;paneer&#39;) data[indices][&#39;cuisine&#39;].value_counts().plot(kind=&#39;bar&#39;, title=&#39;paneer as found per cuisine&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x1b422bed358&gt; . ingredients3 = data[&#39;ingredients&#39;].map(&quot;;&quot;.join) indices = ingredients2.str.contains(&#39;tomatoes&#39;) data[indices][&#39;cuisine&#39;].value_counts().plot(kind=&#39;bar&#39;, title=&#39;tomatoes as found per cuisine&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x1b422c6db38&gt; . Data cleaning . In the data, some of the ingredients have words describing some attributes of the underlying ingredient. . For example, &quot;chopped onions&quot; vs &quot;onions&quot; and &quot;canned coconut milk&quot; vs &quot;coconut milk&quot;. The words chopped and canned don&#39;t add any value to learning ; so we can remove the word &quot;chopped&quot; and &quot;cheese&quot; from these ingredients. . Another case &quot;garlic clove&quot; and &quot;garlic&quot;. In this case, we can&#39;t just remove &quot;clove&quot; since it is also a name of an ingredient. We deal with this case as mapping &quot;garlic clove&quot; to &quot;garlic&quot;. . Additionally, I&#39;ll convert the plurals into singlulars (eggs -&gt; egg) . Finally, we replace one than one spaces to a single space and remove space in the start and end. . import re def clean_ingredients(ingredientlist): words_to_remove = [&quot;lowfat&quot;, &quot;light&quot;, &quot;shredded&quot;, &quot;sliced&quot;, &quot;all purpose&quot;, &quot;all natural&quot;, &quot;natural&quot;, &quot;original&quot;, &quot;gourmet&quot;, &quot;traditional&quot;, &quot;boneless&quot;, &quot;skinless&quot;, &quot;fresh&quot;, &quot;nonfat&quot;, &quot;pitted&quot;, &quot;quick cooking&quot;, &quot;unbleached&quot;, &quot;part skim&quot;, &quot;skim&quot;, &quot;quickcooking&quot;, &quot;oven ready&quot;, &quot;homemade&quot;, &quot;instant&quot;, &quot;small&quot;, &quot;extra large&quot;, &quot;large&quot;, &quot;chopped&quot;, &quot;grated&quot;, &quot;cooked&quot;, &quot;stone ground&quot;, &quot;freshly ground&quot;, &quot;ground&quot;, &quot;pure&quot;, &quot;peeled&quot;, &quot;deveined&quot;, &quot;organic&quot;, &quot;cracked&quot;, &quot;granulated&quot;, &quot;inch thick&quot;, &quot;extra firm&quot;, &quot;crushed&quot;, &quot;flakes&quot;, &quot;self rising&quot;, &quot;diced&quot;, &quot;crumbles&quot;, &quot;crumbled&quot;, &quot;whole wheat&quot;, &quot;whole grain&quot;, &quot;baby&quot;, &quot;medium&quot;, &quot;plain&quot;, &quot;of&quot;, &quot;thick cut&quot;, &quot;cubed&quot;, &quot;coarse&quot;, &quot;free range&quot;, &quot;seasoned&quot;, &quot;canned&quot;, &quot;multipurpose&quot;, &quot;vegan&quot;, &quot;thawed&quot;, &quot;squeezed&quot;, &quot;vegetarian&quot;, &quot;fine&quot;, &quot;zesty&quot;, &quot;halves&quot;, &quot;firmly packed&quot;, &quot;drain&quot;, &quot;drained&quot;,&quot;canned&quot;, &quot;washed&quot;,&quot;smoked&quot;] map_plural_to_singular = [(&quot;steaks&quot;, &quot;steak&quot;), (&quot;loins&quot;, &quot;loin&quot;), (&quot;inches&quot;, &quot;inch&quot;), (&quot;centimeters&quot;, &quot;centimeter&quot;), (&quot;ounces&quot;, &quot;ounce&quot;), (&quot;liters&quot;, &quot;liter&quot;), (&quot;mililiters&quot;, &quot;mililiter&quot;), (&quot;grams&quot;, &quot;gram&quot;), (&quot;cups&quot;, &quot;cup&quot;), (&quot;gallons&quot;, &quot;gallon&quot;), (&quot;quarts&quot;, &quot;quart&quot;), (&quot;lbs&quot;, &quot;lb&quot;), (&quot;pounds&quot;, &quot;pound&quot;), (&quot;tablespoons&quot;, &quot;tablespoon&quot;), (&quot;teaspoons&quot;, &quot;teaspoon&quot;), (&quot;pints&quot;, &quot;pint&quot;), (&quot;fluid ounces&quot;, &quot;fluid ounce&quot;), (&quot;onions&quot;, &quot;onion&quot;), (&quot;cloves&quot;, &quot;clove&quot;), (&quot;bulbs&quot;, &quot;bulb&quot;), (&quot;peppers&quot;, &quot;pepper&quot;), (&quot;breasts&quot;, &quot;breast&quot;), (&quot;eggs&quot;, &quot;egg&quot;), (&quot;carrots&quot;, &quot;carrot&quot;), (&quot;mushrooms&quot;, &quot;mushroom&quot;), (&quot;tortillas&quot;, &quot;tortilla&quot;), (&quot;sausages&quot;, &quot;sausage&quot;), (&quot;wedges&quot;, &quot;wedge&quot;), (&quot;tomatoes&quot;, &quot;tomato&quot;), (&quot;thighs&quot;, &quot;thigh&quot;), (&quot;chilies&quot;, &quot;chili&quot;), (&quot;potatoes&quot;, &quot;potato&quot;), (&quot;peppercorns&quot;, &quot;peppercorn&quot;), (&quot;spices&quot;, &quot;spice&quot;), (&quot;chiles&quot;, &quot;chile&quot;), (&quot;apples&quot;, &quot;apple&quot;), (&quot;legs&quot;, &quot;leg&quot;), (&quot;doughs&quot;, &quot;dough&quot;), (&quot;drumsticks&quot;, &quot;drumstick&quot;)] phrases_to_map = [ ((&quot;green onion&quot;, &quot;red onion&quot;, &quot;purple onion&quot;, &quot;yellow onion&quot;, &quot;yel onion&quot;), &quot;onion&quot;), ((&quot;collard green leaves&quot;, &quot;collards&quot;, &quot;collard leaves&quot;), &quot;collard greens&quot;), (&quot;black pepper&quot;, &quot;pepper&quot;), (&quot;yel chives&quot;, &quot;chives&quot;), (&quot;spinach leaves&quot;, &quot;spinach&quot;), (&quot;tea leaves&quot;, &quot;tea&quot;), (&#39;Indian spice&#39;, &#39;garam masala&#39;), (&#39;catfish fillets&#39;,&#39;catfish&#39;), (&quot;chile&quot;, &quot;chili&quot;), ((&quot;garlic clove&quot;, &quot;garlic bulb&quot;), &quot;garlic&quot;), (&quot;uncooked&quot;, &quot;raw&quot;), (&#39;large eggs&#39;, &#39;eggs&#39;), ((&quot;red chili pepper&quot;, &quot;hot chili pepper&quot;, &quot;red hot chili pepper&quot;), &quot;chili pepper&quot;), ((&quot;baking potato&quot;, &quot;baked potato&quot;), &quot;baked potato&quot;), ((&quot;sea salt&quot;, &quot;kosher salt&quot;, &quot;table salt&quot;, &quot;white salt&quot;), &quot;salt&quot;), (&quot;scotch whiskey&quot;, &quot;scotch&quot;), ((&quot;i cant believe its not butter spread&quot;, &quot;i cant believe its not butter&quot;), &quot;butter&quot;), ((&quot;extra virgin olive oil&quot;, &quot;virgin olive oil&quot;), &quot;olive oil&quot;), ((&quot;white bread&quot;, &quot;wheat bread&quot;, &quot;grain bread&quot;), &quot;bread&quot;), ((&quot;white sugar&quot;, &quot;yel sugar&quot;), &quot;sugar&quot;), (&quot;confectioners sugar&quot;, &quot;powdered sugar&quot;) ] for i in range(len(ingredientlist)): for word in words_to_remove: ingredientlist[i] = re.sub(r&quot; b{} b&quot;.format(word), &quot;&quot;, ingredientlist[i]) for plural, singular in map_plural_to_singular: ingredientlist[i] = re.sub(r&quot; b{} b&quot;.format(plural), singular, ingredientlist[i]) for pattern, replacement in phrases_to_map: if type(pattern) is tuple: for val in pattern: ingredientlist[i] = re.sub(r&quot; b{} b&quot;.format(val), replacement, ingredientlist[i]) elif type(pattern) is str: ingredientlist[i] = re.sub(r&quot; b{} b&quot;.format(pattern), replacement, ingredientlist[i]) ingredientlist[i] = re.compile(r&quot; +&quot;).sub(&quot; &quot;, ingredientlist[i]) ingredientlist[i] = ingredientlist[i].strip() . Design Matrix and splitting the data . from sklearn.model_selection import train_test_split from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.preprocessing import LabelEncoder ingredients = [&#39; &#39;.join(ingredients).lower() for ingredients in data[&#39;ingredients&#39;]] cuisines = [cusine for cusine in data[&#39;cuisine&#39;]] clean_ingredients(ingredients) tfidf_enc = TfidfVectorizer(binary=True) lbl_enc = LabelEncoder() X = tfidf_enc.fit_transform(ingredients) X = X.astype(&#39;float16&#39;) Y = lbl_enc.fit_transform(cuisines) x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.05, random_state = 8888) print(&quot;x_train&quot;, x_train.shape) print(&quot;y_train&quot;, y_train.shape) print(&quot;x_test&quot;, x_test.shape) print(&quot;y_test&quot;, y_test.shape) . x_train (37785, 2970) y_train (37785,) x_test (1989, 2970) y_test (1989,) . Evaluation Matrix . will be utilised to interpret the accuracy in different cases ahead.. . from sklearn.metrics import confusion_matrix from sklearn.metrics import classification_report from matplotlib import pyplot def cm(y_test, y_pred, cuisines): pyplot.figure(figsize=(10, 10)) cm = confusion_matrix(y_test, y_pred) cm_normalized = cm.astype(&#39;float&#39;) / cm.sum(axis=1)[:, np.newaxis] pyplot.imshow(cm_normalized, interpolation=&#39;nearest&#39;) pyplot.title(&quot;confusion matrix&quot;) pyplot.colorbar(shrink=0.2) tick_marks = np.arange(len(cuisines)) pyplot.xticks(tick_marks, cuisines, rotation=90) pyplot.yticks(tick_marks, cuisines) pyplot.tight_layout() pyplot.ylabel(&#39;True label&#39;) pyplot.xlabel(&#39;Predicted label&#39;) print(classification_report(y_test, y_pred, target_names = cuisines)) . Vanilla Neural Network - Case 1 . Multi-layer Feedforward Neural Networks provide a natural extension to the multiclass problem. An MLP consists of at least three layers of nodes: an input layer, a hidden layer and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training. Its multiple layers and non-linear activation distinguish MLP from a linear perceptron. It can distinguish data that is not linearly separable. . &#39;&#39;&#39;from sklearn.neural_network import MLPClassifier from sklearn.metrics import accuracy_score mlp_clf = MLPClassifier(solver=&#39;lbfgs&#39;, alpha=1e-3, hidden_layer_sizes=(128, 64), random_state=1) mlp_clf.fit(x_train, y_train) y_pred1 = mlp_clf.predict(x_train) y_pred2 = mlp_clf.predict(x_test) print(&quot;Training accuracy:&quot;, accuracy_score(y_train, y_pred1)) print(&quot;Testing accuracy:&quot;, accuracy_score(y_test, y_pred2)) cm(y_test, y_pred2, cuisine) &#39;&#39;&#39; from sklearn.neural_network import MLPClassifier from sklearn.metrics import accuracy_score vnn = MLPClassifier(solver=&#39;lbfgs&#39;, alpha=1e-3, hidden_layer_sizes=(128,64), random_state=1) vnn.fit(x_train, y_train) predic1 = vnn.predict(x_train) predic2 = vnn.predict(x_test) print(&quot;Training Accuracy : &quot;, accuracy_score(y_train,predic1)) print(&quot;Test Accuracy : &quot;, accuracy_score(y_test, predic2)) . Training Accuracy : 0.8503903665475718 Test Accuracy : 0.7943690296631473 . #Confusion (Evaluation) Matrix cm(y_test, predic2, cuisine) . precision recall f1-score support italian 0.67 0.67 0.67 18 mexican 0.67 0.41 0.51 39 southern_us 0.77 0.62 0.69 74 indian 0.82 0.86 0.84 145 chinese 0.68 0.68 0.68 31 french 0.59 0.66 0.62 134 cajun_creole 0.92 0.73 0.81 63 thai 0.86 0.92 0.89 144 japanese 0.81 0.58 0.68 38 greek 0.84 0.88 0.86 404 spanish 0.77 0.71 0.74 14 korean 0.71 0.72 0.72 68 vietnamese 0.79 0.75 0.77 40 moroccan 0.94 0.91 0.92 345 british 0.87 0.76 0.81 45 filipino 0.41 0.41 0.41 22 irish 0.73 0.81 0.77 208 jamaican 0.63 0.61 0.62 51 russian 0.77 0.69 0.73 70 brazilian 0.55 0.64 0.59 36 micro avg 0.79 0.79 0.79 1989 macro avg 0.74 0.70 0.72 1989 weighted avg 0.80 0.79 0.79 1989 . Logistic Regression - Case 2 . binary classification algorithm using sigmoid function, . from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score from sklearn.model_selection import cross_val_score from sklearn.model_selection import GridSearchCV y_train = y_train.reshape(y_train.size) purpose = &#39;run&#39; #optimize or run(get best results) if purpose == &#39;optimize&#39;: lr = LogisticRegression(C=10) lr.fit(x_train, y_train) #cross-validation scores = cross_val_score(LogisticRegression(C=10), x_train ,y_train, cv=5) print(&quot;training accuracy: %0.4f (+/- %0.4f)&quot; % (scores.mean(), scores.std() * 2)) y_pred1 = lr.predict(x_test) print(&quot;testing accuracy before Grid Search (knowing the apt hyper-parameters:&quot;, accuracy_score(y_test, y_pred1)) #grid search parameters = {&#39;C&#39;:[0.1,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6,6.5,7,7.5,8,8.5,9,9.5,10]} lr_clf = GridSearchCV(lr, parameters) lr_clf.fit(x_train, y_train) # prediction y_pred2 = lr_clf.predict(x_test) print(&quot;testing accuracy after Grid Seach:&quot;, accuracy_score(y_test, y_pred2)) # best parameter in my run :- C=4.5 - test accuracy 80.1408% print(lr_clf.best_estimator_) else: print(&quot;--before optimization--&quot;) lr = LogisticRegression() lr.fit(x_train, y_train) y_pred1 = lr.predict(x_test) print(&quot;testing accuracy:&quot;, accuracy_score(y_test, y_pred1)) print(&quot;--after optimization--&quot;) lr_clf = LogisticRegression(C=4.5) lr_clf.fit(x_train, y_train) scores = cross_val_score(lr_clf, x_train ,y_train, cv=5) print(&quot;CV training accuracy: %0.4f (+/- %0.4f)&quot; % (scores.mean(), scores.std() * 2)) y_pred2 = lr_clf.predict(x_test) print(&quot;testing accuracy:&quot;, accuracy_score(y_test, y_pred2)) . --before optimization-- . C: Users shekh AppData Roaming Python Python37 site-packages sklearn linear_model logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) C: Users shekh AppData Roaming Python Python37 site-packages sklearn linear_model logistic.py:460: FutureWarning: Default multi_class will be changed to &#39;auto&#39; in 0.22. Specify the multi_class option to silence this warning. &#34;this warning.&#34;, FutureWarning) . testing accuracy: 0.7943690296631473 --after optimization-- . C: Users shekh AppData Roaming Python Python37 site-packages sklearn linear_model logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) C: Users shekh AppData Roaming Python Python37 site-packages sklearn linear_model logistic.py:460: FutureWarning: Default multi_class will be changed to &#39;auto&#39; in 0.22. Specify the multi_class option to silence this warning. &#34;this warning.&#34;, FutureWarning) . CV training accuracy: 0.7882 (+/- 0.0108) testing accuracy: 0.8009049773755657 . cm(y_test, y_pred2, cuisine) . precision recall f1-score support italian 1.00 0.61 0.76 18 mexican 0.60 0.38 0.47 39 southern_us 0.77 0.66 0.71 74 indian 0.84 0.88 0.86 145 chinese 0.68 0.61 0.64 31 french 0.63 0.65 0.64 134 cajun_creole 0.86 0.67 0.75 63 thai 0.86 0.93 0.90 144 japanese 0.79 0.50 0.61 38 greek 0.81 0.91 0.86 404 spanish 0.77 0.71 0.74 14 korean 0.79 0.68 0.73 68 vietnamese 0.86 0.78 0.82 40 moroccan 0.91 0.92 0.92 345 british 0.94 0.73 0.83 45 filipino 0.64 0.32 0.42 22 irish 0.70 0.84 0.76 208 jamaican 0.76 0.69 0.72 51 russian 0.78 0.77 0.78 70 brazilian 0.59 0.44 0.51 36 micro avg 0.80 0.80 0.80 1989 macro avg 0.78 0.68 0.72 1989 weighted avg 0.80 0.80 0.80 1989 . Decision Tree Classifier . from sklearn.tree import DecisionTreeClassifier from sklearn.metrics import accuracy_score rf_clf = DecisionTreeClassifier() rf_clf.fit(x_train, y_train) y_pred1 = rf_clf.predict(x_train) y_pred2 = rf_clf.predict(x_test) print(&quot;training accuracy:&quot;, accuracy_score(y_train, y_pred1)) print(&quot;testing accuracy:&quot;, accuracy_score(y_test, y_pred2)) cm(y_test, y_pred2, cuisine) . training accuracy: 0.9993648273124256 testing accuracy: 0.6535947712418301 precision recall f1-score support italian 0.39 0.39 0.39 18 mexican 0.30 0.33 0.32 39 southern_us 0.68 0.51 0.58 74 indian 0.72 0.69 0.71 145 chinese 0.41 0.45 0.43 31 french 0.43 0.46 0.45 134 cajun_creole 0.62 0.67 0.64 63 thai 0.82 0.77 0.79 144 japanese 0.39 0.32 0.35 38 greek 0.74 0.74 0.74 404 spanish 0.37 0.50 0.42 14 korean 0.57 0.54 0.56 68 vietnamese 0.58 0.70 0.64 40 moroccan 0.82 0.81 0.82 345 british 0.56 0.53 0.55 45 filipino 0.21 0.27 0.24 22 irish 0.62 0.63 0.62 208 jamaican 0.45 0.41 0.43 51 russian 0.64 0.67 0.66 70 brazilian 0.54 0.56 0.55 36 micro avg 0.65 0.65 0.65 1989 macro avg 0.54 0.55 0.54 1989 weighted avg 0.66 0.65 0.65 1989 . Random Forest . from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score y_train = y_train.reshape(y_train.size) rf_clf = RandomForestClassifier(n_estimators=1000, criterion = &#39;entropy&#39;, max_depth=20) rf_clf.fit(x_train, y_train) y_pred1 = rf_clf.predict(x_train) y_pred2 = rf_clf.predict(x_test) print(&quot;training accuracy:&quot;, accuracy_score(y_train, y_pred1)) print(&quot;testing accuracy:&quot;, accuracy_score(y_test, y_pred2)) cm(y_test,y_pred2,cuisine) . training accuracy: 0.7734286092364695 testing accuracy: 0.6601307189542484 precision recall f1-score support italian 0.00 0.00 0.00 18 mexican 0.00 0.00 0.00 39 southern_us 0.92 0.46 0.61 74 indian 0.71 0.93 0.80 145 chinese 1.00 0.26 0.41 31 french 0.70 0.17 0.28 134 cajun_creole 1.00 0.25 0.41 63 thai 0.84 0.89 0.86 144 japanese 0.00 0.00 0.00 38 greek 0.52 0.93 0.67 404 spanish 1.00 0.43 0.60 14 korean 0.89 0.47 0.62 68 vietnamese 1.00 0.42 0.60 40 moroccan 0.83 0.89 0.86 345 british 0.94 0.38 0.54 45 filipino 0.00 0.00 0.00 22 irish 0.48 0.69 0.57 208 jamaican 1.00 0.02 0.04 51 russian 0.82 0.77 0.79 70 brazilian 0.89 0.47 0.62 36 micro avg 0.66 0.66 0.66 1989 macro avg 0.68 0.42 0.46 1989 weighted avg 0.69 0.66 0.61 1989 . C: Users shekh AppData Roaming Python Python37 site-packages sklearn metrics classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. &#39;precision&#39;, &#39;predicted&#39;, average, warn_for) . Support Vector Machine . maximize the minimum distance from the separating hyperplane to the nearest example. I&#39;m trying to use ‘linearSVC + one-vs-rest(OVR) scheme’ and ‘SVC + one-vs-one scheme’ to solve this multi-class problem. . from sklearn import svm from sklearn.metrics import accuracy_score from sklearn.model_selection import cross_val_score from sklearn.model_selection import GridSearchCV y_train = y_train.reshape(y_train.size) purpose = &#39;run&#39; #optimize or run(get best results) if purpose == &#39;optimize&#39;: #****1.Linear SVM#**** lsvm = svm.LinearSVC(C=7) lsvm.fit(x_train, y_train) # cv scores = cross_val_score(svm.LinearSVC(C=7), x_train ,y_train, cv=5) print(&quot;training accuracy: %0.4f (+/- %0.4f)&quot; % (scores.mean(), scores.std() * 2)) y_pred1 = lsvm.predict(x_test) print(&quot;testing accuracy 1 before Grid Search:&quot;, accuracy_score(y_test, y_pred1)) # grid search parameters = {&#39;C&#39;:[0.1,0.5,1,2,3,4,5,6,7,8,9,10]} clf_svm1 = GridSearchCV(lsvm, parameters) clf_svm1.fit(x_train, y_train) # predict cuisines y_pred2 = clf_svm1.predict(x_test) print(&quot;testing accuracy 1 after Grid Seach:&quot;, accuracy_score(y_test, y_pred2)) #clf.get_params() #****2.SVM#**** # grid search param_grid = [{&#39;C&#39;: [0.1, 1, 10], &#39;kernel&#39;: [&#39;linear&#39;]},{&#39;C&#39;: [0.1, 1, 10], &#39;gamma&#39;: [0.001, 0.01, 0.1, 1], &#39;kernel&#39;: [&#39;rbf&#39;]},] svm_kern = svm.SVC() clf_svm2 = GridSearchCV(svm_kern, param_grid) clf_svm2.fit(x_train, y_train) svm_kern.fit(x_train, y_train) # predict cuisines y_pred3= clf_svm2.predict(x_test) print(&quot;testing accuracy 2 after Grid Seach:&quot;, accuracy_score(y_test, y_pred3)) #clf2.get_params() #****3.SVM extension#**** # extend parameter grid param_grid2 = [{&#39;C&#39;: [5, 10, 50, 100, 1000], &#39;gamma&#39;: [0.5, 1, 10, 100, 1000], &#39;kernel&#39;: [&#39;rbf&#39;]}] svm_kern_2 = svm.SVC() clf_svm3 = GridSearchCV(svm_kern_2, param_grid2) clf_svm3.fit(x_train, y_train) # predict cuisines y_pred4= clf_svm3.predict(x_test) print(&quot;testing accuracy 3 after Grid Seach:&quot;, accuracy_score(y_test, y_pred4)) #clf2.get_params() else: print(&quot;*-before optimization-*&quot;) lsvm = svm.LinearSVC() lsvm.fit(x_train, y_train) y_pred1 = lsvm.predict(x_test) print(&quot;testing accuracy:&quot;, accuracy_score(y_test, y_pred1)) print(&quot;*-after optimization-*&quot;) #best parameter C=10, gamma=1, kernel=&#39;rbf&#39; - - test accuracy 82.1016% svm_clf = svm.SVC(C = 10, kernel = &#39;rbf&#39;, gamma = 1) svm_clf.fit(x_train, y_train) scores = cross_val_score(svm_clf, x_train ,y_train, cv=5) print(&quot;CV training accuracy: %0.4f (+/- %0.4f)&quot; % (scores.mean(), scores.std() * 2)) y_pred2 = svm_clf.predict(x_test) print(&quot;testing accuracy:&quot;, accuracy_score(y_test, y_pred2)) cm(y_test, y_pred2, cuisine) . *-before optimization-* testing accuracy: 0.7998994469582705 *-after optimization-* CV training accuracy: 0.8044 (+/- 0.0085) testing accuracy: 0.8205128205128205 precision recall f1-score support italian 0.92 0.61 0.73 18 mexican 0.65 0.56 0.60 39 southern_us 0.81 0.70 0.75 74 indian 0.85 0.85 0.85 145 chinese 0.81 0.71 0.76 31 french 0.66 0.74 0.70 134 cajun_creole 0.83 0.78 0.80 63 thai 0.88 0.94 0.91 144 japanese 0.88 0.55 0.68 38 greek 0.83 0.91 0.87 404 spanish 0.71 0.71 0.71 14 korean 0.80 0.72 0.76 68 vietnamese 0.86 0.80 0.83 40 moroccan 0.93 0.91 0.92 345 british 0.89 0.73 0.80 45 filipino 0.83 0.45 0.59 22 irish 0.73 0.84 0.78 208 jamaican 0.82 0.63 0.71 51 russian 0.78 0.80 0.79 70 brazilian 0.68 0.64 0.66 36 micro avg 0.82 0.82 0.82 1989 macro avg 0.81 0.73 0.76 1989 weighted avg 0.82 0.82 0.82 1989 . FIN. .",
            "url": "https://csblog.madhavshekhar.com/ml/2019/12/30/where-is-the-chef-kaggle.html",
            "relUrl": "/ml/2019/12/30/where-is-the-chef-kaggle.html",
            "date": " • Dec 30, 2019"
        }
        
    
  
    
        ,"post8": {
            "title": "Benchmarking image processing frameworks",
            "content": "Benchmarking JuliaImages.jl . Using: . BenchmarkTools.jl | jl . timeit | py . Against : . OpenCV | Version used : 4.1.0 . scikit-image | Version used : 0.16.2 . (PIL using Pillow)[https://github.com/PseudoCodeNerd/codein-julia/blob/master/benchmark-openCV-JuliaImage/bench-3.ipynb] | Version used : 6.1.0 . Machine on which Benchmarks were carried out : . 64Bit Windows 10 with 16 GB of RAM and i5-7200U@2.5Ghz . Sample image from https://testimages.juliaimages.org/ . . Note : Compared mean times by timing only one sample in timeit. . #Getting the Required Packages using Images, ImageTransformations, FileIO, BenchmarkTools, TestImages . Test 1: Loading Image . @benchmark img = load(&quot;img/mountainstream.png&quot;) . BenchmarkTools.Trial: memory estimate: 3.39 MiB allocs estimate: 322 -- minimum time: 76.631 ms (0.00% GC) median time: 105.579 ms (0.00% GC) mean time: 110.319 ms (0.41% GC) maximum time: 209.470 ms (0.00% GC) -- samples: 46 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 110.319 | . OpenCV | 25.222 | . PIL | 0.248 | . $PIL &lt; OpenCV &lt; Images.jl$ . Test 2: Saving Image . img = load(&quot;img/mountainstream.png&quot;) @benchmark save(&quot;copy_julia.png&quot;, img) . BenchmarkTools.Trial: memory estimate: 3.39 MiB allocs estimate: 305 -- minimum time: 257.997 ms (0.00% GC) median time: 336.976 ms (0.00% GC) mean time: 316.100 ms (0.10% GC) maximum time: 368.297 ms (0.00% GC) -- samples: 16 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 316.1 | . OpenCV | 40.224 | . PIL | 174.674 | . $OpenCV &lt; PIL &lt; Images.jl$ . Test 3: Resizing Image . img = load(&quot;img/mountainstream.png&quot;) @benchmark big_img = imresize(img, ratio=5) . BenchmarkTools.Trial: memory estimate: 29.25 MiB allocs estimate: 6 -- minimum time: 324.998 ms (0.00% GC) median time: 344.478 ms (0.08% GC) mean time: 376.705 ms (4.31% GC) maximum time: 583.193 ms (0.00% GC) -- samples: 14 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 376.705 | . OpenCV | 33.105 | . PIL | 57.582 | . $ OpenCV &lt; PIL &lt; Images.jl$ . Test 4: Greyscaling Image . img = load(&quot;img/mountainstream.png&quot;) @benchmark gray_img = Gray.(img) . BenchmarkTools.Trial: memory estimate: 384.34 KiB allocs estimate: 8 -- minimum time: 1.790 ms (0.00% GC) median time: 2.021 ms (0.00% GC) mean time: 2.198 ms (1.84% GC) maximum time: 18.771 ms (0.00% GC) -- samples: 2264 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 2.198 | . OpenCV | 0.269 | . PIL | 0.985 | . $ OpenCV &lt; PIL &lt; Images.jl$ . Test 5: Applying Gaussian Blur . img = load(&quot;img/mountainstream.png&quot;) @benchmark gauss = imfilter(img, Kernel.gaussian(5)) . BenchmarkTools.Trial: memory estimate: 18.70 MiB allocs estimate: 603 -- minimum time: 39.857 ms (0.00% GC) median time: 42.566 ms (0.00% GC) mean time: 44.348 ms (4.84% GC) maximum time: 93.842 ms (0.00% GC) -- samples: 113 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 44.348 | . OpenCV | 4.007 | . PIL | 33.232 | . $ OpenCV &lt; PIL &lt; Images.jl$ . Test 6: Generating (Greyscale) Histogram . img = load(&quot;img/mountainstream.png&quot;) @benchmark edges, counts = imhist(img,256) . BenchmarkTools.Trial: memory estimate: 386.06 KiB allocs estimate: 5 -- minimum time: 19.395 ms (0.00% GC) median time: 20.976 ms (0.00% GC) mean time: 22.056 ms (0.10% GC) maximum time: 55.325 ms (0.00% GC) -- samples: 227 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 22.056 | . OpenCV | 1.29 | . PIL | 1.773 | . $ OpenCV &lt; PIL &lt; Images.jl$ . Test 7: Changing colorscale to HSV . img = load(&quot;img/mountainstream.png&quot;) @benchmark imghsv = HSV.(img) . BenchmarkTools.Trial: memory estimate: 4.50 MiB allocs estimate: 8 -- minimum time: 6.093 ms (0.00% GC) median time: 6.461 ms (0.00% GC) mean time: 7.373 ms (7.22% GC) maximum time: 64.638 ms (0.00% GC) -- samples: 677 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 7.373 | . OpenCV | 3.675 | . PIL | 22.607 | . $ OpenCV &lt; Images.jl &lt; PIL$ . Test 8: Calculating Integral Image . img = load(&quot;img/mountainstream.png&quot;) @benchmark integral_img = integral_image(img) . BenchmarkTools.Trial: memory estimate: 9.00 MiB allocs estimate: 7 -- minimum time: 4.437 ms (0.00% GC) median time: 5.785 ms (0.00% GC) mean time: 7.329 ms (16.98% GC) maximum time: 73.310 ms (13.81% GC) -- samples: 681 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 7.329 | . OpenCV | 0.226 | . scikit-image | 37.098 | . Note: PIL didn&#39;t have a method to calculate integral image. Benchmarked against scikit-image instead. . $ OpenCV &lt; Images.jl &lt; scikit-image$ . Test 9: Rotating Image (90 Degrees) . img = load(&quot;img/mountainstream.png&quot;) @benchmark rotated = imrotate(img, pi/2) . BenchmarkTools.Trial: memory estimate: 1.13 MiB allocs estimate: 5 -- minimum time: 16.047 ms (0.00% GC) median time: 16.682 ms (0.00% GC) mean time: 17.877 ms (0.82% GC) maximum time: 59.864 ms (0.00% GC) -- samples: 280 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 17.877 | . OpenCV | 4.317 | . PIL | 2.808 | . $ PIL &lt; OpenCV &lt; Images.jl$ . Test 10: Corner Detection using Harris Method . img = load(&quot;img/mountainstream.png&quot;) @benchmark corners = imcorner(img; method = harris) . BenchmarkTools.Trial: memory estimate: 70.88 MiB allocs estimate: 101873 -- minimum time: 75.884 ms (8.44% GC) median time: 83.419 ms (9.94% GC) mean time: 86.072 ms (10.41% GC) maximum time: 136.603 ms (24.07% GC) -- samples: 59 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 86.072 | . OpenCV | 22.802 | . scikit-image | 112.88 | . $ OpenCV &lt; Images.jl &lt; scikit-image$ . Task 11: Morphological Operation - Erode . img = load(&quot;img/mountainstream.png&quot;) @benchmark imge = erode(img, [5,5]) #over 5x5 1&#39;s Kernel . BenchmarkTools.Trial: memory estimate: 1.13 MiB allocs estimate: 3 -- minimum time: 405.601 μs (0.00% GC) median time: 512.500 μs (0.00% GC) mean time: 706.785 μs (23.49% GC) maximum time: 71.665 ms (99.14% GC) -- samples: 7020 evals/sample: 1 . Result: . Framework Time Taken (μs) . Images.jl | 706.785 | . OpenCV | 1190.893 | . scikit-image | 40561.481 | . $ Images.jl &lt; OpenCV &lt; scikit-image$ . Task 12: Morphological Operation - Opening . img = load(&quot;img/mountainstream.png&quot;) @benchmark imgc = closing(img, [5,5]) #over 5x5 1&#39;s Kernel . BenchmarkTools.Trial: memory estimate: 1.13 MiB allocs estimate: 3 -- minimum time: 408.499 μs (0.00% GC) median time: 469.999 μs (0.00% GC) mean time: 652.171 μs (22.81% GC) maximum time: 33.034 ms (0.00% GC) -- samples: 7595 evals/sample: 1 . Result: . Framework Time Taken (μs) . Images.jl | 652.171 | . OpenCV | 1587.633 | . scikit-image | 68730.478 | . $ Images.jl &lt; OpenCV &lt; scikit-image$ . Test 13: Morphological Operation - TopHat . img = load(&quot;img/mountainstream.png&quot;) @benchmark imgth = tophat(img, [9,9]) . BenchmarkTools.Trial: memory estimate: 2.25 MiB allocs estimate: 5 -- minimum time: 960.600 μs (0.00% GC) median time: 1.263 ms (0.00% GC) mean time: 1.687 ms (19.92% GC) maximum time: 28.826 ms (95.24% GC) -- samples: 2937 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 1.687 | . OpenCV | 1.82 | . scikit-image | 65.544 | . $ Images.jl &lt; OpenCV &lt; scikit-image$ . Test 14: Morphological Operation - BottomHat . img = load(&quot;img/mountainstream.png&quot;) @benchmark imgth = bothat(img, [9,9]) . BenchmarkTools.Trial: memory estimate: 2.25 MiB allocs estimate: 5 -- minimum time: 950.299 μs (0.00% GC) median time: 1.079 ms (0.00% GC) mean time: 1.482 ms (20.42% GC) maximum time: 23.362 ms (92.39% GC) -- samples: 3346 evals/sample: 1 . Result: . Framework Time Taken (ms) . Images.jl | 1.482 | . OpenCV | 1.913 | . scikit-image | 81.389 | . $ Images.jl &lt; OpenCV &lt; scikit-image$ . Test 15: Segmentation- Connected Components . img = load(&quot;img/mountainstream.png&quot;) @benchmark markers = label_components(img) . BenchmarkTools.Trial: memory estimate: 10.85 MiB allocs estimate: 70 -- minimum time: 9.715 ms (0.00% GC) median time: 10.430 ms (0.00% GC) mean time: 12.003 ms (9.84% GC) maximum time: 36.741 ms (58.12% GC) -- samples: 416 evals/sample: 1 . End of report. . Please accept now sir. .",
            "url": "https://csblog.madhavshekhar.com/julia/ml/gci19/2019/12/25/image-processing-benchmark.html",
            "relUrl": "/julia/ml/gci19/2019/12/25/image-processing-benchmark.html",
            "date": " • Dec 25, 2019"
        }
        
    
  
    
        ,"post9": {
            "title": "FashionMNIST with PyTorch & fastAI",
            "content": "Task Statement : . Fashion MNIST is a good way to introduce the concept of autoenoders and for classification tasks. Write an efficient Fashion MNIST implementation using Flux and benchmark it against equivalent implementations in TensorFlow and PyTorch. A good extension might be to have it run smoothly on GPUs too. The FashionMNIST dataset can be easily obtained and unpackaged into ready-to-use Julia data types with the help of MLDatasets.jl. A working example of using Flux for classification of handwritten digits from the MNIST dataset can be found here, for students who are already familiar with basic image detection techniques and want to hit the ground running. Flux&#39;s documentation can be found here. . I am going to use a pretrained (CNN) called resnet34. (Only thing I understood after watching first three fastAI lectures that use this thing for image-classification tasks.) Hoping to understand more theory by reading this article . But honestly, I don&#39;t know the complete theory behind a CNN myself. I&#39;m still trying to learn it from the lectures given in the Deep Learning Specialisation. I comletely know how to build simple multilayer perceptrons though and the theory behind them too. xD So I&#39;ll also try to make some of them on data-set. . Also the fastAI course followed a top-down approach to things, so yeah some concepts remain unclear but with reference to some of the image classification tasks we did in lectures 1 and 2 in the course, I was able to make this ! . Julia code will be submitted seperately. . P.S: Special thanks to my mentor Kartikey Gupta for all his support and his implementation in Keras which provided me a path to write the notebook. . . # This Python 3 environment comes with many helpful analytics libraries installed # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python # For example, here&#39;s several helpful packages to load in import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # Input data files are available in the &quot;../input/&quot; directory. # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname, _, filenames in os.walk(&#39;/kaggle/input&#39;): for filename in filenames: print(os.path.join(dirname, filename)) # Any results you write to the current directory are saved as output. import pandas as pd fmnist_test = pd.read_csv(&quot;../input/fashionmnist/fashion-mnist_test.csv&quot;) fmnist_train = pd.read_csv(&quot;../input/fashionmnist/fashion-mnist_train.csv&quot;) . /kaggle/input/fashionmnist/t10k-labels-idx1-ubyte /kaggle/input/fashionmnist/train-images-idx3-ubyte /kaggle/input/fashionmnist/fashion-mnist_train.csv /kaggle/input/fashionmnist/train-labels-idx1-ubyte /kaggle/input/fashionmnist/t10k-images-idx3-ubyte /kaggle/input/fashionmnist/fashion-mnist_test.csv . %reload_ext autoreload %autoreload 2 %matplotlib inline #autoreload reloads modules automatically before entering the execution of code typed. It is beneficial to update matplotlib functions # everytime a cell is run. . from fastai.imports import * . /opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release. from numpy.core.umath_tests import inner1d . from fastai.transforms import * from fastai.conv_learner import * from fastai.model import * from fastai.dataset import * from fastai.sgdr import * from fastai.plots import * import numpy as np import pandas as pd import matplotlib.pyplot as plt import os . torch.cuda.is_available() . True . torch.backends.cudnn.enabled . True . print(os.listdir(&#39;../input/&#39;)) PATH = &quot;../input/&quot; TMP_PATH = &quot;/tmp/tmp&quot; MODEL_PATH = &quot;/tmp/model/&quot; arch = resnet34 sz = 14 . [&#39;fashionmnist&#39;] . Data-Preprocessing . #collapse fmnist_test = pd.read_csv(&quot;../input/fashionmnist/fashion-mnist_test.csv&quot;) fmnist_train = pd.read_csv(&quot;../input/fashionmnist/fashion-mnist_train.csv&quot;) #Shape of the data-sets. print(f&#39;fmnist_train shape : {fmnist_train.shape}&#39;) #60,000 rows and 785 columns print(f&#39;fmnist_test shape : {fmnist_test.shape}&#39;) #10,000 rows and 785 columns #Seeing some of the data distribution. fmnist_train.head(7) . . fmnist_train shape : (60000, 785) fmnist_test shape : (10000, 785) . label pixel1 pixel2 pixel3 pixel4 pixel5 pixel6 pixel7 pixel8 pixel9 pixel10 pixel11 pixel12 pixel13 pixel14 pixel15 pixel16 pixel17 pixel18 pixel19 pixel20 pixel21 pixel22 pixel23 pixel24 pixel25 pixel26 pixel27 pixel28 pixel29 pixel30 pixel31 pixel32 pixel33 pixel34 pixel35 pixel36 pixel37 pixel38 pixel39 ... pixel745 pixel746 pixel747 pixel748 pixel749 pixel750 pixel751 pixel752 pixel753 pixel754 pixel755 pixel756 pixel757 pixel758 pixel759 pixel760 pixel761 pixel762 pixel763 pixel764 pixel765 pixel766 pixel767 pixel768 pixel769 pixel770 pixel771 pixel772 pixel773 pixel774 pixel775 pixel776 pixel777 pixel778 pixel779 pixel780 pixel781 pixel782 pixel783 pixel784 . 0 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 9 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 6 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 5 | 0 | 0 | 0 | 105 | 92 | 101 | 107 | 100 | 132 | 0 | 0 | 2 | 4 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 150 | ... | 211 | 220 | 214 | 74 | 0 | 255 | 222 | 128 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 44 | 12 | 0 | 0 | 40 | 134 | 162 | 191 | 214 | 163 | 146 | 165 | 79 | 0 | 0 | 0 | 30 | 43 | 0 | 0 | 0 | 0 | 0 | . 3 0 | 0 | 0 | 0 | 1 | 2 | 0 | 0 | 0 | 0 | 0 | 114 | 183 | 112 | 55 | 23 | 72 | 102 | 165 | 160 | 28 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 24 | 188 | 163 | 93 | ... | 171 | 249 | 207 | 197 | 202 | 45 | 0 | 3 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 22 | 21 | 25 | 69 | 52 | 45 | 74 | 39 | 3 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 4 3 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 46 | 0 | 21 | 68 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 25 | 187 | 189 | ... | 230 | 237 | 229 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 68 | 116 | 112 | 136 | 147 | 144 | 121 | 102 | 63 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 4 | 0 | 0 | 0 | 5 | 4 | 5 | 5 | 3 | 5 | 6 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 3 | 7 | 4 | 4 | 5 | 5 | 0 | 0 | 0 | 0 | 0 | 0 | 4 | 5 | 4 | 5 | 11 | 2 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 4 | 0 | 0 | 0 | 2 | 4 | 9 | 7 | 8 | 7 | 5 | 4 | 8 | 12 | 5 | 7 | 8 | 7 | 4 | 3 | 7 | 5 | 0 | 0 | 0 | . 6 4 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 159 | 161 | 143 | 180 | 142 | 21 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | ... | 255 | 231 | 241 | 217 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 7 | 36 | 50 | 51 | 68 | 48 | 48 | 33 | 14 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . As from we can see, the first column depicts the label of the image which, from the official repository of the data-set are: Labels | . Each training and test example is assigned to one of the following labels: . Label Description . 0 | T-shirt/top | . 1 | Trouser | . 2 | Pullover | . 3 | Dress | . 4 | Coat | . 5 | Sandal | . 6 | Shirt | . 7 | Sneaker | . 8 | Bag | . 9 | Ankle boot | . #I&#39;ll be now splitting 20% of the training data into validation data-set. fmnist_valid = fmnist_train.sample(frac=0.2) print(fmnist_valid.shape, &#39;| Shape of Validation Set&#39;) #Dropping the label&#39;s column since we would be predicting that. fmnist_train = fmnist_train.drop(fmnist_valid.index) print(fmnist_train.shape, &#39;| Shape Training Set&#39;) . (12000, 785) | Shape of Validation Set (48000, 785) | Shape Training Set . #Defining labels to predict labels = [&#39;T-shirt/top&#39;, &#39;Trouser&#39;, &#39;Pullover&#39;, &#39;Dress&#39;, &#39;Coat&#39;, &#39;Sandal&#39;, &#39;Shirt&#39;, &#39;Sneaker&#39;, &#39;Bag&#39;, &#39;Ankle boot&#39;] . #Getting the images as X (reshaping the images into 28x28) and labels (flattened) as y from the data-sets. (Changing the dimensions) def split(data): &#39;&#39;&#39;returns a tuple (X, y) where X : the training inputs which is in (samples, height, width, channel) shape y : flattened (one-D) label vector &#39;&#39;&#39; y = data[&#39;label&#39;].values.flatten() X = data.drop(&#39;label&#39;, axis=1).values X = X.reshape(X.shape[0], 28, 28) return (X,y) X_train, y_train = split(fmnist_train) X_valid, y_valid = split(fmnist_valid) X_test, y_test = split(fmnist_test) print(&quot;Training Set Shape&quot;) print(X_train.shape,&#39; n&#39;,y_train.shape) print(&quot;Validation Set Shape&quot;) print(X_valid.shape,&#39; n&#39;,y_valid.shape) print(&quot;Test Set Shape&quot;) print(X_test.shape,&#39; n&#39;,y_test.shape) . Training Set Shape (48000, 28, 28) (48000,) Validation Set Shape (12000, 28, 28) (12000,) Test Set Shape (10000, 28, 28) (10000,) . Some image processing tasks . Normalising image data (learnt here) Scaling the values of the individual pixels from 0-&gt;255 to 0-&gt;1 for reduced computational complexity. and adding image missing colour channels (don&#39;t understand this concept, saw this in many models on the same, will try to dig deep to learn more) . X_train = X_train.astype(&#39;float64&#39;) / 255 X_valid = X_valid.astype(&#39;float64&#39;) / 255 X_test = X_test.astype(&#39;float64&#39;) / 255 X_train = np.stack((X_train,) * 3, axis=-1) X_valid = np.stack((X_valid,) * 3, axis=-1) X_test = np.stack((X_test,) * 3, axis=-1) . Visualising a images. . using Matplotlib. . index = 42 #THE ANSWER TO LIFE, THE UNIVERSE AND EVERYTHING is a Pullover. plt.imshow(X_train[index,], cmap=&#39;gray&#39;) plt.title(labels[y_train[index]]) . Text(0.5,1,&#39;Pullover&#39;) . #Code inspiration from Kartikey&#39;s Keras implementation of the same plt.figure(figsize=(10, 10)) for i in range(25): plt.subplot(5, 5, i+1) plt.xticks([]) plt.yticks([]) plt.grid(False) plt.imshow(X_train[i], cmap=&#39;gray&#39;) plt.title(labels[y_train[i]]) plt.show() . Training the Model using pre-trained cnn (resnet34) . for 7 epochs . data = ImageClassifierData.from_arrays(PATH, trn=(X_train,y_train), classes=[0,1,2,3,4,5,6,7,8,9],val=(X_valid, y_valid), tfms=tfms_from_model(arch, 28), test=X_test) learn = ConvLearner.pretrained(arch, data, precompute=True, tmp_name=TMP_PATH, models_name=MODEL_PATH) learn.fit(7e-3, 3, cycle_len=1, cycle_mult=2) . Downloading: &#34;https://download.pytorch.org/models/resnet34-333f7ec4.pth&#34; to /root/.torch/models/resnet34-333f7ec4.pth 100%|██████████| 87306240/87306240 [00:01&lt;00:00, 82135118.30it/s] . 0%| | 0/750 [00:00&lt;?, ?it/s] . /opt/conda/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_. if hasattr(m, &#39;weight&#39;): init_fn(m.weight) . 100%|██████████| 750/750 [00:24&lt;00:00, 31.09it/s] 100%|██████████| 188/188 [00:05&lt;00:00, 31.42it/s] 100%|██████████| 157/157 [00:05&lt;00:00, 31.20it/s] epoch trn_loss val_loss accuracy 0 0.620987 0.512263 0.814333 1 0.578722 0.454397 0.832917 2 0.53767 0.445395 0.83925 3 0.525576 0.430741 0.841833 4 0.486124 0.414247 0.8485 5 0.494705 0.404226 0.853917 6 0.456214 0.398733 0.855167 . [0.3987334932486216, 0.8551666666666666] . We get around a 85.5517 which is good and not inflated like the 99% percent on MNIST data-sets. From what I&#39;ve scavenged from the web, the oneshot high accuracy of fast-ai library can be explained via: . TTA involves taking a series of different versions of the original image (for example cropping different areas, or changing the zoom) and passing them through the model. The average output is then calculated for the different versions and this is given as the final output score for the image. | Dropout combats overfitting and so would have proved crucial in winning on a relatively small dataset such at CIFAR10. Dropout is implemented automatically by fast ai when creating a learn object, though can be altered using the ps variable (not used here though) | log_predicns, _ = learn.TTA(is_test=True) prods = np.exp(log_predicns) prods = np.mean(prods, 0) accuracy_np(prods, y_test) . . 0.8565 . 0.8565. -&gt; 85.65 % . Some notes on accuracy vs precision in ML for my revision. begin{equation} accuracy= frac{TruePositive+TrueNegative}{TruePositive+TrueNegative+FalsePositive+FlaseNegative} end{equation} . -PseudoCodeNerd .",
            "url": "https://csblog.madhavshekhar.com/pytorch/ml/gci19/2019/12/23/FashionMNIST-with-pytorh-fastAI.html",
            "relUrl": "/pytorch/ml/gci19/2019/12/23/FashionMNIST-with-pytorh-fastAI.html",
            "date": " • Dec 23, 2019"
        }
        
    
  
    
        ,"post10": {
            "title": "FashionMNIST with FluxML",
            "content": "Task : Add the Fashion MNIST model to the Flux model-zoo . Task Description . Fashion MNIST is a good way to introduce the concept of autoenoders and for classification tasks. Write an efficient Fashion MNIST implementation using Flux and benchmark it against equivalent implementations in TensorFlow and PyTorch. A good extension might be to have it run smoothly on GPUs too. The FashionMNIST dataset can be easily obtained and unpackaged into ready-to-use Julia data types with the help of MLDatasets.jl. A working example of using Flux for classification of handwritten digits from the MNIST dataset can be found here, for students who are already familiar with basic image detection techniques and want to hit the ground running. Flux&#39;s documentation can be found here Another reference material that may interest you is this notebook that handles the FashionMNIST dataset using keras and tensorflow. . If you need GPUs for your task, I&#39;d recommend you to use NextJournal. If you need help setting up a Julia GPU session, just use the interactive chat icon in the bottom of the screen or contact one of the mentors on Slack. . I must explicitly say this that the code from the model zoo and other sources mentioned sources is solely for reference. Please do copy-paste code without writing proper comments or understanding the code. . Introduction . In this notebook I&#39;ll be using the Flux Machine Learning Package for Julia to build a simple multilayer perceptron to predict Zalando&#39;s articles images. Fashion-MNIST is a dataset of Zalando&#39;s article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Sample here: . Let&#39;s start by importing the required packages. . using Flux using Statistics using Flux: onehotbatch, onecold, crossentropy, throttle using Base.Iterators: repeated . ┌ Info: CUDAdrv.jl failed to initialize, GPU functionality unavailable (set JULIA_CUDA_SILENT or JULIA_CUDA_VERBOSE to silence or expand this message) └ @ CUDAdrv C: Users shekh .julia packages CUDAdrv mCr0O src CUDAdrv.jl:69 . Flux already has the FashionMNIST built in. Source. . #getting the data from Flux itself images = Flux.Data.FashionMNIST.images() labels = Flux.Data.FashionMNIST.labels(); # Example of a image and a label below. r = rand(1:60000) . 34399 . The corresponding image and label for this random data-point is. . images[r] . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; labels[r] #It&#39;s a dress. . 6 . For reference . Each training and test example is assigned to one of the following labels: . Label Description . 0 | T-shirt/top | . 1 | Trouser | . 2 | Pullover | . 3 | Dress | . 4 | Coat | . 5 | Sandal | . 6 | Shirt | . 7 | Sneaker | . 8 | Bag | . 9 | Ankle boot | . Our aim is to make our neural net predict the labels by looking at a 28x28 image. . Image Pre-Processing . We&#39;ll use hcat (behaves like numpy&#39;s reshape function) to stack the images into a single vector and onehotbatch to encode the categorical values into T/F&#39;s. . More about onehotbatch : One hot encoding allowed us to convert our categorical labels: &quot;Trouser&quot;, &quot;Dress&quot;, &quot;Coat&quot;, ... etc. into machine readable values; That is, if our label is &quot;Pullover&quot; in our result set, it would be one-hot encoded against the categories [&quot;T-shirt/top&quot;, &quot;Trouser&quot;, &quot;Pullover&quot;, &quot;Dress&quot;, &quot;Coat&quot;, &quot;Sandal&quot;, &quot;Shirt&quot;, &quot;Sneaker&quot;, &quot;Bag&quot;, &quot;Ankle boot&quot;]as [&quot;false&quot;, &quot;false&quot;, &quot;true&quot;, &quot;false&quot;, &quot;false&quot;, &quot;false&quot;, &quot;false&quot;, &quot;false&quot;, &quot;false&quot;]. In such a matrix, each column represents a one-hot encoded value of the label for the corresponding position in the vector. . X = hcat(float.(reshape.(images, :))...) Y = onehotbatch(labels, 0:9) . 10×60000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}: 0 1 1 0 1 0 0 0 0 0 1 0 0 … 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 … 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 . Creating our ML model (more a Neural Network with 2 layers) . Read more on Flux Layers. We&#39;ll be chaining two dense layers to go from a 28^2 dimensional space (28x28 images) to our predictions which will be 10 dimensional (0-9 types of articles.) . model = Chain(Dense(28^2, 32, relu), Dense(32, 10), softmax) . Chain(Dense(784, 32, relu), Dense(32, 10), softmax) . softmax : The Softmax regression is a activation function that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. In other words, softmax just converts output to probability distribution. Relu are another type of non-linear activation functions used actively in neural networks.It simply sets all negative values computed in the image to 0. The reason we do this, is because we want to introduce a non-linear function into our learning network that mimics very much what our eyes do when detecting images. There are other functions that do similar things such as sigmoid or tanh, which both mimic similar bounded functions, but relu seems to perform faster and gives good results. . See relu link to a Why/How answer on Stack. . In order to train our model in flux, we will require three functions as parameters: . an loss/objective function - allows the network to see how close we are to the result and used for gradient decent | an optimizer - a function that operates on the weight parameters of the network, to decrease the loss and drive gradient decent. | an evaluation function to show the progress of the training | Awesome documentation on Training from the Flux team here . Now, we write our loss function (we&#39;ll be using the log loss function/ better known as Cross-Entropy). The loss function measures the performance of a binary/multiclass classification model (latter, such as ours). Math behind it here . ADAM would be our optimizer function (it can be called a advanced, more powerful gradient descent but for neural networks). It is an adaptive learning rate method, which means, it computes individual learning rates for different parameters. ADAM . #1 loss(x, y) = crossentropy(model(x), y) #2 optim = ADAM(); #3 accuracy(x, y) = mean(onecold(model(x)) .== onecold(y)) # a way to find average of correct guesses in julia dataset = repeated((X,Y),200) # repeating the data set 200 times, as opposed to 200 epochs evalcb = () -&gt; @show(loss(X, Y)) # callback to show loss . #19 (generic function with 1 method) . Buckle up, because it&#39;s the time to train our (smol) model ! . #collapse Flux.train!(loss, params(model), dataset, optim, cb = throttle(evalcb, 10)); . . loss(X, Y) = 2.3620791f0 loss(X, Y) = 1.9865174f0 loss(X, Y) = 1.7601027f0 loss(X, Y) = 1.5901419f0 loss(X, Y) = 1.4566942f0 loss(X, Y) = 1.3407104f0 loss(X, Y) = 1.2393758f0 loss(X, Y) = 1.1476959f0 loss(X, Y) = 1.0679457f0 loss(X, Y) = 1.0048387f0 loss(X, Y) = 0.95166904f0 loss(X, Y) = 0.9043182f0 loss(X, Y) = 0.864224f0 loss(X, Y) = 0.8310807f0 loss(X, Y) = 0.8026322f0 loss(X, Y) = 0.77731687f0 loss(X, Y) = 0.75505835f0 loss(X, Y) = 0.735533f0 loss(X, Y) = 0.718016f0 loss(X, Y) = 0.70237654f0 loss(X, Y) = 0.6885812f0 loss(X, Y) = 0.67597306f0 loss(X, Y) = 0.66427284f0 loss(X, Y) = 0.6535298f0 loss(X, Y) = 0.64366955f0 loss(X, Y) = 0.63447034f0 loss(X, Y) = 0.62585896f0 loss(X, Y) = 0.6178082f0 loss(X, Y) = 0.61024f0 loss(X, Y) = 0.6030882f0 loss(X, Y) = 0.59633154f0 loss(X, Y) = 0.5899332f0 loss(X, Y) = 0.5838449f0 loss(X, Y) = 0.5780466f0 loss(X, Y) = 0.57251835f0 loss(X, Y) = 0.5672301f0 loss(X, Y) = 0.5621674f0 loss(X, Y) = 0.5573126f0 loss(X, Y) = 0.5526478f0 loss(X, Y) = 0.54815936f0 loss(X, Y) = 0.5438368f0 loss(X, Y) = 0.5396687f0 loss(X, Y) = 0.5356429f0 loss(X, Y) = 0.53175306f0 loss(X, Y) = 0.52798784f0 loss(X, Y) = 0.5243427f0 loss(X, Y) = 0.5208112f0 loss(X, Y) = 0.5173864f0 loss(X, Y) = 0.5140641f0 loss(X, Y) = 0.5108422f0 loss(X, Y) = 0.507718f0 loss(X, Y) = 0.50469106f0 loss(X, Y) = 0.5017531f0 loss(X, Y) = 0.4988968f0 loss(X, Y) = 0.49612027f0 loss(X, Y) = 0.4934218f0 loss(X, Y) = 0.49080032f0 loss(X, Y) = 0.4882532f0 loss(X, Y) = 0.48577672f0 loss(X, Y) = 0.4833668f0 loss(X, Y) = 0.4810206f0 loss(X, Y) = 0.47873574f0 loss(X, Y) = 0.47651094f0 loss(X, Y) = 0.4743407f0 loss(X, Y) = 0.47222245f0 loss(X, Y) = 0.47015327f0 loss(X, Y) = 0.46813557f0 . This took around 13 minutes to run on my potato PC. To make it faster we can do smarter things like batching which I have to still learn how to implement. . Testing our model. . The data-set also had a &#39;test&#39; set included on which we&#39;ll now be running our trained model ! . Let&#39;s see how that goes... . r = rand(1:12000) # a random data-point in the 12000 large test set. . 4597 . Flux.Data.FashionMNIST.images(:test)[r] #visualising . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Same image - preprocessing as used before but on the test set this time. . X_test = hcat(float.(reshape.(Flux.Data.FashionMNIST.images(:test), :))...) Y_test = onehotbatch(Flux.Data.FashionMNIST.labels(:test), 0:9); . Running our model on the X_test. . A 10-element array is returned with values between 0 to 1 (probabilities of catetgories being predicted). This means that the model means to say that the image inputted is 99.94% a trouser (0.9994) and 0.013% dress (0.00013). . model(X_test[:,r]) . 10-element Array{Float32,1}: 4.850774e-5 0.99945766 0.00018068193 0.00013932848 0.00017063053 1.0155961e-7 2.5855168e-6 3.8150286e-8 5.9667695e-7 2.269384e-8 . # We can use onecold to compare the true and predicted classes: onecold(model(X_test[:,r])) - 1 # the minus one is to account for julia&#39;s one-indexing. We start #from 0 but Julia&#39;s indexing start at 1. . 1 . 1 corresponds to Trouser and as we can see from the image above, it predicts correctly! . Results . Using accuracy . print(&quot;Train Accuracy : &quot;, accuracy(X,Y)*100, &quot; %&quot;) . Train Accuracy : 84.38166666666666 % . print(&quot;Test Accuracy : &quot;, accuracy(X_test,Y_test)*100,&quot; %&quot;) . Test Accuracy : 82.87 % . Based on the benchmarks provided by Zalando Research, our simple neural network ranks among the top 20% of the top accuracy ! . . -PseudoCodeNerd . P.S: 85.65% on the test set was achieved via the resnet34 pre-trained CNN by fastAI. Notebook attached. . Update . Adding a ConvNet . I say (heavily) influenced from https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl. . using Flux, Statistics using Flux: onehotbatch, onecold, crossentropy, throttle using Base.Iterators: repeated, partition using Printf, BSON . images = Flux.Data.FashionMNIST.images(); labels = Flux.Data.FashionMNIST.labels(); . #hide_output #Bundle images together with labels and group into minibatches. function make_minibatch(X, Y, idxs) X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs)) for i in 1:length(idxs) X_batch[:, :, :, i] = Float32.(X[idxs[i]]) end Y_batch = onehotbatch(Y[idxs], 0:9) return (X_batch, Y_batch) end batch_size = 128 mb_idxs = partition(1:length(images), batch_size) train_set = [make_minibatch(images, labels, i) for i in mb_idxs] . #hide_output test_imgs = Flux.Data.FashionMNIST.images(:test) test_labels = Flux.Data.FashionMNIST.labels(:test) test_set = make_minibatch(test_imgs, test_labels, 1:length(test_imgs)) . Now that we examined and prepared the data, we can now build our CNN to train the articles images on their corresponding labels. . There are 3 convulational layers, 3 maxPool layers, a dense layer and finally softmax to give a output in range of 0--&gt;1 . Convulated : The convolutional layer it convolves the article image with a cumulative result that learns the filter. Convolution is best explained as a a matrix traveling along another matrix and doing an element-wise multiplication against it to get a resulting convolved feature matrix. For further reading, check out this article that explains the convolution step very well with an animation of the convolution occuring between matrices. The Conv function below, takes the feature matrix dimensions as its first parameter. In other words, the first layer will use a 3x3 matrix and slide it over the image pixels to learn the feature detection filter. The first layer will produce 16 outputs from 1 input as indicated by 1=&gt;16 in the second parameter. The relu function, in the third parameter, is a function that simply sets all negative values computed in the image to 0. . Maxpool : After we apply the convolution layer, we apply another function called max pooling which helps reduce the dimensionality of the features that the network is learning, but still maintains the important feature information for learning. The pooling function in our neural network, slides a 2x2 matrix over different sections of the 2d input and pools them into a single value. So a 28 x 28 matrix pooled by a 2x2 pooling matrix would be reduced to a 14x14 matrix. The pooling function can be anything from max value, average, or sum. Max value is most commonly used, since it seems to be very effective. . Role of Abpve Layers :The first 6 layers (3C, 3 MP) are used for feature extraction in the image. hese layers take a 28x28 image input and aggregate into a simpler set of features representing the images. As more images are passed over these 4 layers, the feature extractor portion learns a simplified set of features from the images fed through it. This will make it much easier for the neural net to classify digits in the remaining part of the network . Dense :The reshape function&#39;s job is to get the pooled data into a form that the Dense neural net can process. The dense neural net takes 288 inputs from the last maxpool function and trains on the data to produce 10 outputs. The outputs are then subjected to the softmax function which essentially squashes the values to values between 0 and 1. All values produced by the softmax function will total 1. . The error between the output and actual label value will be fed back through the network to train the weights inside the network. This is called backpropogation. The deep learning uses a technique called gradient descent to adjust the weights of the network based on the error. As the network weights are adjusted with each new training dataset (image, label), the neural net model gets better and better at predicting the digit fed through it. . model = Chain( Conv((3, 3), 1=&gt;16, pad=(1,1), relu), MaxPool((2,2)), Conv((3, 3), 16=&gt;32, pad=(1,1), relu), MaxPool((2,2)), Conv((3, 3), 32=&gt;32, pad=(1,1), relu), MaxPool((2,2)), # Reshape 3d tensor into a 2d one, at this point it should be (3, 3, 32, N) # which is where we get the 288 in the `Dense` layer below: x -&gt; reshape(x, :, size(x, 4)), Dense(288, 10), softmax, ) . Chain(Conv((3, 3), 1=&gt;16, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 16=&gt;32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=&gt;32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), #7, Dense(288, 10), softmax) . # precompiling model before starting our training loop model(train_set[1][1]) # `loss()` calculates the crossentropy loss between our prediction `y_hat` # (calculated from `model(x)`) and the ground truth `y`. We augment the data # a bit, adding gaussian random noise to our image to make it more robust. function loss(x, y) # We augment `x` a little bit here, adding in random noise x_aug = x .+ 0.1f0*gpu(randn(eltype(x), size(x))) y_hat = model(x_aug) return crossentropy(y_hat, y) end accuracy(x, y) = mean(onecold(model(x)) .== onecold(y)) opt = ADAM(0.001) . ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}()) . best_acc = 0.0 last_improvement = 0 for curr_epoch in 1:100 global best_acc, last_improvement # Train for a single epoch Flux.train!(loss, params(model), train_set, opt) # Calculate accuracy. acc = accuracy(test_set...) @info(@sprintf(&quot;[%d]: Test accuracy: %.4f&quot;, curr_epoch, acc)) # If this is the best accuracy we&#39;ve seen so far, save the model out if acc &gt;= best_acc @info(&quot; New best accuracy! Saving model out to mnist_conv.bson&quot;) best_acc = acc last_improvement = curr_epoch end # If we haven&#39;t seen improvement in 5 epochs, drop our learning rate: if epoch_idx - last_improvement &gt;= 5 &amp;&amp; opt.eta &gt; 1e-6 opt.eta /= 10.0 @warn(&quot; Haven&#39;t improved in a while, dropping learning rate to $(opt.eta)!&quot;) # After dropping learning rate, give it a few epochs to improve last_improvement = epoch_idx end if epoch_idx - last_improvement &gt;= 10 @warn(&quot; converged.&quot;) break end end . ┌ Info: [1]: Test accuracy: 0.8214 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [2]: Test accuracy: 0.8493 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [3]: Test accuracy: 0.8625 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [4]: Test accuracy: 0.8650 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [5]: Test accuracy: 0.8727 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [6]: Test accuracy: 0.8720 └ @ Main In[29]:10 ┌ Info: [7]: Test accuracy: 0.8780 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [8]: Test accuracy: 0.8775 └ @ Main In[29]:10 ┌ Info: [9]: Test accuracy: 0.8760 └ @ Main In[29]:10 ┌ Info: [10]: Test accuracy: 0.8751 └ @ Main In[29]:10 ┌ Info: [11]: Test accuracy: 0.8805 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [12]: Test accuracy: 0.8835 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [13]: Test accuracy: 0.8831 └ @ Main In[29]:10 ┌ Info: [14]: Test accuracy: 0.8822 └ @ Main In[29]:10 ┌ Info: [15]: Test accuracy: 0.8825 └ @ Main In[29]:10 ┌ Info: [16]: Test accuracy: 0.8849 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [17]: Test accuracy: 0.8827 └ @ Main In[29]:10 ┌ Info: [18]: Test accuracy: 0.8843 └ @ Main In[29]:10 ┌ Info: [19]: Test accuracy: 0.8866 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [20]: Test accuracy: 0.8844 └ @ Main In[29]:10 ┌ Info: [21]: Test accuracy: 0.8830 └ @ Main In[29]:10 ┌ Info: [22]: Test accuracy: 0.8846 └ @ Main In[29]:10 ┌ Info: [23]: Test accuracy: 0.8858 └ @ Main In[29]:10 ┌ Info: [24]: Test accuracy: 0.8851 └ @ Main In[29]:10 ┌ Warning: -&gt; Haven&#39;t improved in a while, dropping learning rate to 0.0001! └ @ Main In[29]:29 ┌ Info: [25]: Test accuracy: 0.8983 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [26]: Test accuracy: 0.8993 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [27]: Test accuracy: 0.8978 └ @ Main In[29]:10 ┌ Info: [28]: Test accuracy: 0.8991 └ @ Main In[29]:10 ┌ Info: [29]: Test accuracy: 0.9004 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [30]: Test accuracy: 0.8993 └ @ Main In[29]:10 ┌ Info: [31]: Test accuracy: 0.8993 └ @ Main In[29]:10 ┌ Info: [32]: Test accuracy: 0.8993 └ @ Main In[29]:10 ┌ Info: [33]: Test accuracy: 0.8991 └ @ Main In[29]:10 ┌ Info: [34]: Test accuracy: 0.9006 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [35]: Test accuracy: 0.8999 └ @ Main In[29]:10 ┌ Info: [36]: Test accuracy: 0.8998 └ @ Main In[29]:10 ┌ Info: [37]: Test accuracy: 0.8989 └ @ Main In[29]:10 ┌ Info: [38]: Test accuracy: 0.8991 └ @ Main In[29]:10 ┌ Info: [39]: Test accuracy: 0.9011 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [40]: Test accuracy: 0.8999 └ @ Main In[29]:10 ┌ Info: [41]: Test accuracy: 0.9022 └ @ Main In[29]:10 ┌ Info: -&gt; New best accuracy! Saving model out to mnist_conv.bson └ @ Main In[29]:20 ┌ Info: [42]: Test accuracy: 0.8991 └ @ Main In[29]:10 ┌ Info: [43]: Test accuracy: 0.9015 └ @ Main In[29]:10 ┌ Info: [44]: Test accuracy: 0.9010 └ @ Main In[29]:10 ┌ Info: [45]: Test accuracy: 0.9001 └ @ Main In[29]:10 ┌ Info: [46]: Test accuracy: 0.8990 └ @ Main In[29]:10 ┌ Warning: -&gt; Haven&#39;t improved in a while, dropping learning rate to 1.0e-5! └ @ Main In[29]:29 ┌ Info: [47]: Test accuracy: 0.8988 └ @ Main In[29]:10 ┌ Info: [48]: Test accuracy: 0.8985 └ @ Main In[29]:10 ┌ Info: [49]: Test accuracy: 0.8988 └ @ Main In[29]:10 ┌ Info: [50]: Test accuracy: 0.8990 └ @ Main In[29]:10 ┌ Info: [51]: Test accuracy: 0.8987 └ @ Main In[29]:10 ┌ Warning: -&gt; Haven&#39;t improved in a while, dropping learning rate to 1.0000000000000002e-6! └ @ Main In[29]:29 ┌ Info: [52]: Test accuracy: 0.8991 └ @ Main In[29]:10 ┌ Info: [53]: Test accuracy: 0.8990 └ @ Main In[29]:10 ┌ Info: [54]: Test accuracy: 0.8990 └ @ Main In[29]:10 ┌ Info: [55]: Test accuracy: 0.8991 └ @ Main In[29]:10 . (Max) Accuracy achieved : 90.22. . Training time : 1:06:34 .",
            "url": "https://csblog.madhavshekhar.com/julia/ml/gci19/2019/12/23/FashionMNIST-with-FluxML.html",
            "relUrl": "/julia/ml/gci19/2019/12/23/FashionMNIST-with-FluxML.html",
            "date": " • Dec 23, 2019"
        }
        
    
  
    
        ,"post11": {
            "title": "Deploying Web Apps in Julia",
            "content": ". Preview at https://deploy-tutorial-plot.herokuapp.com/ In this blog, I’ll show how you can deploy a Dashboard written in Julia using Heroku, a free cloud storage platform. This is done under Google Code-In for Julia. . Task Statement . Deploy an instance of a dashboard created with Dashboards.jl and publish it to a free service like Heroku. Contribute instructions on how others can do this to Dashboards.jl. See this blog post for info on how to publish a web app in Julia. . This task is best done by someone who has already completed Create a sample dashboard with Dashboards.jl. . Background . The task states that the task is best done by someone who has already completed Create a sample dashboard with Dashboards.jl. I’d like to state that I did attempt to implement a dashboard written in python and put my life into it. However, the callback didn’t work and I couldn’t submit it. . But be assured, in the process of creating that Dashboard, I learnt all the fundamentals and am capable of guiding you in deploying your own dashboard (or webapp). . . Step 1 . In this tutorial, I’ll be deploying this dash file. Let’s get started… . Pre-requisites : . A Heroku Account | Your Files. (here, Dashboard files) | Julia Installation | Heroku CLI (Command Line Interface) | I have uploaded the files at my GitHub Repository. Check them out here. . Windows users may have problems with installing Heroku CLI on their systems. I too faced a problem with the %PATH% variables. I’d like to suggest you too install heroku-cli through scoop (a package manager). Here’s how to do it. . Install Scoop | $ scoop install heroku-cli | . After the CLI is succesfully installed, run: . $ heroku login . A browser window will open, prompting you to login to your heroku account using a single button. eazze right ? . . Step 2 . Create a new app through your Heroku Dashboard. Note that only names with letters and dashes are allowed. Once you’ve named it, return to your jolly old command prompt. We got stuff to do… . I’ll assume that we named our project deploy-tutorial-plot. . Don’t name this, it’s already the name of my app xD. . . Step 3 . I’m assuming that whatever app you’re trying to deploy, it’s already in it’s own Julia env folder with a Project.toml and Manifest.toml. Read this to know how to create an enivironment in Julia. . The Project and Manifestt .toml(s) contain information about your code: dependancies, versions, and author name. . Let’s take web_dash as the folder containing my files. Hop into your cmd now to intialize a git rep in your folder. . $ cd web_dash $ git init . Now, connect your Heroku app with you local folder. This can be done by running . $ git heroku git:remote -a deploy-tutorial-plot . Put your app’s name after -a. . . Step 4 . Now, to the working directory (here, your folder) add a Procfile. . A Procfile is a mechanism for declaring what commands are run by your application’s dynos on the Heroku platform. . web: julia --project web_dash.jl $PORT . Here, web_dash.jl is your app file name. $PORT represents the PORT number heroku will be using for your application. . At this point, your working directory must look like this: . Folder PATH listing for volume RAVENCLAW Volume serial number is B4F9-8664 C:. Manifest.toml Procfile Project.toml web_dash.jl . We still need to parse this PORT number on our script before starting the server. If we are using HTTP.jl we can replace the alreay existing hosting code in our file by the following : . Replace HTTP.Sockets.localhost with &quot;0.0.0.0&quot; . Replace /YOURPORTNUMBER/ with parse(Int,ARGS[1]) . Ultimately, the ending of must look like this: . handler = make_handler(app, debug = false) println(&quot;started at localhost:$(parse(Int, ARGS[1]))&quot;) HTTP.serve(handler,&quot;0.0.0.0&quot;,parse(Int,ARGS[1])) . Also, before putting up our files on the cloud, we need to tell Heroku what language we’re putting forwards. This is accomplished using a BuildPack. . Heroku Buildpacks determine the build process for an app, and which assets and runtimes should be made available to your code at runtime. Buildpacks enable you to extend Heroku’s build system to support your language or customizations, or to make particular binary packages available to the runtime. . Even though, Julia isn’t there on the Heroku Languages page; we have a julia-buildPack available at our disposal from here. . https://github.com/Optomatica/heroku-buildpack-julia.git . Paste this in buildpack row by moving to your app settings page on your heroku site. . . Final Step . Now, we’re ready to commit and deploy our plot by pushing to Heroku. . If you aren’t familiar with basic git commands to do this, please try to know them beforehand. . (Trust me, they’re really helpful! You won’t regret learning more about it…) . $ git status $ git add . $ git commit -m &quot;commit message&quot; $git push heroku master . This should prompt heroku to start building your web-app.Putting the results here too because I found i oddlySatisfying. . Enumerating objects: 6, done. Counting objects: 100% (6/6), done. Delta compression using up to 4 threads Compressing objects: 100% (5/5), done. Writing objects: 100% (6/6), 6.47 KiB | 947.00 KiB/s, done. Total 6 (delta 0), reused 0 (delta 0) remote: Compressing source files... done. remote: Building source: remote: remote: --&gt; Julia app detected remote: --&gt; Installing julia .... - julia-1.3.0-linux-x86_64.tar.gz . . . remote: --&gt; Compressing... remote: Done: 364.6M remote: --&gt; Launching... remote: ! Warning: Your slug size (364 MB) exceeds our soft limit (300 MB) which may affect boot time. remote: Released v3 remote: https://deploy-tutorial-plot.herokuapp.com/ deployed to Heroku remote: remote: Verifying deploy... done. To https://git.heroku.com/deploy-tutorial-plot.git * [new branch] master -&gt; master . Phew, so if everything went awesome on your part too, you can see your app hosted at [app-name.herokuapp.com](https://deploy-tutorial-plot.herokuapp.com/). . I hope that you found this tutorial helpful. . Cheerio! . . Hosted App . Files on GitHub .",
            "url": "https://csblog.madhavshekhar.com/gci19/2019/12/10/deplying_dashboards_heroku.html",
            "relUrl": "/gci19/2019/12/10/deplying_dashboards_heroku.html",
            "date": " • Dec 10, 2019"
        }
        
    
  
    
        ,"post12": {
            "title": "Email spam classifier from scratch",
            "content": "Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems . Chapter 3: Classification . Exercise: Question 3 . Problem Statement: Build a spam classifier ( a more challenging experience) . Download examples of spam and ham from Apaches SpamAssasin&#39;s Public DataSet. | Unzip data and familiarize yourself with data format. | Split data-sets into training and test. | Write a data preparation pipeline to convert each email into a feature vector. The pipeline should transform email into a (sparse) vector that indicates presence or absence of each possible word. | You may add hyperparameters to prep. pipeline to control whether or not to strip of email header, convert mail to lowercase, remove punctuation, replace URLS with &quot;url&quot;, replace all numbers with &quot;NUM&quot; or do stemming. | . {Optional}, try out several classifiers and see if you can build a great spam classifier, with high recall and precision . Official Data Desc. . spam: 500 spam messages, all received from non-spam-trap sources. . | easy_ham: 2500 non-spam messages. These are typically quite easy to differentiate from spam, since they frequently do not contain any spammish signatures (like HTML etc). . | hard_ham: 250 non-spam messages which are closer in many respects to typical spam: use of HTML, unusual HTML markup, coloured text, &quot;spammish-sounding&quot; phrases etc. . | easy_ham_2: 1400 non-spam messages. A more recent addition to the set. . | spam_2: 1397 spam messages. Again, more recent. . | . Total count: 6047 messages, with about a 31% spam ratio . import tarfile import os import urllib down_path = &quot;http://spamassassin.apache.org/old/publiccorpus/&quot; ham_url = down_path + &quot;20030228_easy_ham.tar.bz2&quot; spam_url = down_path + &quot;20030228_spam.tar.bz2&quot; spam_path = os.path.join(&quot;datasets&quot;, &quot;spam&quot;) def fetch_spam_data(spam_url=spam_url, spam_path=spam_path): if not os.path.isdir(spam_path): os.makedirs(spam_path) for filename, url in ((&quot;ham.tar.bz2&quot;, ham_url), (&quot;spam.tar.bz2&quot;, spam_url)): path = os.path.join(spam_path, filename) if not os.path.isfile(path): urllib.request.urlretrieve(url, path) tar_bz2_file = tarfile.open(path) tar_bz2_file.extractall(path=spam_path) tar_bz2_file.close() . fetch_spam_data() . ham_directory = os.path.join(spam_path, &quot;easy_ham&quot;) spam_directory = os.path.join(spam_path, &quot;spam&quot;) ham_filenames = [name for name in sorted(os.listdir(ham_directory)) if len(name) &gt; 20] spam_filenames = [name for name in sorted(os.listdir(spam_directory)) if len(name) &gt; 20] . print(len(ham_filenames)) print(len(spam_filenames)) . 2500 500 . #using email module and policy function (in email) in python to parse mails import email import email.policy def get_mails(is_spam, file, spam_path=spam_path): if is_spam: directory = &quot;spam&quot; else: directory = &quot;easy_ham&quot; with open(os.path.join(spam_path, directory, file), &quot;rb&quot;) as f: return email.parser.BytesParser(policy=email.policy.default).parse(f) ham_emails = [get_mails(is_spam=False, file=name) for name in ham_filenames] spam_emails = [get_mails(is_spam=True, file=name) for name in spam_filenames] . print(ham_emails[42].get_content().strip()) . &lt; &gt; &gt; I downloaded a driver from the nVidia website and installed it using RPM. &gt; Then I ran Sax2 (as was recommended in some postings I found on the net), but &gt; it still doesn&#39;t feature my video card in the available list. What next? hmmm. Peter. Open a terminal and as root type lsmod you want to find a module called NVdriver. If it isn&#39;t loaded then load it. #insmod NVdriver.o Oh and ensure you have this module loaded on boot.... else when you reboot you might be in for a nasty surprise. Once the kernel module is loaded #vim /etc/X11/XF86Config in the section marked Driver I have &#34;NeoMagic&#34; you need to have Driver &#34;nvidia&#34; Here is part of my XF86Config Also note that using the card you are using you &#39;should&#39; be able to safely use the FbBpp 32 option . Section &#34;Module&#34; Load &#34;extmod&#34; Load &#34;xie&#34; Load &#34;pex5&#34; Load &#34;glx&#34; SubSection &#34;dri&#34; #You don&#39;t need to load this Peter. Option &#34;Mode&#34; &#34;666&#34; EndSubSection Load &#34;dbe&#34; Load &#34;record&#34; Load &#34;xtrap&#34; Load &#34;speedo&#34; Load &#34;type1&#34; EndSection #Plus the Modelines for your monitor should be singfinicantly different. Section &#34;Monitor&#34; Identifier &#34;Monitor0&#34; VendorName &#34;Monitor Vendor&#34; ModelName &#34;Monitor Model&#34; HorizSync 28.00-35.00 VertRefresh 43.00-72.00 Modeline &#34;800x600&#34; 36 800 824 896 1024 600 601 603 625 Modeline &#34;1024x768&#34; 49 1024 1032 1176 1344 768 771 777 806 EndSection Section &#34;Device&#34; Identifier &#34;Card0&#34; Driver &#34;neomagic&#34; #Change this to &#34;nvidia&#34;... making sure the modules are in the correct path VendorName &#34;Neomagic&#34; # &#34;Nvidia&#34; BoardName &#34;NM2160&#34; BusID &#34;PCI:0:18:0&#34; EndSection Section &#34;Screen&#34; Identifier &#34;Screen0&#34; Device &#34;Card0&#34; Monitor &#34;Monitor0&#34; DefaultDepth 24 SubSection &#34;Display&#34; Depth 1 EndSubSection SubSection &#34;Display&#34; Depth 4 EndSubSection SubSection &#34;Display&#34; Depth 8 EndSubSection SubSection &#34;Display&#34; Depth 15 EndSubSection SubSection &#34;Display&#34; Depth 16 EndSubSection SubSection &#34;Display&#34; Depth 24 #FbBpp 32 #Ie you should be able lto uncomment this line Modes &#34;1024x768&#34; &#34;800x600&#34; &#34;640x480&#34; # And add in higher resulutions as desired. EndSubSection EndSection -- Irish Linux Users&#39; Group: ilug@linux.ie http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information. List maintainer: listmaster@linux.ie . print(spam_emails[42].get_content().strip()) . Help wanted. We are a 14 year old fortune 500 company, that is growing at a tremendous rate. We are looking for individuals who want to work from home. This is an opportunity to make an excellent income. No experience is required. We will train you. So if you are looking to be employed from home with a career that has vast opportunities, then go: http://www.basetel.com/wealthnow We are looking for energetic and self motivated people. If that is you than click on the link and fill out the form, and one of our employement specialist will contact you. To be removed from our link simple go to: http://www.basetel.com/remove.html 7749doNL1-136DfsE5701lGxl2-486pAKM7127JwoR4-054PCfq9499xMtW0-594hucS91l66 . Some emails are actually multipart, with images and attachments. Let&#39;s look at the various types of structures. . def email_structure(email): if isinstance(email, str): return email payload = email.get_payload() if isinstance(payload, list): return &quot;multipart({})&quot;.format(&quot;, &quot;.join([ email_structure(sub_email) for sub_email in payload ])) else: return email.get_content_type() from collections import Counter def structure_count(emails): structures = Counter() for email in emails: structure = email_structure(email) structures[structure] += 1 return structures . structure_count(ham_emails).most_common() . [(&#39;text/plain&#39;, 2408), (&#39;multipart(text/plain, application/pgp-signature)&#39;, 66), (&#39;multipart(text/plain, text/html)&#39;, 8), (&#39;multipart(text/plain, text/plain)&#39;, 4), (&#39;multipart(text/plain)&#39;, 3), (&#39;multipart(text/plain, application/octet-stream)&#39;, 2), (&#39;multipart(text/plain, text/enriched)&#39;, 1), (&#39;multipart(text/plain, application/ms-tnef, text/plain)&#39;, 1), (&#39;multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)&#39;, 1), (&#39;multipart(text/plain, video/mng)&#39;, 1), (&#39;multipart(text/plain, multipart(text/plain))&#39;, 1), (&#39;multipart(text/plain, application/x-pkcs7-signature)&#39;, 1), (&#39;multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)&#39;, 1), (&#39;multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))&#39;, 1), (&#39;multipart(text/plain, application/x-java-applet)&#39;, 1)] . structure_count(spam_emails).most_common() . [(&#39;text/plain&#39;, 218), (&#39;text/html&#39;, 183), (&#39;multipart(text/plain, text/html)&#39;, 45), (&#39;multipart(text/html)&#39;, 20), (&#39;multipart(text/plain)&#39;, 19), (&#39;multipart(multipart(text/html))&#39;, 5), (&#39;multipart(text/plain, image/jpeg)&#39;, 3), (&#39;multipart(text/html, application/octet-stream)&#39;, 2), (&#39;multipart(text/plain, application/octet-stream)&#39;, 1), (&#39;multipart(text/html, text/plain)&#39;, 1), (&#39;multipart(multipart(text/html), application/octet-stream, image/jpeg)&#39;, 1), (&#39;multipart(multipart(text/plain, text/html), image/gif)&#39;, 1), (&#39;multipart/alternative&#39;, 1)] . we can see that spam has got quite a lot HTML and plain text (either together or individualy) ham mails are often plain text and are signed using PGP (spam isn&#39;t). Concretely, email structure appears to be an important feature in classification . #email_headers for header, value in spam_emails[42].items(): print(header,&quot;--&gt;&quot;,value) . Return-Path --&gt; &lt;bill@bluemail.dk&gt; Delivered-To --&gt; zzzz@localhost.spamassassin.taint.org Received --&gt; from localhost (localhost [127.0.0.1]) by phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 98B7343F99 for &lt;zzzz@localhost&gt;; Mon, 26 Aug 2002 10:12:43 -0400 (EDT) Received --&gt; from mail.webnote.net [193.120.211.219] by localhost with POP3 (fetchmail-5.9.0) for zzzz@localhost (single-drop); Mon, 26 Aug 2002 15:12:43 +0100 (IST) Received --&gt; from smtp.easydns.com (smtp.easydns.com [205.210.42.30]) by webnote.net (8.9.3/8.9.3) with ESMTP id TAA11952; Fri, 23 Aug 2002 19:49:56 +0100 From --&gt; bill@bluemail.dk Received --&gt; from bluemail.dk (klhtnet.klht.pvt.k12.ct.us [206.97.9.2]) by smtp.easydns.com (Postfix) with SMTP id 754E52CFFB; Fri, 23 Aug 2002 14:49:52 -0400 (EDT) Reply-To --&gt; bill@bluemail.dk Message-ID --&gt; &lt;003d35d40cab$6883b2c8$6aa10ea4@khnqja&gt; To --&gt; byrt5@hotmail.com Subject --&gt; FORTUNE 500 COMPANY HIRING, AT HOME REPS. MiME-Version --&gt; 1.0 Content-Type --&gt; text/plain; charset=&#34;iso-8859-1&#34; X-Priority --&gt; 3 (Normal) X-MSMail-Priority --&gt; Normal X-Mailer --&gt; Microsoft Outlook Express 6.00.2462.0000 Importance --&gt; Normal Date --&gt; Fri, 23 Aug 2002 14:49:52 -0400 Content-Transfer-Encoding --&gt; 8bit . a networking guy would assure you that this in-fact is an overload of info which can be used for effective classification however, i gotta read some of these headers up to get more background info on how spam affects the headers... For now lets just figure stuff out from the &quot;Subject&quot; header. . spam_emails[42][&quot;Subject&quot;] . &#39;FORTUNE 500 COMPANY HIRING, AT HOME REPS.&#39; . import numpy as np from sklearn.model_selection import train_test_split X = np.array(ham_emails + spam_emails) y = np.array([0] * len(ham_emails) + [1] * len(spam_emails)) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) . Feature-Engineering . #ToDo #- Convert HTML to plain text (using BS4 or regex) import re from html import unescape def htmlTOtext(html): text = re.sub(&#39;&lt;head.*?&gt;.*?&lt;/head&gt;&#39;, &#39;&#39;, html, flags=re.M | re.S | re.I) text = re.sub(&#39;&lt;a s.*?&gt;&#39;, &#39; HYPERLINK &#39;, text, flags=re.M | re.S | re.I) text = re.sub(&#39;&lt;.*?&gt;&#39;, &#39;&#39;, text, flags=re.M | re.S) text = re.sub(r&#39;( s* n)+&#39;, &#39; n&#39;, text, flags=re.M | re.S) return unescape(text) . #checking htmlTOtext htmlSPAM = [] for email in X_train[y_train==1]: if email_structure(email) == &quot;text/html&quot;: htmlSPAM.append(email) sampleSPAM = htmlSPAM[5] print(sampleSPAM.get_content().strip()[:1000], &quot;...&quot;) . &lt;html&gt;&lt;body&gt;&lt;center&gt; &lt;table bgcolor=&#34;663399&#34; border=&#34;2&#34; width=&#34;999&#34; cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt; &lt;tr&gt; &lt;td colspan=&#34;3&#34; width=&#34;999&#34;&gt; &lt;hr&gt;&lt;font color=&#34;yellow&#34;&gt; &lt;center&gt; &lt;font size=&#34;7&#34;&gt; &lt;br&gt;&lt;center&gt;&lt;b&gt;Get 12 FREE VHS or DVDs! &lt;/b&gt;&lt;br&gt; &lt;table bgcolor=&#34;white&#34; border=&#34;2&#34; width=&#34;500&#34;&gt; &lt;tr&gt; &lt;td&gt; &lt;font size=&#34;7&#34;&gt; &lt;font color=&#34;003399&#34;&gt;&lt;center&gt;Click &lt;a href=&#34;http://www.bozomber.com/porno/index.html&#34;&gt; HERE For Details!&lt;/a&gt; &lt;font size=&#34;5&#34;&gt;&lt;br&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; &lt;br&gt; &lt;table bgcolor=&#34;#CCFF33&#34; border=&#34;2&#34; width=&#34;600&#34;&gt; &lt;tr&gt; &lt;td&gt;&lt;center&gt;&lt;center&gt;&lt;font size=&#34;6&#34;&gt;&lt;font color=&#34;6633CC&#34;&gt;&lt;br&gt; We Only Have HIGH QUALITY &lt;br&gt;Porno Movies to Choose From!&lt;br&gt;&lt;br&gt; &#34;This is a &lt;i&gt;VERY SPECIAL, LIMITED TIME OFFER&lt;/i&gt;.&#34;&lt;br&gt;&lt;br&gt; Get up to 12 DVDs absolutely FREE,&lt;br&gt; with&lt;a href=&#34;http://www.bozomber.com/porno/index.html&#34;&gt; NO COMMITMENT!&lt;/a&gt; &lt;br&gt;&lt;br&gt; There&#39;s &lt;b&gt;no better deal anywhere&lt;/b&gt;.&lt;br&gt; There&#39;s &lt;i&gt;no catches&lt;/i&gt; and &lt;i&gt;no gimmicks&lt;/i&gt;. &lt;br&gt;You only pay for the shipping,&lt;br&gt; and the DVDs ... . print(htmlTOtext(sampleSPAM.get_content())[:1000], &quot;...&quot;) . Get 12 FREE VHS or DVDs! Click HYPERLINK HERE For Details! We Only Have HIGH QUALITY Porno Movies to Choose From! &#34;This is a VERY SPECIAL, LIMITED TIME OFFER.&#34; Get up to 12 DVDs absolutely FREE, with HYPERLINK NO COMMITMENT! There&#39;s no better deal anywhere. There&#39;s no catches and no gimmicks. You only pay for the shipping, and the DVDs are absolutely free! Take a Peak at our HYPERLINK Full Catalog! High quality cum filled titles such as: HYPERLINK 500 Oral Cumshots 5 Description: 500 Oral Cum Shots! I need hot jiz on my face! Will you cum in my mouth? Dozens of Dirty Hardcore titles such as: HYPERLINK Amazing Penetrations No. 17 Description: 4 full hours of amazing penetrations with some of the most beautiful women in porn! From our &#34;Sexiest Innocent Blondes&#34; collections: HYPERLINK Audition Tapes Description: Our girls go from cute, young and innocent, to screaming sex goddess beggin&#39; to have massive cocks in their tight, wet pussies and asses! ... . #Great! Now let&#39;s write a function that takes an email as input and returns its content as plain text, whatever its format is: def emailTOtext(email): html = None for part in email.walk(): ctype = part.get_content_type() if not ctype in (&quot;text/plain&quot;, &quot;text/html&quot;): continue try: content = part.get_content() except: # in case of encoding issues content = str(part.get_payload()) if ctype == &quot;text/plain&quot;: return content else: html = content if html: return htmlTOtext(html) . NSFW Below . not me, but the data is NSFW . print(emailTOtext(sampleSPAM)[:100], &quot;...&quot;) . Get 12 FREE VHS or DVDs! Click HYPERLINK HERE For Details! We Only Have HIGH QUALITY Porno Movi ... . let&#39;s do more text preprocessing, technically-&gt; stemming . import nltk stemmer = nltk.PorterStemmer() for word in (&quot;Computations&quot;, &quot;Computation&quot;, &quot;Computing&quot;, &quot;Computed&quot;, &quot;Compute&quot;, &quot;Compulsive&quot;,&quot;Technology&quot;,&quot;Convulated&quot;): print(word, &quot;--&gt;&quot;, stemmer.stem(word)) . Computations --&gt; comput Computation --&gt; comput Computing --&gt; comput Computed --&gt; comput Compute --&gt; comput Compulsive --&gt; compuls Technology --&gt; technolog Convulated --&gt; convul . let&#39;s also do as the problem statement says and change all URLS to &quot;URL&#39; . import urlextract urlextractor = urlextract.URLExtract() #try print(urlextractor.find_urls(&quot;My personal website is talktosharmadhav.netlify.com and I like to surf wikipedia.com and keep my code on www.github.com/pseudocodenerd I just watched this https://www.youtube.com/watch?v=_7QRpuhz-90&quot;)) . [&#39;talktosharmadhav.netlify.com&#39;, &#39;wikipedia.com&#39;, &#39;www.github.com/pseudocodenerd&#39;, &#39;https://www.youtube.com/watch?v=_7QRpuhz-90&#39;] . lol nice, it works Now, let&#39;s put all this together into a text transformer . from sklearn.base import BaseEstimator, TransformerMixin class dopeTransformer(BaseEstimator, TransformerMixin): def __init__(self, strip_headers=True, remove_punctuation=True, replace_urls=True, replace_numbers=True, stemming=True): self.strip_headers = strip_headers self.remove_punctuation = remove_punctuation self.replace_urls = replace_urls self.replace_numbers = replace_numbers self.stemming = stemming def transform(self, X, y=None): X_transformed = [] for email in X: text = emailTOtext(email) if self.replace_numbers: text = re.sub(r&#39; d+(?: . d*(?:[eE] d+))?&#39;, &#39;NUMBER&#39;, str(text))#regexIStough!! if self.remove_punctuation: text = re.sub(r&#39; W+&#39;, &#39; &#39;, text, flags=re.M) if self.replace_urls and urlextractor is not None: urls = list(set(urlextractor.find_urls(text))) urls.sort(key=lambda url: len(url), reverse=True) for url in urls: text = text.replace(url, &quot; URL &quot;) word_counts = Counter(text.split()) if self.stemming and stemmer is not None: stemmed_word_counts = Counter() for word, count in word_counts.items(): stemmed_word = stemmer.stem(word) stemmed_word_counts[stemmed_word] += count word_counts = stemmed_word_counts X_transformed.append(word_counts) return np.array(X_transformed) def fit(self, X, y=None): return self . sampleX = X_train[:2] sampleXwordcount = dopeTransformer().fit_transform(sampleX) print(sampleXwordcount) . [Counter({&#39;chuck&#39;: 1, &#39;murcko&#39;: 1, &#39;wrote&#39;: 1, &#39;stuff&#39;: 1, &#39;yawn&#39;: 1, &#39;R&#39;: 1}) Counter({&#39;the&#39;: 11, &#39;of&#39;: 9, &#39;and&#39;: 8, &#39;all&#39;: 3, &#39;christian&#39;: 3, &#39;by&#39;: 3, &#39;jefferson&#39;: 2, &#39;I&#39;: 2, &#39;have&#39;: 2, &#39;superstit&#39;: 2, &#39;one&#39;: 2, &#39;on&#39;: 2, &#39;been&#39;: 2, &#39;ha&#39;: 2, &#39;half&#39;: 2, &#39;to&#39;: 2, &#39;rogueri&#39;: 2, &#39;teach&#39;: 2, &#39;jesu&#39;: 2, &#39;some&#39;: 1, &#39;interest&#39;: 1, &#39;quot&#39;: 1, &#39;http&#39;: 1, &#39;www&#39;: 1, &#39;postfun&#39;: 1, &#39;com&#39;: 1, &#39;pfp&#39;: 1, &#39;worboi&#39;: 1, &#39;html&#39;: 1, &#39;thoma&#39;: 1, &#39;examin&#39;: 1, &#39;known&#39;: 1, &#39;word&#39;: 1, &#39;do&#39;: 1, &#39;not&#39;: 1, &#39;find&#39;: 1, &#39;in&#39;: 1, &#39;our&#39;: 1, &#39;particular&#39;: 1, &#39;redeem&#39;: 1, &#39;featur&#39;: 1, &#39;they&#39;: 1, &#39;are&#39;: 1, &#39;alik&#39;: 1, &#39;found&#39;: 1, &#39;fabl&#39;: 1, &#39;mytholog&#39;: 1, &#39;million&#39;: 1, &#39;innoc&#39;: 1, &#39;men&#39;: 1, &#39;women&#39;: 1, &#39;children&#39;: 1, &#39;sinc&#39;: 1, &#39;introduct&#39;: 1, &#39;burnt&#39;: 1, &#39;tortur&#39;: 1, &#39;fine&#39;: 1, &#39;imprison&#39;: 1, &#39;what&#39;: 1, &#39;effect&#39;: 1, &#39;thi&#39;: 1, &#39;coercion&#39;: 1, &#39;To&#39;: 1, &#39;make&#39;: 1, &#39;world&#39;: 1, &#39;fool&#39;: 1, &#39;other&#39;: 1, &#39;hypocrit&#39;: 1, &#39;support&#39;: 1, &#39;error&#39;: 1, &#39;over&#39;: 1, &#39;earth&#39;: 1, &#39;six&#39;: 1, &#39;histor&#39;: 1, &#39;american&#39;: 1, &#39;john&#39;: 1, &#39;E&#39;: 1, &#39;remsburg&#39;: 1, &#39;letter&#39;: 1, &#39;william&#39;: 1, &#39;short&#39;: 1, &#39;again&#39;: 1, &#39;becom&#39;: 1, &#39;most&#39;: 1, &#39;pervert&#39;: 1, &#39;system&#39;: 1, &#39;that&#39;: 1, &#39;ever&#39;: 1, &#39;shone&#39;: 1, &#39;man&#39;: 1, &#39;absurd&#39;: 1, &#39;untruth&#39;: 1, &#39;were&#39;: 1, &#39;perpetr&#39;: 1, &#39;upon&#39;: 1, &#39;a&#39;: 1, &#39;larg&#39;: 1, &#39;band&#39;: 1, &#39;dupe&#39;: 1, &#39;import&#39;: 1, &#39;led&#39;: 1, &#39;paul&#39;: 1, &#39;first&#39;: 1, &#39;great&#39;: 1, &#39;corrupt&#39;: 1})] . with the the word counts with us, we need to vectorize them for use in the dataset. . from scipy.sparse import csr_matrix class dopeVectorTransformer(BaseEstimator, TransformerMixin): def __init__(self, vocab_size =1000): self.vocab_size = vocab_size def fit(self, X, y=None):#builds the vocabulary (an ordered list of the most common words) countT = Counter() for word_count in X: for word, count in word_count.items(): countT[word]+=min(count, 10) mostCommon = countT.most_common()[:self.vocab_size] self.mostCommon = mostCommon self.vocab = {word: index + 1 for index, (word, count) in enumerate(mostCommon)} return self def transform(self, X, y=None): R=[]; C=[]; Data=[] for r, word_count in enumerate(X): for word, count in word_count.items(): R.append(r) C.append(self.vocab.get(word,0)) Data.append(count) return csr_matrix((Data, (R, C)), shape=(len(X), self.vocab_size + 1)) . sampleVectorX = dopeVectorTransformer(vocab_size=5) sampleVectors = sampleVectorX.fit_transform(sampleXwordcount) print(sampleVectors) sampleVectors.toarray() print(sampleVectorX.vocab) . (0, 0) 6 (1, 0) 115 (1, 1) 11 (1, 2) 9 (1, 3) 8 (1, 4) 3 (1, 5) 3 {&#39;the&#39;: 1, &#39;of&#39;: 2, &#39;and&#39;: 3, &#39;all&#39;: 4, &#39;christian&#39;: 5} . nice . #let&#39;s do this on the entire data now we have tests it from sklearn.pipeline import Pipeline pre_processing = Pipeline([(&quot;email_to_word_count&quot;, dopeTransformer()), (&quot;wordcount_to_vector&quot;, dopeVectorTransformer()), ]) X_final = pre_processing.fit_transform(X_train) . #finally from sklearn.linear_model import LogisticRegression from sklearn.model_selection import cross_val_score model = LogisticRegression(random_state=42) score = cross_val_score(model, X_final, y_train, cv=3, verbose=3) score.mean() . [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. C: Users shekh AppData Roaming Python Python37 site-packages sklearn linear_model logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) . [CV] ................................................................ [CV] .................................... , score=0.985, total= 0.1s [CV] ................................................................ [CV] .................................... , score=0.985, total= 0.1s . [Parallel(n_jobs=1)]: Done 1 out of 1 | elapsed: 0.2s remaining: 0.0s [Parallel(n_jobs=1)]: Done 2 out of 2 | elapsed: 0.4s remaining: 0.0s . [CV] ................................................................ [CV] .................................. , score=0.99125, total= 0.0s . [Parallel(n_jobs=1)]: Done 3 out of 3 | elapsed: 0.5s finished . 0.9870833333333332 . 98.7; Dope .",
            "url": "https://csblog.madhavshekhar.com/ml/2019/10/19/spamClassifier-Oreilly-homework-chapter3.html",
            "relUrl": "/ml/2019/10/19/spamClassifier-Oreilly-homework-chapter3.html",
            "date": " • Oct 19, 2019"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "I am a man of vehement disposition, with violent enthusiasms, and extreme immoderation in all my passions. - Oliver Sacks . Hi there. . I’m Madhav Shekhar Sharma and I am passionate about computer science, building things and celebrating the joy of programming. I also love learning Machine Learning and reading Mythology(mostly hindu fanfic) . Currently, I’m a high school senior. In my free time I am generally found learning ML, doing courses and/or browsing reddit. . This website is about my experimentation in creating and following a system for constant personal growth by documenting my projects and writing about my future projects ideas. . If you’d like to connect, feel free to email. . . Colophon . This website is built with fastpages, an easy to use blogging platform with extra features for Jupyter Notebooks, by fastAI. . For the design, it uses a slightly modified minima theme for Jekyll and PyCharm’s dracula highlighting for code-blocks. . Beautiful landing image of the site is courtesy of Unsplash. For typography, it uses the Inter Typface family. Mono-spaced goodness is provided by IBM Plex Mono. . Lastly, Git is used to publish on Github, where all the code for this website is freely available. .",
          "url": "https://csblog.madhavshekhar.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

}