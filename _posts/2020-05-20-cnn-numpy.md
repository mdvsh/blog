---
keywords: fastai
description: "An attempt at implementing a CNN to from scratch using NumPy to better understand its working."
title: "Convolutional Model Building Blocks"
toc: true
branch: master
badges: true
comments: false
categories: [dl]
image: images/backprop.png
hide: false
search_exclude: false
nb_path: _notebooks/2020-05-20-cnn-numpy.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-05-20-cnn-numpy.ipynb
-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='Gist hosted <a href="https://gist.github.com/PseudoCodeNerd/ae94cc895a1c9302853306abdf99a49b">here</a>.' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TODO:">TODO:<a class="anchor-link" href="#TODO:"> </a></h3><ul>
<li>Convolution Functions<ul>
<li>Zero padding</li>
<li>Convolve window</li>
<li>Forward convolution</li>
<li>Backward Convolution</li>
</ul>
</li>
<li>Pooling Function<ul>
<li>Forward pool</li>
<li>Mask creation</li>
<li>Value distribution</li>
<li>Backward Pool</li>
</ul>
</li>
</ul>
<hr>
<center>Basic structure of CNN</center><p><img src="/blog/images/copied_from_nb/img/model_cnn.png" alt="image.png"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Zero-Padding">Zero Padding<a class="anchor-link" href="#Zero-Padding"> </a></h3><p>To add zeros around the image matrix to prevent loss of features due to scaling down after one step of a convolution.
<em>Same Convolution</em>: padding such that h-w of original image preserved after one layer.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">zero_pad</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    params</span>
<span class="sd">    X: (n, nH, nW, nC) dims array representing a batch of images</span>
<span class="sd">    p: int, amount of padding around each image</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pad_width</span> <span class="o">=</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">X_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">X_p</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>An example of padding some sample data and demonstrating.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">x_p</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;X.shape =</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;x_p.shape =</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">x_p</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axarr</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;X: Original Image Matrix&#39;</span><span class="p">)</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;X_p: Padded Image Matrix&#39;</span><span class="p">)</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_p</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>X.shape =
 (1, 3, 3, 2)
x_p.shape =
 (1, 7, 7, 2)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.image.AxesImage at 0x7f33b5942bd0&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Convolution">Convolution<a class="anchor-link" href="#Convolution"> </a></h3><ol>
<li><code>conv_one_part()</code><ul>
<li>TODO:  Take input volume (matrix by no. of channels) and <strong>convolve</strong> filter against it to output new volume with features (hopefully) identified.</li>
</ul>
</li>
</ol>
<p><code>conv_one_part()</code> will apply convolution to a part of the given image matrix (X) of dimensions filter_h x filter_w, taking steps of value <em>stride</em> after each iteration of the function.
To be implemented in the next function.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">conv_one_part</span><span class="p">(</span><span class="n">a_slice</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    params</span>
<span class="sd">    m_slice: slice of input matrix; dims --&gt; (f_h, f_w, nC_prev)</span>
<span class="sd">    W: Weight params contained in a window; dims --&gt; (f_h, f_w, nC_prev)</span>
<span class="sd">    b: Bias params contained in a window; dims --&gt; (1, 1, 1) : scalar</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">a_slice</span><span class="p">,</span> <span class="n">W</span><span class="p">)),</span> <span class="n">b</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Z</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li><code>forward_conv()</code><ul>
<li>TODO: Take multiple filters and convolve all of them on the input. Stack 2D Matrix outputs to produce output volume giving result of a single forward pass of convolution.</li>
</ul>
</li>
</ol>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">forward_conv</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparams</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    params</span>
<span class="sd">    A_prev: previous layer activation; dims --&gt; (n, nH, nW, nC_prev)</span>
<span class="sd">    W: Weight params contained in a window; dims --&gt; (f_h, f_w, nC_prev, nC)</span>
<span class="sd">    b: Bias params contained in a window; dims --&gt; (1, 1, 1, nC) : scalar</span>
<span class="sd">    hparams: dict containing values for stride and padding</span>
<span class="sd">    </span>
<span class="sd">    return</span>
<span class="sd">    Z: conv step output; dims --&gt; (n, nH, nW, nC)</span>
<span class="sd">    cache: for calculating derivatives in backward_conv()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Init: Dimensions, hparams</span>
    <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">nH_prev</span><span class="p">,</span> <span class="n">nW_prev</span><span class="p">,</span> <span class="n">nC_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A_prev</span><span class="p">)</span>
    <span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">nC_prev</span><span class="p">,</span> <span class="n">nC</span><span class="p">)</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s1">&#39;stride&#39;</span><span class="p">]</span>
    <span class="n">pad</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s1">&#39;padding&#39;</span><span class="p">]</span>
    <span class="n">nH</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">nH_prev</span><span class="o">-</span><span class="n">f</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">pad</span><span class="p">)</span><span class="o">/</span><span class="n">s</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
    <span class="n">nW</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">nW_prev</span><span class="o">-</span><span class="n">f</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">pad</span><span class="p">)</span><span class="o">/</span><span class="n">s</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">nH</span><span class="p">,</span> <span class="n">nW</span><span class="p">,</span> <span class="n">nC</span><span class="p">))</span>
    
    <span class="c1"># Applying padding to prev layer activation</span>
    <span class="n">A_prev_p</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
    
    <span class="c1"># Loop (Vectorization &gt;&gt;&gt;&gt;&gt;&gt;&gt; Loops) to apply convolution operation.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">a_prev_p</span> <span class="o">=</span> <span class="n">A_prev_p</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nH</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nW</span><span class="p">):</span>
                <span class="n">vert1_f</span><span class="p">,</span> <span class="n">vert2_f</span> <span class="o">=</span> <span class="n">h</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="n">h</span><span class="o">*</span><span class="n">s</span><span class="o">+</span><span class="n">f</span>
                <span class="n">hori1_f</span><span class="p">,</span> <span class="n">hori2_f</span> <span class="o">=</span> <span class="n">w</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="n">w</span><span class="o">*</span><span class="n">s</span><span class="o">+</span><span class="n">f</span>
                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="n">nC</span><span class="p">):</span>
                    <span class="c1"># slice</span>
                    <span class="n">a_slice</span> <span class="o">=</span> <span class="n">a_prev_p</span><span class="p">[</span><span class="n">vert1_f</span><span class="p">:</span><span class="n">vert2_f</span><span class="p">,</span> <span class="n">hori1_f</span><span class="p">:</span><span class="n">hori2_f</span><span class="p">,</span> <span class="p">:]</span>
                    <span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_one_part</span><span class="p">(</span><span class="n">a_slice</span><span class="p">,</span> <span class="n">W</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">c</span><span class="p">],</span> <span class="n">b</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">c</span><span class="p">])</span>
    <span class="c1"># for backward_conv()               </span>
    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparams</span><span class="p">)</span>
<span class="c1">#     assert(Z.shape == (n, nH, nW, nC))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">cache</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Testing-one-iteration-of-forward_conv()-on-sample-data.">Testing one iteration of <code>forward_conv()</code> on sample data.<a class="anchor-link" href="#Testing-one-iteration-of-forward_conv()-on-sample-data."> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">A_prev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span> <span class="c1"># channels of A_prev and W has to be the same (here, 4)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
<span class="n">hparams</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;padding&quot;</span> <span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>

<span class="n">Z</span><span class="p">,</span> <span class="n">cache_conv</span> <span class="o">=</span> <span class="n">forward_conv</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparams</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Z&#39;s mean =</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Z</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Z[3,2,1] =</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">Z</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cache_conv[0][1][2][3] =&quot;</span><span class="p">,</span> <span class="n">cache_conv</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">3</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Z&#39;s mean =
 -0.1282614539128993
Z[3,2,1] =
 [ 4.98925312 -0.12934609  6.77487928 -6.44934224  1.80531313  8.75470928
 -2.85387942 -2.65858316]
cache_conv[0][1][2][3] = [-0.9970198  -0.10679399  1.45142926 -0.61803685]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Pooling">Pooling<a class="anchor-link" href="#Pooling"> </a></h3><p>Pooling operation after convolution to keep strong features by taking the maximum / average value contained in a sub-matrix of dims of the filter. Pooling helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. 
<code>forward_pool()</code> implments a forward pass of the pooling layer. By default, <em>maxpool</em>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">forward_pool</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparams</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;maxpool&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    params</span>
<span class="sd">    A_prev: previous layer activation; dims --&gt; (n, nH, nW, nC_prev)</span>
<span class="sd">    hparams: dict containing values for filter_size and padding</span>
<span class="sd">    mode: pooling to perform; default --&gt; maxpool</span>
<span class="sd">    </span>
<span class="sd">    return</span>
<span class="sd">    A: pool step output; dims --&gt; (n, nH, nW, nC)</span>
<span class="sd">    cache: for calculating derivatives in backward_pool()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Init: Dimensions, hparams</span>
    <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">nH_prev</span><span class="p">,</span> <span class="n">nW_prev</span><span class="p">,</span> <span class="n">nC_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A_prev</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s1">&#39;stride&#39;</span><span class="p">]</span>
    <span class="n">fs</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s1">&#39;filt_size&#39;</span><span class="p">]</span>
    <span class="n">nH</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">nH_prev</span><span class="o">-</span><span class="n">fs</span><span class="p">)</span><span class="o">/</span><span class="n">s</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
    <span class="n">nW</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">nW_prev</span><span class="o">-</span><span class="n">fs</span><span class="p">)</span><span class="o">/</span><span class="n">s</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
    <span class="n">nC</span> <span class="o">=</span> <span class="n">nC_prev</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">nH</span><span class="p">,</span> <span class="n">nW</span><span class="p">,</span> <span class="n">nC</span><span class="p">))</span>
    
    <span class="c1"># Loop (Vectorization &gt;&gt;&gt;&gt;&gt;&gt;&gt; Loops) to apply pooling operation.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nH</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nW</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nC</span><span class="p">):</span>
                    <span class="n">vert1_f</span><span class="p">,</span> <span class="n">vert2_f</span> <span class="o">=</span> <span class="n">h</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="n">h</span><span class="o">*</span><span class="n">s</span><span class="o">+</span><span class="n">fs</span>
                    <span class="n">hori1_f</span><span class="p">,</span> <span class="n">hori2_f</span> <span class="o">=</span> <span class="n">w</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="n">w</span><span class="o">*</span><span class="n">s</span><span class="o">+</span><span class="n">fs</span>
                    <span class="n">a_slice</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">vert1_f</span><span class="p">:</span><span class="n">vert2_f</span><span class="p">,</span> <span class="n">hori1_f</span><span class="p">:</span><span class="n">hori2_f</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;maxpool&#39;</span><span class="p">:</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">a_slice</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;avrgpool&#39;</span><span class="p">:</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a_slice</span><span class="p">)</span>
    <span class="c1"># for backward_conv()               </span>
    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparams</span><span class="p">)</span>
<span class="c1">#     assert(A.shape == (n, nH, nW, nC))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">cache</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Testing-one-iteration-of-forward_pool(mode='maxpool')-on-sample-data.">Testing one iteration of <code>forward_pool(mode='maxpool')</code> on sample data.<a class="anchor-link" href="#Testing-one-iteration-of-forward_pool(mode='maxpool')-on-sample-data."> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">A_prev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">hparams</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;stride&quot;</span> <span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;filt_size&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A_prev.shape = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">A_prev</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A = </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">A_prev</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="n">A</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">forward_pool</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparams</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pooling type : Max Pooling&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A.shape = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A =</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="n">A</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">forward_pool</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparams</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;avrgpool&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pooling type : Average Pooling&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A.shape = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A =</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>A_prev.shape = (1, 5, 5, 3)
A = 
 [[[[ 1.62434536 -0.61175641 -0.52817175]
   [-1.07296862  0.86540763 -2.3015387 ]
   [ 1.74481176 -0.7612069   0.3190391 ]
   [-0.24937038  1.46210794 -2.06014071]
   [-0.3224172  -0.38405435  1.13376944]]

  [[-1.09989127 -0.17242821 -0.87785842]
   [ 0.04221375  0.58281521 -1.10061918]
   [ 1.14472371  0.90159072  0.50249434]
   [ 0.90085595 -0.68372786 -0.12289023]
   [-0.93576943 -0.26788808  0.53035547]]

  [[-0.69166075 -0.39675353 -0.6871727 ]
   [-0.84520564 -0.67124613 -0.0126646 ]
   [-1.11731035  0.2344157   1.65980218]
   [ 0.74204416 -0.19183555 -0.88762896]
   [-0.74715829  1.6924546   0.05080775]]

  [[-0.63699565  0.19091548  2.10025514]
   [ 0.12015895  0.61720311  0.30017032]
   [-0.35224985 -1.1425182  -0.34934272]
   [-0.20889423  0.58662319  0.83898341]
   [ 0.93110208  0.28558733  0.88514116]]

  [[-0.75439794  1.25286816  0.51292982]
   [-0.29809284  0.48851815 -0.07557171]
   [ 1.13162939  1.51981682  2.18557541]
   [-1.39649634 -1.44411381 -0.50446586]
   [ 0.16003707  0.87616892  0.31563495]]]]

Pooling type : Max Pooling
A.shape = (1, 2, 2, 3)
A =
 [[[[1.74481176 0.90159072 1.65980218]
   [1.74481176 1.6924546  1.65980218]]

  [[1.13162939 1.51981682 2.18557541]
   [1.13162939 1.6924546  2.18557541]]]]

Pooling type : Average Pooling
A.shape = (1, 2, 2, 3)
A =
 [[[[-0.03010467 -0.00324021 -0.33629886]
   [ 0.12893444  0.22242847  0.1250676 ]]

  [[-0.38268052  0.23257995  0.6259979 ]
   [-0.09525515  0.268511    0.46605637]]]]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Convolution-Layer---Backward-Pass">Convolution Layer - Backward Pass<a class="anchor-link" href="#Convolution-Layer---Backward-Pass"> </a></h2><p><em>Note: $dZ_{hw}$ is a scalar corresponding to the gradient of the cost with respect to the output of the conv layer Z at the hth row and wth column (corresponding to the dot product taken at the ith stride left and jth stride down).</em></p>
<p>Further, We need to compute :</p>
<ol>
<li><p>$dA$ (w.r.t cost for a certain filter $W_{c}$)
  $$ dA += \sum _{h=0} ^{n_H} \sum_{w=0} ^{n_W} W_c \times dZ_{hw} \tag{1}$$</p>
<ul>
<li>Notice, how everytime the same filter is multiplied by a different derivative of cost w.r.t output of conv layer Z ($dZ$)</li>
</ul>
</li>
<li>$dW$ (derivative of one filter w.r.t to the loss)
 $$ dW_c  += \sum _{h=0} ^{n_H} \sum_{w=0} ^ {n_W} a_{slice} \times dZ_{hw}  \tag{2}$$<ul>
<li>Where, $a_{slice}$ is the slice of original matrix used to generate activation $Z_{ij}$. This follows from the fact that the filter matrix can also learn (from backprop) optimal values.   </li>
</ul>
</li>
<li><p>$db$ ( w.r.t to the cost of a certain filter $dW_{c}$)
 $$ db = \sum_h \sum_w dZ_{hw} \tag{3}$$</p>
<ul>
<li>summing over all the gradients of the conv output (Z) with respect to the cost.</li>
</ul>
</li>
</ol>
<h4 id="backward_conv()-:-To-implement-the-backward-propagation-for-a-convolution-function"><code>backward_conv()</code> : To implement the backward propagation for a convolution function<a class="anchor-link" href="#backward_conv()-:-To-implement-the-backward-propagation-for-a-convolution-function"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">backward_conv</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">cache</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    params</span>
<span class="sd">    dZ: gradient of cost w.r.t conv layer output (Z); dims --&gt; (n, nH, nW, nC)</span>
<span class="sd">    cache: cache of values needed for backward_conv(); i.e. output of forward_conv()</span>
<span class="sd">    </span>
<span class="sd">    returns</span>
<span class="sd">    see above (markdown)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Init: Dimensions, hparams</span>
    <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparams</span><span class="p">)</span> <span class="o">=</span> <span class="n">cache</span>
    <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">nH_prev</span><span class="p">,</span> <span class="n">nW_prev</span><span class="p">,</span> <span class="n">nC_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A_prev</span><span class="p">)</span>
    <span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">nC_prev</span><span class="p">,</span> <span class="n">nC</span><span class="p">)</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s1">&#39;stride&#39;</span><span class="p">]</span>
    <span class="n">pad</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s1">&#39;padding&#39;</span><span class="p">]</span>
    <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">nH</span><span class="p">,</span> <span class="n">nW</span><span class="p">,</span> <span class="n">nC</span><span class="p">)</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">dZ</span><span class="p">)</span>
    
    <span class="n">dA_prev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">A_prev</span><span class="p">)</span>
    <span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    
    <span class="n">A_prev_p</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
    <span class="n">dA_prev_p</span>  <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">dA_prev</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
    
    <span class="c1"># Loop (Vectorization &gt;&gt;&gt;&gt;&gt;&gt;&gt; Loops) for backward convolution step.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">a_prev_p</span> <span class="o">=</span> <span class="n">A_prev_p</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="n">da_prev_p</span> <span class="o">=</span> <span class="n">dA_prev_p</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nH</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nW</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nC</span><span class="p">):</span>
                    <span class="n">vert1_f</span><span class="p">,</span> <span class="n">vert2_f</span> <span class="o">=</span> <span class="n">h</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="n">h</span><span class="o">*</span><span class="n">s</span><span class="o">+</span><span class="n">f</span>
                    <span class="n">hori1_f</span><span class="p">,</span> <span class="n">hori2_f</span> <span class="o">=</span> <span class="n">w</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="n">w</span><span class="o">*</span><span class="n">s</span><span class="o">+</span><span class="n">f</span>
                    <span class="c1"># slice</span>
                    <span class="n">a_slice</span> <span class="o">=</span> <span class="n">a_prev_p</span><span class="p">[</span><span class="n">vert1_f</span><span class="p">:</span><span class="n">vert2_f</span><span class="p">,</span> <span class="n">hori1_f</span><span class="p">:</span><span class="n">hori2_f</span><span class="p">,</span> <span class="p">:]</span>
                    <span class="c1"># updating gradients</span>
                    <span class="n">da_prev_p</span><span class="p">[</span><span class="n">vert1_f</span><span class="p">:</span><span class="n">vert2_f</span><span class="p">,</span> <span class="n">hori1_f</span><span class="p">:</span><span class="n">hori2_f</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">W</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">c</span><span class="p">]</span> <span class="o">*</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
                    <span class="n">dW</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a_slice</span> <span class="o">*</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
                    <span class="n">db</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
        <span class="n">dA_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">da_prev_p</span><span class="p">[</span><span class="n">pad</span><span class="p">:</span><span class="o">-</span><span class="n">pad</span><span class="p">,</span> <span class="n">pad</span><span class="p">:</span><span class="o">-</span><span class="n">pad</span><span class="p">,</span> <span class="p">:]</span>
    
<span class="c1">#     assert(dA_prev.shape == (m, nH_prev, nW_prev, nC_prev))</span>
    <span class="k">return</span> <span class="n">dA_prev</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Testing-backward_conv()-on-sample-data.">Testing <code>backward_conv()</code> on sample data.<a class="anchor-link" href="#Testing-backward_conv()-on-sample-data."> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># We&#39;ll run conv_forward to initialize the &#39;Z&#39; and &#39;cache_conv&quot;,</span>
<span class="c1"># which we&#39;ll use to test the conv_backward function</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">A_prev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span> <span class="c1"># six filters</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">hparameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;padding&quot;</span> <span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="n">Z</span><span class="p">,</span> <span class="n">cache_conv</span> <span class="o">=</span> <span class="n">forward_conv</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
<span class="c1"># Testing backward_conv()</span>
<span class="n">dA</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="n">backward_conv</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">cache_conv</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dA_mean =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dA</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dW_mean =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dW</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;db_mean =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">db</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>dA_mean = -0.9683520023516613
dW_mean = -3.028451139022465
db_mean = 41.04575496729348
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pooling-Layer---Backward-Pass">Pooling Layer - Backward Pass<a class="anchor-link" href="#Pooling-Layer---Backward-Pass"> </a></h2><p>Although, pooling layer has no learnable parameters for backpropagation, we still need to go through the pooling layer to complete gradient computation for layers that come before pooling layer.</p>
<p>To compute backward pooling, we would need a function <code>mask_window()</code> to create a matrix which keeps track of where the maximum of the matrix is.</p>
$$ X = \begin{bmatrix}
1 &amp;&amp; 2 \\
3 &amp;&amp; 4
\end{bmatrix} \quad \rightarrow  \quad M =\begin{bmatrix}
0 &amp;&amp; 0 \\
0 &amp;&amp; 1
\end{bmatrix}$$<h4 id="But,-why-do-we-keep-track-of-the-position-of-the-max?">But, why do we keep track of the position of the max?<a class="anchor-link" href="#But,-why-do-we-keep-track-of-the-position-of-the-max?"> </a></h4><p>It's because this is the input value that ultimately influenced the output, and therefore the cost. Backprop is computing gradients with respect to the cost, so anything that influences the ultimate cost should have a non-zero gradient. So, backprop will "propagate" the gradient back to this particular input value that had influenced the cost.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">max_mask</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    params</span>
<span class="sd">    x: input matrix to be masked</span>
<span class="sd">    </span>
<span class="sd">    returns</span>
<span class="sd">    m_x: masked matrix, same dims as x, 1 / True at max elem position</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">m_x</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x = &#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;m_x = &#39;</span><span class="p">,</span> <span class="n">max_mask</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>x =  [[5 8 9]
 [5 0 0]
 [1 7 6]]
m_z =  [[False False  True]
 [False False False]
 [False False False]]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We would also need a similar mask function for average pooling as well.</p>
<p>In case of average pooling, every elem of the sliced (window) matrix has equal influence on the output <em>unlike</em> max pooling where maximum influence is by the largest element.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">avrg_mask</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dims</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    params</span>
<span class="sd">    x: input scalar to be masked</span>
<span class="sd">    dims: dims of array we want to distribute x to. </span>
<span class="sd">    </span>
<span class="sd">    returns</span>
<span class="sd">    m_x: masked matrix, same dims as x with x distributed among it</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">(</span><span class="n">nH</span><span class="p">,</span> <span class="n">nW</span><span class="p">)</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">avg</span>  <span class="o">=</span> <span class="n">x</span><span class="o">/</span><span class="p">(</span><span class="n">nH</span><span class="o">*</span><span class="n">nW</span><span class="p">)</span>
    <span class="n">m_x</span> <span class="o">=</span> <span class="n">avg</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">nH</span><span class="p">,</span> <span class="n">nW</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">m_x</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Value to be Distributed: &#39;</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Distributed / Average Mask:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">avrg_mask</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Value to be Distributed:  25 
Distributed / Average Mask:
 [[2.77777778 2.77777778 2.77777778]
 [2.77777778 2.77777778 2.77777778]
 [2.77777778 2.77777778 2.77777778]]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now with our helper functions in place, we can proceed towards writing our final function of the day <code>backward_pool()</code>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">backward_pool</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;maxpool&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    params</span>
<span class="sd">    dA: gradient of cost w.r.t output of pooling layer; dims --&gt; like A</span>
<span class="sd">    cache: cache output from forward step of pooling layer; contains inputs and hparams</span>
<span class="sd">    moode: max/average pool</span>
<span class="sd">    </span>
<span class="sd">    returns</span>
<span class="sd">    dA_prev: gradient of cost w.r.t input of pooling layer; dims --&gt; like A_prev</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Init; Dimensions and hparams</span>
    <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparams</span><span class="p">)</span> <span class="o">=</span> <span class="n">cache</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s1">&#39;stride&#39;</span><span class="p">]</span>
    <span class="n">fs</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s1">&#39;filt_size&#39;</span><span class="p">]</span>
    <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">nH</span><span class="p">,</span> <span class="n">nW</span><span class="p">,</span> <span class="n">nC</span><span class="p">)</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">dA</span><span class="p">)</span>
    <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">nH_prev</span><span class="p">,</span> <span class="n">nW_prev</span><span class="p">,</span> <span class="n">nC_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A_prev</span><span class="p">)</span>
    <span class="n">dA_prev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">A_prev</span><span class="p">)</span>
    
    <span class="c1"># Loop (Vectorization &gt;&gt;&gt;&gt;&gt;&gt;&gt; Loops) for backward pooling step.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">a_prev</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nH</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nW</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nC</span><span class="p">):</span>
                    <span class="n">vert1_f</span><span class="p">,</span> <span class="n">vert2_f</span> <span class="o">=</span> <span class="n">h</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="n">h</span><span class="o">*</span><span class="n">s</span><span class="o">+</span><span class="n">fs</span>
                    <span class="n">hori1_f</span><span class="p">,</span> <span class="n">hori2_f</span> <span class="o">=</span> <span class="n">w</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="n">w</span><span class="o">*</span><span class="n">s</span><span class="o">+</span><span class="n">fs</span>
                    <span class="k">if</span> <span class="n">mode</span><span class="o">==</span><span class="s1">&#39;maxpool&#39;</span><span class="p">:</span>
                        <span class="n">a_prev_slice</span> <span class="o">=</span> <span class="n">a_prev</span><span class="p">[</span><span class="n">vert1_f</span><span class="p">:</span><span class="n">vert2_f</span><span class="p">,</span> <span class="n">hori1_f</span><span class="p">:</span><span class="n">hori2_f</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
                        <span class="c1"># create mask from a_prev_slice</span>
                        <span class="n">mask</span> <span class="o">=</span> <span class="n">max_mask</span><span class="p">(</span><span class="n">a_prev_slice</span><span class="p">)</span>
                        <span class="n">dA_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">vert1_f</span><span class="p">:</span><span class="n">vert2_f</span><span class="p">,</span> <span class="n">hori1_f</span><span class="p">:</span><span class="n">hori2_f</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">mask</span> <span class="o">*</span> <span class="n">dA</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
                    <span class="k">elif</span> <span class="n">mode</span><span class="o">==</span><span class="s1">&#39;avrgpool&#39;</span><span class="p">:</span>
                        <span class="n">da</span> <span class="o">=</span> <span class="n">dA</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
                        <span class="n">dims</span> <span class="o">=</span> <span class="p">(</span><span class="n">fs</span><span class="p">,</span> <span class="n">fs</span><span class="p">)</span>
                        <span class="n">dA_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">vert1_f</span><span class="p">:</span><span class="n">vert2_f</span><span class="p">,</span> <span class="n">hori1_f</span><span class="p">:</span><span class="n">hori2_f</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">avrg_mask</span><span class="p">(</span><span class="n">da</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span>
                        
<span class="c1">#     assert(dA_prev.shape == A_prev.shape)</span>
    
    <span class="k">return</span> <span class="n">dA_prev</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Testing-backward_pool()-on-sample-data.">Testing <code>backward_pool()</code> on sample data.<a class="anchor-link" href="#Testing-backward_pool()-on-sample-data."> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">A_prev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">hparameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;stride&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;filt_size&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="n">A</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">forward_pool</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
<span class="n">dA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">dA_prev</span> <span class="o">=</span> <span class="n">backward_pool</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;maxpool&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pooling type : Max Pooling&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mean of dA = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dA</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dA_prev[1,1] = &#39;</span><span class="p">,</span> <span class="n">dA_prev</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>  
<span class="nb">print</span><span class="p">()</span>
<span class="n">dA_prev</span> <span class="o">=</span> <span class="n">backward_pool</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;avrgpool&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pooling type : Average Pooling&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mean of dA = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dA</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dA_prev[1,1] = &#39;</span><span class="p">,</span> <span class="n">dA_prev</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Pooling type : Max Pooling
mean of dA =  0.14571390272918056
dA_prev[1,1] =  [[ 0.          0.        ]
 [ 5.05844394 -1.68282702]
 [ 0.          0.        ]]

Pooling type : Average Pooling
mean of dA =  0.14571390272918056
dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]
 [ 1.26461098 -0.25749373]
 [ 1.17975636 -0.53624893]]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>With this, we have completed all the basic building <del>blocks</del> functions required to build a Convolutional Model.</p>
<p>While coding this out, I was able to greatly increase my understanding about the mathematical working beneath both convolution and pooling operations.</p>
<p>With deeplearning libraries such as PyTorch and Tensorflow making such things a breeze, (only 10 lines of pytorch code to do all things I've done in this notebook) it's not practical to define CNN models from scratch using numpy since tensors (numpy arrays + GPU support) are the go-to. Still, this endeavour turned out to be extremely knowledgable and <em>EPIC</em>.</p>
<h3 id="kthnxbye"><em>kthnxbye</em><a class="anchor-link" href="#kthnxbye"> </a></h3>
</div>
</div>
</div>
</div>
 

